<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>dxer</title>
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://dxer.github.io/"/>
  <updated>2016-07-13T06:51:54.771Z</updated>
  <id>http://dxer.github.io/</id>
  
  <author>
    <name>dxer</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>WebDigger爬虫</title>
    <link href="http://dxer.github.io/2016/07/13/WebDigger/"/>
    <id>http://dxer.github.io/2016/07/13/WebDigger/</id>
    <published>2016-07-13T03:52:41.293Z</published>
    <updated>2016-07-13T06:51:54.771Z</updated>
    
    <content type="html">&lt;p&gt;WebDigger是一个采用Java开发的爬虫框架。WebDigger的目标是简化爬虫的开发流程，让开发者只用关心抓取页面的数据提取和数据保存的逻辑。WebDigger也提供注解的方式来配置要抓取的网页数据，以减少代码的开发。&lt;a href=&quot;https://github.com/dxer/WebDigger&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;项目地址&lt;/a&gt;&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&quot;组件&quot;&gt;&lt;a href=&quot;#组件&quot; class=&quot;headerlink&quot; title=&quot;组件&quot;&gt;&lt;/a&gt;组件&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Digger&lt;br&gt;负责控制数据流在系统中所有组件中流动，并在相应动作发生时触发事件。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Scheduler&lt;br&gt;调度器从引擎接受request并将他们入队，以便之后引擎请求他们时提供给引擎。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Downloader&lt;br&gt;下载器负责获取页面数据Response，供Processor模块进行数据提取&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Processor&lt;br&gt;是用于分析response并提取item(需要的抓取的具体的数据)。每个spider的Processor负责处理一个特定(或一些)网站。网页数据提取支持Jsoup和Xpath的方式。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Storage&lt;br&gt;负责处理被Processor提取出来的item。主要是用来将item进行持久化操作（保存到文件，打印输出等）。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;下面是一个抓取豆瓣图书的例子&lt;/p&gt;
&lt;figure class=&quot;highlight java&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;25&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;26&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;27&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;28&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;29&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;30&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;31&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;32&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;33&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;34&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;35&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;36&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;37&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;38&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;39&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;40&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;41&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;42&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;class&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;DBBookSpider&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;extends&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;Spider&lt;/span&gt; &lt;/span&gt;&amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;comment&quot;&gt;/**&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;     * 自定义的processor，负责解析页面书籍的相关信息&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;     */&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;meta&quot;&gt;@Override&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;process&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;(Response response)&lt;/span&gt; &lt;/span&gt;&amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        Selector selector = response.getJXDoc().getSelector();&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        Map&amp;lt;String, String&amp;gt; fieldMap = &lt;span class=&quot;keyword&quot;&gt;new&lt;/span&gt; HashMap&amp;lt;String, String&amp;gt;();&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        fieldMap.put(&lt;span class=&quot;string&quot;&gt;&quot;name&quot;&lt;/span&gt;, &lt;span class=&quot;string&quot;&gt;&quot;div.info &amp;gt; h2 &amp;gt; a&quot;&lt;/span&gt;);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        fieldMap.put(&lt;span class=&quot;string&quot;&gt;&quot;pub&quot;&lt;/span&gt;, &lt;span class=&quot;string&quot;&gt;&quot;div.info &amp;gt; div.pub&quot;&lt;/span&gt;);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        fieldMap.put(&lt;span class=&quot;string&quot;&gt;&quot;score&quot;&lt;/span&gt;, &lt;span class=&quot;string&quot;&gt;&quot;div.info &amp;gt; div.star.clearfix &amp;gt; span.rating_nums&quot;&lt;/span&gt;);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        fieldMap.put(&lt;span class=&quot;string&quot;&gt;&quot;comments&quot;&lt;/span&gt;, &lt;span class=&quot;string&quot;&gt;&quot;div.info &amp;gt; div.star.clearfix &amp;gt; span.pl&quot;&lt;/span&gt;);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        fieldMap.put(&lt;span class=&quot;string&quot;&gt;&quot;intro&quot;&lt;/span&gt;, &lt;span class=&quot;string&quot;&gt;&quot;div.info &amp;gt; p&quot;&lt;/span&gt;);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        List&amp;lt;Map&amp;lt;String, String&amp;gt;&amp;gt; list = selector.foreach(&lt;span class=&quot;string&quot;&gt;&quot;#subject_list &amp;gt; ul &amp;gt; li&quot;&lt;/span&gt;, fieldMap);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        response.put(&lt;span class=&quot;string&quot;&gt;&quot;list&quot;&lt;/span&gt;, list);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;comment&quot;&gt;/**&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;     * 自定义的Storage，这里仅仅是将信息打印输出&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;     */&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;meta&quot;&gt;@Override&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;persist&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;(Item item)&lt;/span&gt; &lt;/span&gt;&amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        List&amp;lt;Map&amp;lt;String, String&amp;gt;&amp;gt; list = (List&amp;lt;Map&amp;lt;String, String&amp;gt;&amp;gt;) item.get(&lt;span class=&quot;string&quot;&gt;&quot;list&quot;&lt;/span&gt;);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &lt;span class=&quot;keyword&quot;&gt;if&lt;/span&gt; (list != &lt;span class=&quot;keyword&quot;&gt;null&lt;/span&gt; &amp;amp;&amp;amp; !list.isEmpty()) &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            &lt;span class=&quot;keyword&quot;&gt;for&lt;/span&gt; (Map&amp;lt;String, String&amp;gt; map: list) &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;                System.out.println(JSON.toJSONString(map));&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;main&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;(String[] args)&lt;/span&gt; &lt;/span&gt;&amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &lt;span class=&quot;keyword&quot;&gt;new&lt;/span&gt; DBBookSpider()&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;                        .addStartUrls(&lt;span class=&quot;string&quot;&gt;&quot;https://book.douban.com/tag/中国文学&quot;&lt;/span&gt;,&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;                            &lt;span class=&quot;string&quot;&gt;&quot;https://book.douban.com/tag/中国文学?start=20&amp;amp;type=T&quot;&lt;/span&gt;,&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;                            &lt;span class=&quot;string&quot;&gt;&quot;https://book.douban.com/tag/中国文学?start=40&amp;amp;type=T&quot;&lt;/span&gt;).setFollowed(&lt;span class=&quot;keyword&quot;&gt;false&lt;/span&gt;).start(); &lt;span class=&quot;comment&quot;&gt;// 启动爬虫&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;基于注解方式的抓取数据的定义&lt;/p&gt;
&lt;figure class=&quot;highlight java&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;class&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;QQTechModel&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;extends&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;CrawlerModel&lt;/span&gt; &lt;/span&gt;&amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &lt;span class=&quot;meta&quot;&gt;@FieldRule&lt;/span&gt;(type = FieldType.CSS, expr = &lt;span class=&quot;string&quot;&gt;&quot;#C-Main-Article-QQ &amp;gt; div.hd &amp;gt; h1&quot;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &lt;span class=&quot;keyword&quot;&gt;private&lt;/span&gt; String title;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &lt;span class=&quot;meta&quot;&gt;@FieldRule&lt;/span&gt;(type = FieldType.CSS, expr = &lt;span class=&quot;string&quot;&gt;&quot;#C-Main-Article-QQ &amp;gt; div.hd &amp;gt; div &amp;gt; div &amp;gt; span.pubTime&quot;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &lt;span class=&quot;keyword&quot;&gt;private&lt;/span&gt; String pubTime;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &lt;span class=&quot;meta&quot;&gt;@FieldRule&lt;/span&gt;(type = FieldType.CSS, expr = &lt;span class=&quot;string&quot;&gt;&quot;#Cnt-Main-Article-QQ&quot;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &lt;span class=&quot;keyword&quot;&gt;private&lt;/span&gt; String content;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;// ... get &amp;amp; set&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/dxer/WebDigger&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;项目地址&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;ps： 欢迎有兴趣的同学，一起沟通学习~&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;WebDigger是一个采用Java开发的爬虫框架。WebDigger的目标是简化爬虫的开发流程，让开发者只用关心抓取页面的数据提取和数据保存的逻辑。WebDigger也提供注解的方式来配置要抓取的网页数据，以减少代码的开发。&lt;a href=&quot;https://github.com/dxer/WebDigger&quot;&gt;项目地址&lt;/a&gt;&lt;br&gt;
    
    </summary>
    
    
      <category term="爬虫" scheme="http://dxer.github.io/tags/%E7%88%AC%E8%99%AB/"/>
    
      <category term="WebDigger" scheme="http://dxer.github.io/tags/WebDigger/"/>
    
  </entry>
  
  <entry>
    <title>redis快速入门</title>
    <link href="http://dxer.github.io/2016/07/02/redis_quick_start/"/>
    <id>http://dxer.github.io/2016/07/02/redis_quick_start/</id>
    <published>2016-07-02T01:13:19.000Z</published>
    <updated>2016-07-14T02:19:42.054Z</updated>
    
    <content type="html">&lt;h2 id=&quot;Redis简介&quot;&gt;&lt;a href=&quot;#Redis简介&quot; class=&quot;headerlink&quot; title=&quot;Redis简介&quot;&gt;&lt;/a&gt;Redis简介&lt;/h2&gt;&lt;p&gt;Redis是一款开源的，高性能的键值存储。它常被称为是一款数据结构服务器。Redis的键值可以包含字符串，哈希，列表，集合和有序集合等数据类型。对于这些数据类型，你可以执行原子操作.&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;为了获得优异的性能，redis采用了内存中（in memory）数据集的方式。同时redis支持数据的持久化，可以每隔一段时间将数据转存到磁盘上（snapshot），也可以在日志尾部追加每一条操作命令（append only file， aof）&lt;/p&gt;
&lt;p&gt;redis支持主从复制（master-slave replication），并且具有非常快速的非阻塞首次同步，网络断开自动重连等功能。&lt;/p&gt;
&lt;p&gt;redis支持的数据类型&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Keys&lt;br&gt;  非二进制安全的字符类型&lt;/li&gt;
&lt;li&gt;Values&lt;ul&gt;
&lt;li&gt;Strings&lt;/li&gt;
&lt;li&gt;Lists&lt;/li&gt;
&lt;li&gt;Sets&lt;/li&gt;
&lt;li&gt;Sorted sets&lt;/li&gt;
&lt;li&gt;Hash&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;Key相关的命令&quot;&gt;&lt;a href=&quot;#Key相关的命令&quot; class=&quot;headerlink&quot; title=&quot;Key相关的命令&quot;&gt;&lt;/a&gt;Key相关的命令&lt;/h2&gt;&lt;h3 id=&quot;exists-key&quot;&gt;&lt;a href=&quot;#exists-key&quot; class=&quot;headerlink&quot; title=&quot;exists key&quot;&gt;&lt;/a&gt;exists key&lt;/h3&gt;&lt;p&gt;测试指定的key是否存在，返回1表示存在，0表示不存在&lt;/p&gt;
&lt;h3 id=&quot;del-key1-key2-…-keyN&quot;&gt;&lt;a href=&quot;#del-key1-key2-…-keyN&quot; class=&quot;headerlink&quot; title=&quot;del key1 key2 … keyN&quot;&gt;&lt;/a&gt;del key1 key2 … keyN&lt;/h3&gt;&lt;p&gt;删除指定的key，返回删除key的数目，0表示给定eky都不存在&lt;/p&gt;
&lt;h3 id=&quot;type-key&quot;&gt;&lt;a href=&quot;#type-key&quot; class=&quot;headerlink&quot; title=&quot;type key&quot;&gt;&lt;/a&gt;type key&lt;/h3&gt;&lt;p&gt;返回指定key的value类型。返回none表示不存在。&lt;/p&gt;
&lt;h3 id=&quot;keys-pattern&quot;&gt;&lt;a href=&quot;#keys-pattern&quot; class=&quot;headerlink&quot; title=&quot;keys pattern&quot;&gt;&lt;/a&gt;keys pattern&lt;/h3&gt;&lt;p&gt;返回匹配指定模式的所有key（支持*,?,[abc]的方式）&lt;/p&gt;
&lt;h3 id=&quot;randomkey&quot;&gt;&lt;a href=&quot;#randomkey&quot; class=&quot;headerlink&quot; title=&quot;randomkey&quot;&gt;&lt;/a&gt;randomkey&lt;/h3&gt;&lt;p&gt;返回当前数据库中随机选择的一个key，如果当前数据库是空的，返回空串&lt;/p&gt;
&lt;h3 id=&quot;rename-oldkey-newkey&quot;&gt;&lt;a href=&quot;#rename-oldkey-newkey&quot; class=&quot;headerlink&quot; title=&quot;rename oldkey newkey&quot;&gt;&lt;/a&gt;rename oldkey newkey&lt;/h3&gt;&lt;p&gt;原子的重命名一个key，如果newkey存在，将会被覆盖，返回1表示成功，0表示失败。失败可能是oldkey不存在或者和newkey相同&lt;/p&gt;
&lt;h3 id=&quot;renamenx-oldkey-newkey&quot;&gt;&lt;a href=&quot;#renamenx-oldkey-newkey&quot; class=&quot;headerlink&quot; title=&quot;renamenx oldkey newkey&quot;&gt;&lt;/a&gt;renamenx oldkey newkey&lt;/h3&gt;&lt;p&gt;同上，但是如果newkey存在则返回失败&lt;/p&gt;
&lt;h3 id=&quot;dbsize&quot;&gt;&lt;a href=&quot;#dbsize&quot; class=&quot;headerlink&quot; title=&quot;dbsize&quot;&gt;&lt;/a&gt;dbsize&lt;/h3&gt;&lt;p&gt;返回当前数据库的key的数量&lt;/p&gt;
&lt;h3 id=&quot;expire-key-seconds&quot;&gt;&lt;a href=&quot;#expire-key-seconds&quot; class=&quot;headerlink&quot; title=&quot;expire key seconds&quot;&gt;&lt;/a&gt;expire key seconds&lt;/h3&gt;&lt;p&gt;为指定的key设置过期时间，单位是秒。返回1表示成功，0表示key已经设置过期时间或者不存在。&lt;/p&gt;
&lt;h3 id=&quot;ttl-key&quot;&gt;&lt;a href=&quot;#ttl-key&quot; class=&quot;headerlink&quot; title=&quot;ttl key&quot;&gt;&lt;/a&gt;ttl key&lt;/h3&gt;&lt;p&gt;返回设置了过期时间的key的剩余过期秒数。-1表示key不存在或者没有设置过期时间&lt;/p&gt;
&lt;h3 id=&quot;select-db-index&quot;&gt;&lt;a href=&quot;#select-db-index&quot; class=&quot;headerlink&quot; title=&quot;select db-index&quot;&gt;&lt;/a&gt;select db-index&lt;/h3&gt;&lt;p&gt;通过索引选择数据库，默认连接的是数据库是0。默认数据库数是16.返回1表示成功，0表示失败&lt;/p&gt;
&lt;h3 id=&quot;move-key-db-index&quot;&gt;&lt;a href=&quot;#move-key-db-index&quot; class=&quot;headerlink&quot; title=&quot;move key db-index&quot;&gt;&lt;/a&gt;move key db-index&lt;/h3&gt;&lt;p&gt;将key从当前数据库移动到指定数据库。返回1表示成功，0表示key不存在或者已经在指定的数据库中&lt;/p&gt;
&lt;h3 id=&quot;flushdb&quot;&gt;&lt;a href=&quot;#flushdb&quot; class=&quot;headerlink&quot; title=&quot;flushdb&quot;&gt;&lt;/a&gt;flushdb&lt;/h3&gt;&lt;p&gt;删除当前数据库中所有key，此方法不会失败（慎用）&lt;/p&gt;
&lt;h3 id=&quot;flushall&quot;&gt;&lt;a href=&quot;#flushall&quot; class=&quot;headerlink&quot; title=&quot;flushall&quot;&gt;&lt;/a&gt;flushall&lt;/h3&gt;&lt;p&gt;删除所有数据库中的所有的key，此方法不会失败（慎用）&lt;/p&gt;
&lt;h2 id=&quot;String&quot;&gt;&lt;a href=&quot;#String&quot; class=&quot;headerlink&quot; title=&quot;String&quot;&gt;&lt;/a&gt;String&lt;/h2&gt;&lt;p&gt;string是redis最基本的数据类型，而且string类型是二进制安全的&lt;br&gt;redis的string可以包含任何数据，包括jpg图片或者序列化对象&lt;br&gt;最大上限是1G字节&lt;br&gt;如果只用string类型，redis就可以被看作是特性的memcached&lt;/p&gt;
&lt;h2 id=&quot;string相关命令&quot;&gt;&lt;a href=&quot;#string相关命令&quot; class=&quot;headerlink&quot; title=&quot;string相关命令&quot;&gt;&lt;/a&gt;string相关命令&lt;/h2&gt;&lt;h3 id=&quot;set-key-value&quot;&gt;&lt;a href=&quot;#set-key-value&quot; class=&quot;headerlink&quot; title=&quot;set key value&quot;&gt;&lt;/a&gt;set key value&lt;/h3&gt;&lt;p&gt;设置key的值，成功返回1，失败返回0&lt;/p&gt;
&lt;h3 id=&quot;setnx-key-value&quot;&gt;&lt;a href=&quot;#setnx-key-value&quot; class=&quot;headerlink&quot; title=&quot;setnx key value&quot;&gt;&lt;/a&gt;setnx key value&lt;/h3&gt;&lt;p&gt;同上，如果key已经存在，返回0。nx表示not exist的意思&lt;/p&gt;
&lt;h3 id=&quot;get-key&quot;&gt;&lt;a href=&quot;#get-key&quot; class=&quot;headerlink&quot; title=&quot;get key&quot;&gt;&lt;/a&gt;get key&lt;/h3&gt;&lt;p&gt;获取key的值，如果key不存在则返回nil&lt;/p&gt;
&lt;h3 id=&quot;getset-key-value&quot;&gt;&lt;a href=&quot;#getset-key-value&quot; class=&quot;headerlink&quot; title=&quot;getset key value&quot;&gt;&lt;/a&gt;getset key value&lt;/h3&gt;&lt;p&gt;设置key的值，并返回key的旧值。如果key不存在，则返回nil&lt;/p&gt;
&lt;h3 id=&quot;mget-key1-key2-…-keyN&quot;&gt;&lt;a href=&quot;#mget-key1-key2-…-keyN&quot; class=&quot;headerlink&quot; title=&quot;mget key1 key2 … keyN&quot;&gt;&lt;/a&gt;mget key1 key2 … keyN&lt;/h3&gt;&lt;p&gt;一次获取多个key的值，如果对应的key不存在，则对应返回nil&lt;/p&gt;
&lt;h3 id=&quot;mset-key1-value1-key2-value2-…-keyN-valueN&quot;&gt;&lt;a href=&quot;#mset-key1-value1-key2-value2-…-keyN-valueN&quot; class=&quot;headerlink&quot; title=&quot;mset key1 value1 key2 value2 … keyN valueN&quot;&gt;&lt;/a&gt;mset key1 value1 key2 value2 … keyN valueN&lt;/h3&gt;&lt;p&gt;一次设置多个key的值，成功返回1，表示所有的值都设置了，失败返回0，表示任何值都没有被设置&lt;/p&gt;
&lt;h3 id=&quot;msetnx-key1-value1-key2-value2-…-keyN-valueN&quot;&gt;&lt;a href=&quot;#msetnx-key1-value1-key2-value2-…-keyN-valueN&quot; class=&quot;headerlink&quot; title=&quot;msetnx key1 value1 key2 value2 … keyN valueN&quot;&gt;&lt;/a&gt;msetnx key1 value1 key2 value2 … keyN valueN&lt;/h3&gt;&lt;p&gt;同上，但是不会覆盖已经存在的key&lt;/p&gt;
&lt;h3 id=&quot;incr-key&quot;&gt;&lt;a href=&quot;#incr-key&quot; class=&quot;headerlink&quot; title=&quot;incr key&quot;&gt;&lt;/a&gt;incr key&lt;/h3&gt;&lt;p&gt;对key的值做加加操作，并返回新的值。incr一个不是int的value会返回错误，incr一个不存在的key，则设置key为1&lt;/p&gt;
&lt;h3 id=&quot;decr-key&quot;&gt;&lt;a href=&quot;#decr-key&quot; class=&quot;headerlink&quot; title=&quot;decr key&quot;&gt;&lt;/a&gt;decr key&lt;/h3&gt;&lt;p&gt;做减减操作。decr一个不存在的key，则设置key的值为-1&lt;/p&gt;
&lt;h3 id=&quot;incrby-key-integer&quot;&gt;&lt;a href=&quot;#incrby-key-integer&quot; class=&quot;headerlink&quot; title=&quot;incrby key integer&quot;&gt;&lt;/a&gt;incrby key integer&lt;/h3&gt;&lt;p&gt;加指定值&lt;/p&gt;
&lt;h3 id=&quot;decrby-key-integer&quot;&gt;&lt;a href=&quot;#decrby-key-integer&quot; class=&quot;headerlink&quot; title=&quot;decrby key integer&quot;&gt;&lt;/a&gt;decrby key integer&lt;/h3&gt;&lt;p&gt;减去指定值&lt;/p&gt;
&lt;h3 id=&quot;append-key-value&quot;&gt;&lt;a href=&quot;#append-key-value&quot; class=&quot;headerlink&quot; title=&quot;append key value&quot;&gt;&lt;/a&gt;append key value&lt;/h3&gt;&lt;p&gt;给指定key的字符串追加value，返回新字符串值得长度&lt;/p&gt;
&lt;h3 id=&quot;substr-key-start-end&quot;&gt;&lt;a href=&quot;#substr-key-start-end&quot; class=&quot;headerlink&quot; title=&quot;substr key start end&quot;&gt;&lt;/a&gt;substr key start end&lt;/h3&gt;&lt;p&gt;返回截取过的key的字符串，并不修改key的值。下表是从0开始的。&lt;/p&gt;
&lt;h2 id=&quot;List&quot;&gt;&lt;a href=&quot;#List&quot; class=&quot;headerlink&quot; title=&quot;List&quot;&gt;&lt;/a&gt;List&lt;/h2&gt;&lt;p&gt;redis的list类型其实就是一个每个子元素都是string类型的双向链表。我们可以通过push，pop操作从链表的头部或者尾部添加删除元素。这使得list既可以用作栈，又可以用作队列&lt;br&gt;list的pop操作还有阻塞版本。当我们使用[lr]pop一个list对象的时候，如果list为空，或者list不存在，会立即返回nil。但是如果使用b[lr]pop可以阻塞，也可以设置超时时间，超过超时时间返回nil。阻塞版本的pop主要是为了避免轮训。&lt;/p&gt;
&lt;h2 id=&quot;List的相关命令&quot;&gt;&lt;a href=&quot;#List的相关命令&quot; class=&quot;headerlink&quot; title=&quot;List的相关命令&quot;&gt;&lt;/a&gt;List的相关命令&lt;/h2&gt;&lt;h3 id=&quot;lpush-key-string&quot;&gt;&lt;a href=&quot;#lpush-key-string&quot; class=&quot;headerlink&quot; title=&quot;lpush key string&quot;&gt;&lt;/a&gt;lpush key string&lt;/h3&gt;&lt;p&gt;在key对应list的头部添加字符串元素，成功返回1，失败返回0，表示key存在且不是list类型&lt;/p&gt;
&lt;h3 id=&quot;rpush-key-string&quot;&gt;&lt;a href=&quot;#rpush-key-string&quot; class=&quot;headerlink&quot; title=&quot;rpush key string&quot;&gt;&lt;/a&gt;rpush key string&lt;/h3&gt;&lt;p&gt;同上，在尾部添加&lt;/p&gt;
&lt;h3 id=&quot;llen-key&quot;&gt;&lt;a href=&quot;#llen-key&quot; class=&quot;headerlink&quot; title=&quot;llen key&quot;&gt;&lt;/a&gt;llen key&lt;/h3&gt;&lt;p&gt;返回key对应list的长度，key不存在返回0，如果key对应类型不是list返回错误&lt;/p&gt;
&lt;h3 id=&quot;lrange-key-start-end&quot;&gt;&lt;a href=&quot;#lrange-key-start-end&quot; class=&quot;headerlink&quot; title=&quot;lrange key start end&quot;&gt;&lt;/a&gt;lrange key start end&lt;/h3&gt;&lt;p&gt;返回指定区间内的元素，下标从0开始，负值表示从后面计算，-1表示倒数第一个元素，key不存在返回空列表&lt;/p&gt;
&lt;h3 id=&quot;ltrim-key-start-end&quot;&gt;&lt;a href=&quot;#ltrim-key-start-end&quot; class=&quot;headerlink&quot; title=&quot;ltrim key start end&quot;&gt;&lt;/a&gt;ltrim key start end&lt;/h3&gt;&lt;p&gt;截取list，保留指定区间内的元素，成功返回1，key不存在返回错误&lt;/p&gt;
&lt;h3 id=&quot;lset-key-index-value&quot;&gt;&lt;a href=&quot;#lset-key-index-value&quot; class=&quot;headerlink&quot; title=&quot;lset key index value&quot;&gt;&lt;/a&gt;lset key index value&lt;/h3&gt;&lt;p&gt;设置list中指定下标的元素值，成功返回1，key或者下标不存在返回错误&lt;/p&gt;
&lt;h3 id=&quot;lrem-key-count-value&quot;&gt;&lt;a href=&quot;#lrem-key-count-value&quot; class=&quot;headerlink&quot; title=&quot;lrem key count value&quot;&gt;&lt;/a&gt;lrem key count value&lt;/h3&gt;&lt;p&gt;从key对应的list中删除count个和value相同的元素。count为0的时候删除全部&lt;/p&gt;
&lt;h3 id=&quot;lpop-key&quot;&gt;&lt;a href=&quot;#lpop-key&quot; class=&quot;headerlink&quot; title=&quot;lpop key&quot;&gt;&lt;/a&gt;lpop key&lt;/h3&gt;&lt;p&gt;从list的头部删除数据，并返回删除的数据。如果key对应的list不存在或者是空返回nil，如果key对应值不是list，返回错误&lt;/p&gt;
&lt;h3 id=&quot;rpop-key&quot;&gt;&lt;a href=&quot;#rpop-key&quot; class=&quot;headerlink&quot; title=&quot;rpop key&quot;&gt;&lt;/a&gt;rpop key&lt;/h3&gt;&lt;p&gt;同上，从尾部删除&lt;/p&gt;
&lt;h3 id=&quot;blpop-key1-key2-…-keyN-timeout&quot;&gt;&lt;a href=&quot;#blpop-key1-key2-…-keyN-timeout&quot; class=&quot;headerlink&quot; title=&quot;blpop key1 key2 … keyN timeout&quot;&gt;&lt;/a&gt;blpop key1 key2 … keyN timeout&lt;/h3&gt;&lt;p&gt;从左到右扫描返回对第一个非空list进行lpop操作并返回。比如blpop list1 list2 list3 0 ,如果list不存在，list2,list3都是非空则对list2做lpop并返回从list2中删除的元素。如果所有的list都是空或不存在，则会阻塞timeout秒，timeout为0表示一直阻塞。当阻塞时，如果有client对key1…keyN中的任意key进行push操作，则第一在这个key上被阻塞的client会立即返回。如果超时发生，则返回nil。&lt;/p&gt;
&lt;h3 id=&quot;brpop-key1-key2-…-keyN-timeout&quot;&gt;&lt;a href=&quot;#brpop-key1-key2-…-keyN-timeout&quot; class=&quot;headerlink&quot; title=&quot;brpop key1 key2 … keyN timeout&quot;&gt;&lt;/a&gt;brpop key1 key2 … keyN timeout&lt;/h3&gt;&lt;p&gt;同blpop，从尾部删除&lt;/p&gt;
&lt;h3 id=&quot;rpoplpush-srckey-destkey&quot;&gt;&lt;a href=&quot;#rpoplpush-srckey-destkey&quot; class=&quot;headerlink&quot; title=&quot;rpoplpush srckey destkey&quot;&gt;&lt;/a&gt;rpoplpush srckey destkey&lt;/h3&gt;&lt;p&gt;从srckey对应的list的尾部移除元素并添加到destkey对应list的头部，最后返回被移除的元素值，整个操作是原子操作的。如果srckey是空或者不存在返回nil&lt;/p&gt;
&lt;h2 id=&quot;Set&quot;&gt;&lt;a href=&quot;#Set&quot; class=&quot;headerlink&quot; title=&quot;Set&quot;&gt;&lt;/a&gt;Set&lt;/h2&gt;&lt;p&gt;redis的set是string类型的无序集合&lt;br&gt;set元素最大可以包含2的32次方-1个元素&lt;br&gt;set是通过hash table实现的，hash table会随着添加或者删除自动跳帧大小&lt;br&gt;关于set集合类型除了基本的添加操作删除，其他有用的操作还包含集合的取并集（union），交集（insertsection），差集（difference）。&lt;/p&gt;
&lt;h3 id=&quot;sass-key-member&quot;&gt;&lt;a href=&quot;#sass-key-member&quot; class=&quot;headerlink&quot; title=&quot;sass key member&quot;&gt;&lt;/a&gt;sass key member&lt;/h3&gt;&lt;p&gt;添加一个string元素到key对应的set集合中，成功返回1&lt;/p&gt;
&lt;h3 id=&quot;srem-key-member&quot;&gt;&lt;a href=&quot;#srem-key-member&quot; class=&quot;headerlink&quot; title=&quot;srem key member&quot;&gt;&lt;/a&gt;srem key member&lt;/h3&gt;&lt;h3 id=&quot;spop-key&quot;&gt;&lt;a href=&quot;#spop-key&quot; class=&quot;headerlink&quot; title=&quot;spop key&quot;&gt;&lt;/a&gt;spop key&lt;/h3&gt;&lt;p&gt;删除并返回key对应set中随机的一个元素，如果set是空，或者key不存在则返回nil&lt;/p&gt;
&lt;h3 id=&quot;smove-srckey-dstkey-member&quot;&gt;&lt;a href=&quot;#smove-srckey-dstkey-member&quot; class=&quot;headerlink&quot; title=&quot;smove srckey dstkey member&quot;&gt;&lt;/a&gt;smove srckey dstkey member&lt;/h3&gt;&lt;p&gt;从srckey对应的set中移除member并添加到dstkey对应的set中，整个操作是原子的，成功返回1，如果member在srckey中不存在返回0，如果key不是set类型返回错误&lt;/p&gt;
&lt;h3 id=&quot;scard-key&quot;&gt;&lt;a href=&quot;#scard-key&quot; class=&quot;headerlink&quot; title=&quot;scard key&quot;&gt;&lt;/a&gt;scard key&lt;/h3&gt;&lt;p&gt;返回set的元素的个数，如果set是空或者key不存在返回0&lt;/p&gt;
&lt;h3 id=&quot;sismember-key-member&quot;&gt;&lt;a href=&quot;#sismember-key-member&quot; class=&quot;headerlink&quot; title=&quot;sismember key member&quot;&gt;&lt;/a&gt;sismember key member&lt;/h3&gt;&lt;p&gt;判断member是否在set中，存在返回1，不存在或者key不存在返回0&lt;/p&gt;
&lt;h3 id=&quot;sinter-key1-key2-…-keyN&quot;&gt;&lt;a href=&quot;#sinter-key1-key2-…-keyN&quot; class=&quot;headerlink&quot; title=&quot;sinter key1 key2 … keyN&quot;&gt;&lt;/a&gt;sinter key1 key2 … keyN&lt;/h3&gt;&lt;p&gt;返回所有给定key的交集&lt;/p&gt;
&lt;h3 id=&quot;sinterstore-dstkey-key1-key2-…-keyN&quot;&gt;&lt;a href=&quot;#sinterstore-dstkey-key1-key2-…-keyN&quot; class=&quot;headerlink&quot; title=&quot;sinterstore dstkey key1 key2 … keyN&quot;&gt;&lt;/a&gt;sinterstore dstkey key1 key2 … keyN&lt;/h3&gt;&lt;p&gt;同sinter，但是同时将交集存到dstkey下&lt;/p&gt;
&lt;h3 id=&quot;sunion-key1-key2-…-keyN&quot;&gt;&lt;a href=&quot;#sunion-key1-key2-…-keyN&quot; class=&quot;headerlink&quot; title=&quot;sunion key1 key2 … keyN&quot;&gt;&lt;/a&gt;sunion key1 key2 … keyN&lt;/h3&gt;&lt;p&gt;返回所有给定key的并集&lt;/p&gt;
&lt;h3 id=&quot;sunionstore-dstkey-key1-key2-…-keyN&quot;&gt;&lt;a href=&quot;#sunionstore-dstkey-key1-key2-…-keyN&quot; class=&quot;headerlink&quot; title=&quot;sunionstore dstkey key1 key2 … keyN&quot;&gt;&lt;/a&gt;sunionstore dstkey key1 key2 … keyN&lt;/h3&gt;&lt;p&gt;同sunion，并同时保存并集到dstkey下&lt;/p&gt;
&lt;h3 id=&quot;sdiff-key1-key2-…-keyN&quot;&gt;&lt;a href=&quot;#sdiff-key1-key2-…-keyN&quot; class=&quot;headerlink&quot; title=&quot;sdiff key1 key2 … keyN&quot;&gt;&lt;/a&gt;sdiff key1 key2 … keyN&lt;/h3&gt;&lt;p&gt;返回所有给定key的差集&lt;/p&gt;
&lt;h3 id=&quot;sdiffstore-dstkey-key1-key2-…-keyN&quot;&gt;&lt;a href=&quot;#sdiffstore-dstkey-key1-key2-…-keyN&quot; class=&quot;headerlink&quot; title=&quot;sdiffstore dstkey key1 key2 … keyN&quot;&gt;&lt;/a&gt;sdiffstore dstkey key1 key2 … keyN&lt;/h3&gt;&lt;p&gt;同sdiff，并同时保存差集到dstkey下&lt;/p&gt;
&lt;h3 id=&quot;smembers-key&quot;&gt;&lt;a href=&quot;#smembers-key&quot; class=&quot;headerlink&quot; title=&quot;smembers key&quot;&gt;&lt;/a&gt;smembers key&lt;/h3&gt;&lt;p&gt;返回key对应set的所有不元素，结果是无序的&lt;/p&gt;
&lt;h2 id=&quot;Sorted-set&quot;&gt;&lt;a href=&quot;#Sorted-set&quot; class=&quot;headerlink&quot; title=&quot;Sorted set&quot;&gt;&lt;/a&gt;Sorted set&lt;/h2&gt;&lt;p&gt;和set一样sorted set也是string类型元素的集合，不同的是每个元素都会关联一个double类型的score。sorted set的实现是skip list和hash table的混合体。当元素被添加到集合中时，一个元素到score的映射被添加到hash table中，另一个score到元素的映射被添加到skip list&lt;br&gt;并按照score排序，所以就可以有序的获取集合中的元素&lt;/p&gt;
&lt;h3 id=&quot;zadd-key-score-member&quot;&gt;&lt;a href=&quot;#zadd-key-score-member&quot; class=&quot;headerlink&quot; title=&quot;zadd key score member&quot;&gt;&lt;/a&gt;zadd key score member&lt;/h3&gt;&lt;p&gt;添加元素到集合，元素在集合中存在则更新对应score&lt;/p&gt;
&lt;h3 id=&quot;zrem-key-member&quot;&gt;&lt;a href=&quot;#zrem-key-member&quot; class=&quot;headerlink&quot; title=&quot;zrem key member&quot;&gt;&lt;/a&gt;zrem key member&lt;/h3&gt;&lt;p&gt;删除指定元素，1表示成功，如果不存在返回0&lt;/p&gt;
&lt;h3 id=&quot;zincrvy-key-incr-member&quot;&gt;&lt;a href=&quot;#zincrvy-key-incr-member&quot; class=&quot;headerlink&quot; title=&quot;zincrvy key incr member&quot;&gt;&lt;/a&gt;zincrvy key incr member&lt;/h3&gt;&lt;p&gt;增加对应的member的score值，然后移动元素并报出skip list有序，返回更新后的score值&lt;/p&gt;
&lt;h3 id=&quot;zrank-key-member&quot;&gt;&lt;a href=&quot;#zrank-key-member&quot; class=&quot;headerlink&quot; title=&quot;zrank key member&quot;&gt;&lt;/a&gt;zrank key member&lt;/h3&gt;&lt;p&gt;返回指定元素在集合中的排名（下标，非score），结合中元素是按score从小到大排序的&lt;/p&gt;
&lt;h3 id=&quot;zrevrank-key-member&quot;&gt;&lt;a href=&quot;#zrevrank-key-member&quot; class=&quot;headerlink&quot; title=&quot;zrevrank key member&quot;&gt;&lt;/a&gt;zrevrank key member&lt;/h3&gt;&lt;p&gt;同上，但是集合中元素是按score从大到小排序&lt;/p&gt;
&lt;h3 id=&quot;zrange-key-start-end&quot;&gt;&lt;a href=&quot;#zrange-key-start-end&quot; class=&quot;headerlink&quot; title=&quot;zrange key start end&quot;&gt;&lt;/a&gt;zrange key start end&lt;/h3&gt;&lt;p&gt;类似zrange操作从集合中取指定区间的元素，返回的是有序的结果&lt;/p&gt;
&lt;h3 id=&quot;zrevrange-key-start-end&quot;&gt;&lt;a href=&quot;#zrevrange-key-start-end&quot; class=&quot;headerlink&quot; title=&quot;zrevrange key start end&quot;&gt;&lt;/a&gt;zrevrange key start end&lt;/h3&gt;&lt;p&gt;同上，返回结果是按score倒序的&lt;/p&gt;
&lt;h3 id=&quot;zrangebyscore-key-min-max&quot;&gt;&lt;a href=&quot;#zrangebyscore-key-min-max&quot; class=&quot;headerlink&quot; title=&quot;zrangebyscore key min max&quot;&gt;&lt;/a&gt;zrangebyscore key min max&lt;/h3&gt;&lt;p&gt;返回集合中score在给定区间的元素&lt;/p&gt;
&lt;h3 id=&quot;zcout-key-min-max&quot;&gt;&lt;a href=&quot;#zcout-key-min-max&quot; class=&quot;headerlink&quot; title=&quot;zcout key min max&quot;&gt;&lt;/a&gt;zcout key min max&lt;/h3&gt;&lt;p&gt;返回集合中score在给定区域间的数量&lt;/p&gt;
&lt;h3 id=&quot;zcard-key&quot;&gt;&lt;a href=&quot;#zcard-key&quot; class=&quot;headerlink&quot; title=&quot;zcard key&quot;&gt;&lt;/a&gt;zcard key&lt;/h3&gt;&lt;p&gt;返回集合中元素的个数&lt;/p&gt;
&lt;h3 id=&quot;zscore-key-element&quot;&gt;&lt;a href=&quot;#zscore-key-element&quot; class=&quot;headerlink&quot; title=&quot;zscore key element&quot;&gt;&lt;/a&gt;zscore key element&lt;/h3&gt;&lt;p&gt;返回给定元素对应的score&lt;/p&gt;
&lt;h3 id=&quot;zremrangebyrank-key-min-max&quot;&gt;&lt;a href=&quot;#zremrangebyrank-key-min-max&quot; class=&quot;headerlink&quot; title=&quot;zremrangebyrank key min max&quot;&gt;&lt;/a&gt;zremrangebyrank key min max&lt;/h3&gt;&lt;p&gt;删除集合中排名在给定区间的元素&lt;/p&gt;
&lt;h3 id=&quot;zremrangebyscore-key-min-max&quot;&gt;&lt;a href=&quot;#zremrangebyscore-key-min-max&quot; class=&quot;headerlink&quot; title=&quot;zremrangebyscore key min max&quot;&gt;&lt;/a&gt;zremrangebyscore key min max&lt;/h3&gt;&lt;p&gt;删除集合中score在给定区间的元素&lt;/p&gt;
&lt;h2 id=&quot;Hash&quot;&gt;&lt;a href=&quot;#Hash&quot; class=&quot;headerlink&quot; title=&quot;Hash&quot;&gt;&lt;/a&gt;Hash&lt;/h2&gt;&lt;p&gt;redis hash是一个string类型的field和value的映射表&lt;br&gt;hash特别适合用于存储对象，相对于将对象的每个字段存在单个string类型。将一个对象存储在hash类型中会占用更少的内存，并且可以更方便的存取整个对象。&lt;/p&gt;
&lt;h2 id=&quot;Hash相关命令&quot;&gt;&lt;a href=&quot;#Hash相关命令&quot; class=&quot;headerlink&quot; title=&quot;Hash相关命令&quot;&gt;&lt;/a&gt;Hash相关命令&lt;/h2&gt;&lt;h3 id=&quot;hset-key-field-value&quot;&gt;&lt;a href=&quot;#hset-key-field-value&quot; class=&quot;headerlink&quot; title=&quot;hset key field value&quot;&gt;&lt;/a&gt;hset key field value&lt;/h3&gt;&lt;h3 id=&quot;hget-key-field&quot;&gt;&lt;a href=&quot;#hget-key-field&quot; class=&quot;headerlink&quot; title=&quot;hget key field&quot;&gt;&lt;/a&gt;hget key field&lt;/h3&gt;&lt;p&gt;设置hash field为指定值，如果key不存在，则先创建&lt;/p&gt;
&lt;h3 id=&quot;hmget-key-field1-field2-…-fieldN&quot;&gt;&lt;a href=&quot;#hmget-key-field1-field2-…-fieldN&quot; class=&quot;headerlink&quot; title=&quot;hmget  key field1 field2 … fieldN&quot;&gt;&lt;/a&gt;hmget  key field1 field2 … fieldN&lt;/h3&gt;&lt;p&gt;获取指定的hash field&lt;/p&gt;
&lt;h3 id=&quot;hmset-key-field1-value1-field2-value2…-fieldN-valueN&quot;&gt;&lt;a href=&quot;#hmset-key-field1-value1-field2-value2…-fieldN-valueN&quot; class=&quot;headerlink&quot; title=&quot;hmset key field1 value1 field2 value2… fieldN valueN&quot;&gt;&lt;/a&gt;hmset key field1 value1 field2 value2… fieldN valueN&lt;/h3&gt;&lt;p&gt;同时设置hash的多个field&lt;/p&gt;
&lt;h3 id=&quot;hincrby-key-field-interger&quot;&gt;&lt;a href=&quot;#hincrby-key-field-interger&quot; class=&quot;headerlink&quot; title=&quot;hincrby key field interger&quot;&gt;&lt;/a&gt;hincrby key field interger&lt;/h3&gt;&lt;p&gt;将指定的hash field加上给定值&lt;/p&gt;
&lt;h3 id=&quot;hexists-key-field&quot;&gt;&lt;a href=&quot;#hexists-key-field&quot; class=&quot;headerlink&quot; title=&quot;hexists key field&quot;&gt;&lt;/a&gt;hexists key field&lt;/h3&gt;&lt;p&gt;测试指定field是否存在&lt;/p&gt;
&lt;h3 id=&quot;hdel-key-field&quot;&gt;&lt;a href=&quot;#hdel-key-field&quot; class=&quot;headerlink&quot; title=&quot;hdel key field&quot;&gt;&lt;/a&gt;hdel key field&lt;/h3&gt;&lt;p&gt;删除指定的hash field&lt;/p&gt;
&lt;h3 id=&quot;hlen-key&quot;&gt;&lt;a href=&quot;#hlen-key&quot; class=&quot;headerlink&quot; title=&quot;hlen key&quot;&gt;&lt;/a&gt;hlen key&lt;/h3&gt;&lt;p&gt;返回指定hash的field&lt;/p&gt;
&lt;h3 id=&quot;hkeys-key&quot;&gt;&lt;a href=&quot;#hkeys-key&quot; class=&quot;headerlink&quot; title=&quot;hkeys key&quot;&gt;&lt;/a&gt;hkeys key&lt;/h3&gt;&lt;p&gt;返回hash的所有field&lt;/p&gt;
&lt;h3 id=&quot;hvals-key&quot;&gt;&lt;a href=&quot;#hvals-key&quot; class=&quot;headerlink&quot; title=&quot;hvals key&quot;&gt;&lt;/a&gt;hvals key&lt;/h3&gt;&lt;p&gt;返回hash的所有value&lt;/p&gt;
&lt;h3 id=&quot;hgetall&quot;&gt;&lt;a href=&quot;#hgetall&quot; class=&quot;headerlink&quot; title=&quot;hgetall&quot;&gt;&lt;/a&gt;hgetall&lt;/h3&gt;&lt;p&gt;返回hash的所有field和value&lt;/p&gt;
&lt;h2 id=&quot;持久化&quot;&gt;&lt;a href=&quot;#持久化&quot; class=&quot;headerlink&quot; title=&quot;持久化&quot;&gt;&lt;/a&gt;持久化&lt;/h2&gt;&lt;p&gt;redis是一个支持持久化的数据库，也就是说redis需要经常将内存中的数据同步到磁盘来保证持久化。这是相对于memcache来说一个大的优势。redis支持两种持久化方式:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Snapshotting(快照)&lt;br&gt;redis的默认持久化方式。这种方式将内存中数据以快照的方式写入到二进制文件中，默认的文件名为dump.rdb。可以配置自动做快照持久化的方式。我们可以配置redis在n秒内如果超过m个key并修改就自动做快照。&lt;/li&gt;
&lt;/ul&gt;
&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;save 900 1  &lt;span class=&quot;comment&quot;&gt;#900秒内如果超过1个key被修改，则发起快照保存&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;save 300 10 &lt;span class=&quot;comment&quot;&gt;#300秒内容如超过10个key被修改，则发起快照保存&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;save 60 10000&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;ul&gt;
&lt;li&gt;Append-only file(AOF)&lt;br&gt;AOF快照方式有更好的持久化性，是由于在使用AOF持久化方式时，redis会将每个收到的写命令都通过write函数追加到文件中（默认是applendonly.aof）。当redis重启时，会通过重新执行文件中保存的写命令来在内存中重建整个数据库的内容。当然由于os会在内核中缓存write做的修改。不过我们可以通过配置文件告诉redis我们想要通过fsync函数强制os写入到磁盘的实际。有三种方式：&lt;/li&gt;
&lt;/ul&gt;
&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;appendonly yes // 启用AOF持久化方式&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;appendfsync always // 每次收到写命令就立即强制写入磁盘，最慢的，但是保证完全的持久化，不推荐使用&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;appendfsync eversec // 每秒强制写入磁盘一次，在性能和持久化方面做了很好的这种，推荐&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;appendfsync no // 完全依赖os，性能最好，持久化没有保证&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h2 id=&quot;主从复制&quot;&gt;&lt;a href=&quot;#主从复制&quot; class=&quot;headerlink&quot; title=&quot;主从复制&quot;&gt;&lt;/a&gt;主从复制&lt;/h2&gt;&lt;p&gt;主从复制允许多个slave server拥有和master server相同的数据库副本。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;master可以有多个slave&lt;/li&gt;
&lt;li&gt;除了多个slave连到相同的master外，slave也可以连接其他slave形成图形结构&lt;/li&gt;
&lt;li&gt;主从复制不会阻塞master。也就是说的那个一个或多个slave与master进行初次同步数据时，master可以继续处理client发来的请求。相求slave在初次同步数据时则会阻塞，不能处理client的请求&lt;/li&gt;
&lt;li&gt;主从复制可以用来提高系统的可伸缩性（可以用多个slave专门用于client的读请求，比如sort操作可以使用slave来处理），也可以用来简单的数据冗余&lt;/li&gt;
&lt;li&gt;可以在master禁用数据出就花，只需要注释掉master配置文件中的所有slave配置，然后只在slave配置数据持久化。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&quot;事物&quot;&gt;&lt;a href=&quot;#事物&quot; class=&quot;headerlink&quot; title=&quot;事物&quot;&gt;&lt;/a&gt;事物&lt;/h2&gt;&lt;p&gt;redis对事物的支持目前还比较简单。redis只能保证一个client发起的事物中的命令可以连续的执行，而中间不会插入其他client的命令&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Multi 事物开始&lt;/li&gt;
&lt;li&gt;Exec  执行事物&lt;/li&gt;
&lt;li&gt;Discard  放弃事物&lt;/li&gt;
&lt;li&gt;Watch  监听key&lt;/li&gt;
&lt;li&gt;Unwatch  放弃所有key的监听&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;watch命令会监事给定的key，当exec时候如果监听的key从调用watch后发生过变化，则整个事物会失败。注意watch的key是对整个连接有效的，和事物一样，如果连接断开，监听和事物都会被自动清除&lt;/p&gt;
&lt;h2 id=&quot;发布订阅（pub-sub）&quot;&gt;&lt;a href=&quot;#发布订阅（pub-sub）&quot; class=&quot;headerlink&quot; title=&quot;发布订阅（pub/sub）&quot;&gt;&lt;/a&gt;发布订阅（pub/sub）&lt;/h2&gt;&lt;p&gt;发布定于是一种消息通信模式。订阅者可以通过subscribe和psubscribe命令向redis server订阅自己感兴趣的消息类型，redis将消息类型成为通道（channel）。当发布者通过publish命令向redis server发送特定类型的消息时。订阅该消息类型的全部client都会收到此消息。这里消息的传递是多对多的。一个client可以订阅多个channel，也可以向多个channel发送消息。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Subscribe&lt;/li&gt;
&lt;li&gt;Unsubscribe&lt;/li&gt;
&lt;li&gt;Psubscribe&lt;/li&gt;
&lt;li&gt;Publish&lt;/li&gt;
&lt;/ul&gt;
</content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;Redis简介&quot;&gt;&lt;a href=&quot;#Redis简介&quot; class=&quot;headerlink&quot; title=&quot;Redis简介&quot;&gt;&lt;/a&gt;Redis简介&lt;/h2&gt;&lt;p&gt;Redis是一款开源的，高性能的键值存储。它常被称为是一款数据结构服务器。Redis的键值可以包含字符串，哈希，列表，集合和有序集合等数据类型。对于这些数据类型，你可以执行原子操作.&lt;br&gt;
    
    </summary>
    
    
      <category term="NoSQL" scheme="http://dxer.github.io/tags/NoSQL/"/>
    
      <category term="redis" scheme="http://dxer.github.io/tags/redis/"/>
    
  </entry>
  
  <entry>
    <title>HBase过滤器总结</title>
    <link href="http://dxer.github.io/2016/06/21/hbase_filter/"/>
    <id>http://dxer.github.io/2016/06/21/hbase_filter/</id>
    <published>2016-06-21T01:25:38.000Z</published>
    <updated>2016-06-21T01:45:58.886Z</updated>
    
    <content type="html">&lt;p&gt;HBase过滤器提供了非常强大的特性来帮助用户提高其处理表中数据的效率。用户不仅可以使用HBase中已经定义好的过滤器，还可以自定义过滤器。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Get和Scan两个类都支持过滤器。&lt;/p&gt;
&lt;p&gt;CompareFilter中的比较运算符&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;操作&lt;/th&gt;
&lt;th&gt;描述&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;LESS&lt;/td&gt;
&lt;td&gt;匹配小于设定值的值&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;LESS_OR_EQUAL&lt;/td&gt;
&lt;td&gt;匹配小于或等于设定值的值&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;EQUAL&lt;/td&gt;
&lt;td&gt;匹配等于设定值的值&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;NOT_EQUAL&lt;/td&gt;
&lt;td&gt;匹配大于设定值不相同的值&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;GREATER_OR_EQUAL&lt;/td&gt;
&lt;td&gt;匹配大于或等于设定值的值&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;GREATER&lt;/td&gt;
&lt;td&gt;匹配大于设定值的值&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;NOT_OP&lt;/td&gt;
&lt;td&gt;排除一切值&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;比较器&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;比较器&lt;/th&gt;
&lt;th&gt;描述&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;BinaryComparator&lt;/td&gt;
&lt;td&gt;使用Bytes.compareTo()比较当前值与阈值&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;BinaryPrefixComparator&lt;/td&gt;
&lt;td&gt;与上面的相似，使用Bytes.compareTo()进行匹配，但是是从左端开始前缀匹配&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;NullComparator&lt;/td&gt;
&lt;td&gt;不做匹配，只判断当前值是不是null&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;BitComparator&lt;/td&gt;
&lt;td&gt;通过BitwiseOp类提供的按位与（AND），或（OR），异或（XOR）操作执行位级比较&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;RegexStringComparator&lt;/td&gt;
&lt;td&gt;根据一个正则表达式，在实例化这个比较器的时候去匹配表中数据&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;SubstringComparator&lt;/td&gt;
&lt;td&gt;把阈值和表中数据当做String实例，同时通过contains()操作匹配字符串&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&quot;比较过滤器&quot;&gt;&lt;a href=&quot;#比较过滤器&quot; class=&quot;headerlink&quot; title=&quot;比较过滤器&quot;&gt;&lt;/a&gt;比较过滤器&lt;/h2&gt;&lt;h3 id=&quot;RowFilter（行过滤器）&quot;&gt;&lt;a href=&quot;#RowFilter（行过滤器）&quot; class=&quot;headerlink&quot; title=&quot;RowFilter（行过滤器）&quot;&gt;&lt;/a&gt;RowFilter（行过滤器）&lt;/h3&gt;&lt;p&gt;行过滤器是基于行键来过滤数据&lt;/p&gt;
&lt;h3 id=&quot;FamilyFilter（列族过滤器）&quot;&gt;&lt;a href=&quot;#FamilyFilter（列族过滤器）&quot; class=&quot;headerlink&quot; title=&quot;FamilyFilter（列族过滤器）&quot;&gt;&lt;/a&gt;FamilyFilter（列族过滤器）&lt;/h3&gt;&lt;p&gt;列族过滤器是基于列族来进行过滤数据&lt;/p&gt;
&lt;h3 id=&quot;QualifierFilter（列名过滤器）&quot;&gt;&lt;a href=&quot;#QualifierFilter（列名过滤器）&quot; class=&quot;headerlink&quot; title=&quot;QualifierFilter（列名过滤器）&quot;&gt;&lt;/a&gt;QualifierFilter（列名过滤器）&lt;/h3&gt;&lt;p&gt;列名过滤器用户筛选特定的列&lt;/p&gt;
&lt;h3 id=&quot;ValueFilter（值过滤器）&quot;&gt;&lt;a href=&quot;#ValueFilter（值过滤器）&quot; class=&quot;headerlink&quot; title=&quot;ValueFilter（值过滤器）&quot;&gt;&lt;/a&gt;ValueFilter（值过滤器）&lt;/h3&gt;&lt;p&gt;值过滤器用户筛选某个特定值的单元格。与RegexStringComparator配合使用，可以使用功能强大的表达式来进行筛选。&lt;/p&gt;
&lt;h3 id=&quot;DependentColumnFilter（参考列过滤器）&quot;&gt;&lt;a href=&quot;#DependentColumnFilter（参考列过滤器）&quot; class=&quot;headerlink&quot; title=&quot;DependentColumnFilter（参考列过滤器）&quot;&gt;&lt;/a&gt;DependentColumnFilter（参考列过滤器）&lt;/h3&gt;&lt;p&gt;参考列过滤器不仅仅简单的通过用户指定的信息筛选数据，还允许用户指定一个参考列或是引用列。并使用参考列控制其他列的过滤。&lt;/p&gt;
&lt;h2 id=&quot;专用过滤器&quot;&gt;&lt;a href=&quot;#专用过滤器&quot; class=&quot;headerlink&quot; title=&quot;专用过滤器&quot;&gt;&lt;/a&gt;专用过滤器&lt;/h2&gt;&lt;h3 id=&quot;SingleColumnValueFilter&quot;&gt;&lt;a href=&quot;#SingleColumnValueFilter&quot; class=&quot;headerlink&quot; title=&quot;SingleColumnValueFilter&quot;&gt;&lt;/a&gt;SingleColumnValueFilter&lt;/h3&gt;&lt;p&gt;用一列的值决定是否一行数据是否被过滤&lt;/p&gt;
&lt;h3 id=&quot;SingleColumnValueExcludeFilter（单列排除过滤器）&quot;&gt;&lt;a href=&quot;#SingleColumnValueExcludeFilter（单列排除过滤器）&quot; class=&quot;headerlink&quot; title=&quot;SingleColumnValueExcludeFilter（单列排除过滤器）&quot;&gt;&lt;/a&gt;SingleColumnValueExcludeFilter（单列排除过滤器）&lt;/h3&gt;&lt;p&gt;该过滤器继承SingleColumnValueFilter，反考烈不会包含在结果中。&lt;/p&gt;
&lt;h3 id=&quot;PrefixFilter（前缀过滤器）&quot;&gt;&lt;a href=&quot;#PrefixFilter（前缀过滤器）&quot; class=&quot;headerlink&quot; title=&quot;PrefixFilter（前缀过滤器）&quot;&gt;&lt;/a&gt;PrefixFilter（前缀过滤器）&lt;/h3&gt;&lt;p&gt;筛选出具有特点前缀的行键的数据。扫描操作以字典序查找，当遇到比前缀大的行时，扫描结束。PrefixFilter对get()方法作用不大。前缀过滤器只针对行键。&lt;/p&gt;
&lt;h3 id=&quot;PageFilter（分页过滤器）&quot;&gt;&lt;a href=&quot;#PageFilter（分页过滤器）&quot; class=&quot;headerlink&quot; title=&quot;PageFilter（分页过滤器）&quot;&gt;&lt;/a&gt;PageFilter（分页过滤器）&lt;/h3&gt;&lt;p&gt;可以使用这个过滤器对结果按行分页。当用户创建PageFilter的实例的时候，指定了pageSize，这个参数可以控制每页返回的行数。&lt;/p&gt;
&lt;h3 id=&quot;KeyOnlyFilter（行键过滤器）&quot;&gt;&lt;a href=&quot;#KeyOnlyFilter（行键过滤器）&quot; class=&quot;headerlink&quot; title=&quot;KeyOnlyFilter（行键过滤器）&quot;&gt;&lt;/a&gt;KeyOnlyFilter（行键过滤器）&lt;/h3&gt;&lt;p&gt;只返回每行的行键，不返回值。对于之关注于行键的应用常见来说非常合适，不返回值，可以减少传递到客户端的数据量，能起到一定的优化作用。&lt;/p&gt;
&lt;h3 id=&quot;FirstKeyOnlyFilter（首次行键过滤器）&quot;&gt;&lt;a href=&quot;#FirstKeyOnlyFilter（首次行键过滤器）&quot; class=&quot;headerlink&quot; title=&quot;FirstKeyOnlyFilter（首次行键过滤器）&quot;&gt;&lt;/a&gt;FirstKeyOnlyFilter（首次行键过滤器）&lt;/h3&gt;&lt;p&gt;只想返回的结果集中只包含第一列的数据&lt;/p&gt;
&lt;h3 id=&quot;InclusiveStopFilter（包含结束的过滤器）&quot;&gt;&lt;a href=&quot;#InclusiveStopFilter（包含结束的过滤器）&quot; class=&quot;headerlink&quot; title=&quot;InclusiveStopFilter（包含结束的过滤器）&quot;&gt;&lt;/a&gt;InclusiveStopFilter（包含结束的过滤器）&lt;/h3&gt;&lt;p&gt;开始行被包含在结果中，单终止行被排除在外，使用这个过滤器，也可以将结束行包含在结果中。&lt;/p&gt;
&lt;h3 id=&quot;TimestampFilter（时间戳过滤器）&quot;&gt;&lt;a href=&quot;#TimestampFilter（时间戳过滤器）&quot; class=&quot;headerlink&quot; title=&quot;TimestampFilter（时间戳过滤器）&quot;&gt;&lt;/a&gt;TimestampFilter（时间戳过滤器）&lt;/h3&gt;&lt;p&gt;使用时间戳过滤器可以对扫描结果中对版本进行细粒度的控制。&lt;/p&gt;
&lt;h3 id=&quot;ColumnCountGetFilter（列计数过滤器）&quot;&gt;&lt;a href=&quot;#ColumnCountGetFilter（列计数过滤器）&quot; class=&quot;headerlink&quot; title=&quot;ColumnCountGetFilter（列计数过滤器）&quot;&gt;&lt;/a&gt;ColumnCountGetFilter（列计数过滤器）&lt;/h3&gt;&lt;p&gt;确定每行最多返回多少列，并在遇到一定的列数超过我们锁设置的限制值的时候，结束扫描操作&lt;/p&gt;
&lt;h3 id=&quot;ColumnPaginationFilter（列分页过滤器）&quot;&gt;&lt;a href=&quot;#ColumnPaginationFilter（列分页过滤器）&quot; class=&quot;headerlink&quot; title=&quot;ColumnPaginationFilter（列分页过滤器）&quot;&gt;&lt;/a&gt;ColumnPaginationFilter（列分页过滤器）&lt;/h3&gt;&lt;p&gt;与PageFilter类似，列分页过滤器可以对一行的所有列进行分页。&lt;/p&gt;
&lt;h3 id=&quot;ColumnPrefixFilter（列前缀过滤器）&quot;&gt;&lt;a href=&quot;#ColumnPrefixFilter（列前缀过滤器）&quot; class=&quot;headerlink&quot; title=&quot;ColumnPrefixFilter（列前缀过滤器）&quot;&gt;&lt;/a&gt;ColumnPrefixFilter（列前缀过滤器）&lt;/h3&gt;&lt;p&gt;类似PrefixFilter，列前缀过滤器通过对列名进行前缀匹配过滤&lt;/p&gt;
&lt;h3 id=&quot;RandomRowFilter（随机行过滤器）&quot;&gt;&lt;a href=&quot;#RandomRowFilter（随机行过滤器）&quot; class=&quot;headerlink&quot; title=&quot;RandomRowFilter（随机行过滤器）&quot;&gt;&lt;/a&gt;RandomRowFilter（随机行过滤器）&lt;/h3&gt;&lt;p&gt;随机行过滤器可以让结果中包含随机行。&lt;/p&gt;
&lt;h2 id=&quot;附加过滤器&quot;&gt;&lt;a href=&quot;#附加过滤器&quot; class=&quot;headerlink&quot; title=&quot;附加过滤器&quot;&gt;&lt;/a&gt;附加过滤器&lt;/h2&gt;&lt;h3 id=&quot;SkipFilter（跳转过滤器）&quot;&gt;&lt;a href=&quot;#SkipFilter（跳转过滤器）&quot; class=&quot;headerlink&quot; title=&quot;SkipFilter（跳转过滤器）&quot;&gt;&lt;/a&gt;SkipFilter（跳转过滤器）&lt;/h3&gt;&lt;p&gt;与ValueFilter结合使用，如果发现一行中的某一列不符合条件，那么整行都会被过滤掉。&lt;/p&gt;
&lt;h3 id=&quot;WhileMatchFilter（全匹配过滤器）&quot;&gt;&lt;a href=&quot;#WhileMatchFilter（全匹配过滤器）&quot; class=&quot;headerlink&quot; title=&quot;WhileMatchFilter（全匹配过滤器）&quot;&gt;&lt;/a&gt;WhileMatchFilter（全匹配过滤器）&lt;/h3&gt;&lt;p&gt;如果你想想要在遇到某种条件数据之前的数据时，就可以使用这个过滤器，当遇到不符合设定条件的数据的时候，整个扫描也结束了。&lt;/p&gt;
&lt;h2 id=&quot;自定义过滤器&quot;&gt;&lt;a href=&quot;#自定义过滤器&quot; class=&quot;headerlink&quot; title=&quot;自定义过滤器&quot;&gt;&lt;/a&gt;自定义过滤器&lt;/h2&gt;&lt;p&gt;可以通过实现Filter接口或者直接竭诚FilterBase类来实现自定义过滤器。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;HBase过滤器提供了非常强大的特性来帮助用户提高其处理表中数据的效率。用户不仅可以使用HBase中已经定义好的过滤器，还可以自定义过滤器。&lt;br&gt;
    
    </summary>
    
    
      <category term="hbase" scheme="http://dxer.github.io/tags/hbase/"/>
    
  </entry>
  
  <entry>
    <title>HBase协处理器</title>
    <link href="http://dxer.github.io/2016/06/20/hbase_coprocessor/"/>
    <id>http://dxer.github.io/2016/06/20/hbase_coprocessor/</id>
    <published>2016-06-20T14:25:38.000Z</published>
    <updated>2016-06-21T01:47:05.185Z</updated>
    
    <content type="html">&lt;p&gt;使用Scan的时候，可以配合各种Filter进行数据的筛选以减少返回的数据量，同样也可以通过选择特定的列族和列来减少返回的数据量。若是能将该特性进一步的优化则HBase会更强大。HBase在0.92版本后引入了协处理器来实现该功能。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;协处理器允许用户在region服务器上运行自己的代码，更准确的说是允许用户执行region级的操作，并且可以使用与RDBMS中的触发器类似的功能。在客户端，用户不用关系操作具体在哪里执行，HBase的分布式框架会帮助用户把这些工作变得透明。有点类似MapReduce。&lt;/p&gt;
&lt;p&gt;使用协处理器的好处显而易见，可以将运算放到server端，减少通信开销的同时还能有效的提升性能。&lt;/p&gt;
&lt;p&gt;协处理的两种类型&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;系统协处理器：可以全局导入region server上的所有数据表&lt;/li&gt;
&lt;li&gt;表协处理器：用户可以指定一张表使用协处理器&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;协处理器框架为了更好支持其行为的灵活性，提供了两个不同方面的插件。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;观察者（observer），类似于关系数据库的触发器（主动触发），在一些特定事件发生的时候被执行。这些时间包括一些用户产生的事件，也包括服务器端内部产生的事件。&lt;/li&gt;
&lt;li&gt;终端（endpoint），动态的终端有点像存储过程。除了事件处理之外还需要将用户自定义操作添加到服务器端。用户代码可以被部署到管理数据的服务器端。endpoint通过添加一些远程调用来扩展RPC协议。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;Observer&quot;&gt;&lt;a href=&quot;#Observer&quot; class=&quot;headerlink&quot; title=&quot;Observer&quot;&gt;&lt;/a&gt;Observer&lt;/h2&gt;&lt;p&gt;观察者的设计意图是允许用户通过插入代码来重载协处理器框架的&lt;code&gt;upcall&lt;/code&gt;方法，而具体的事情触发的&lt;code&gt;callback&lt;/code&gt;方法由HBase的核心代码来指定。协处理器框架处理所有的&lt;code&gt;callback&lt;/code&gt;调用细节，协处理器自身只需要插入添加或者改变的功能。&lt;/p&gt;
&lt;p&gt;Observer提供的接口：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;RegionObserver：提供客户端的数据操作时间钩子：Get、Put、Delete和Scan等&lt;/li&gt;
&lt;li&gt;WALObserver：提供WAL相关操作钩子&lt;/li&gt;
&lt;li&gt;MasterObserver：提供DDL类型的操作钩子，如创建、删除、修改数据表等。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这些接口可以同时使用在同一个地方，按照不同的优先级顺序执行，用户可以任意基于协处理器实现负责的HBase功能层，HBase有很多种时间可以出发观察者方法，这些事件与方法从HBase0.92版本起，都会集成在HBase中。不过这些API可能会由于各种原因有所改动，不同版本的接口改动比较大。&lt;/p&gt;
&lt;h2 id=&quot;endpoint&quot;&gt;&lt;a href=&quot;#endpoint&quot; class=&quot;headerlink&quot; title=&quot;endpoint&quot;&gt;&lt;/a&gt;endpoint&lt;/h2&gt;&lt;p&gt;endpoint是HBase的一种通用扩展。当endpoint安装在集群上时，它扩展了HBase的RPC协议，对客户端应用开放了新方法。就像observer一样，endpoint在RegiionServer上执行，紧挨着你的数据。&lt;/p&gt;
&lt;p&gt;endpoint协处理类似于其他数据库引擎中的存储过程。从客户端看，调用一个endpoint协处理器类似于调用其他HBase命令，只是其功能建立在定义协处理器的定制代码上，通常先创建请求对象，然后把它传给HtableInterface在集群上执行，最后收集结果。&lt;/p&gt;
&lt;p&gt;单个region&lt;br&gt;单个行键调用coprocessorProxy()。返回一个CoprocessorProtocol接口的动态代理，它使用包含给定行键的region作为RPC endpoint，即使给空行键鬼影的行不存在也不影响。&lt;/p&gt;
&lt;p&gt;一段范围的region&lt;br&gt;通过起始行键和终止行键调用coprocessorExec()。表中包含在起始行键到终止行键范围内的所有region都将作为RPCendpoint&lt;/p&gt;
&lt;h3 id=&quot;实现一个endpoint的步骤&quot;&gt;&lt;a href=&quot;#实现一个endpoint的步骤&quot; class=&quot;headerlink&quot; title=&quot;实现一个endpoint的步骤&quot;&gt;&lt;/a&gt;实现一个endpoint的步骤&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;扩展CoprocessorProtlcol接口&lt;br&gt;这一步将设定与新endpoint的通信细节，即定义了客户端和服务店的RPC协议&lt;/li&gt;
&lt;li&gt;扩展BaseEndpointCoprocessor类&lt;br&gt;用户必须实现endpoint设计的方法，包括抽象类BaseEndpointCoprocessor，以及之前定义的endpoint协议接口&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&quot;协处理器的配置方法&quot;&gt;&lt;a href=&quot;#协处理器的配置方法&quot; class=&quot;headerlink&quot; title=&quot;协处理器的配置方法&quot;&gt;&lt;/a&gt;协处理器的配置方法&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;启用全局aggregation，能操作所有表上的数据，通过修改hbase-site.xml配置文件实现，添加如下示例代码：&lt;/li&gt;
&lt;/ul&gt;
&lt;figure class=&quot;highlight xml&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;property&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;name&lt;/span&gt;&amp;gt;&lt;/span&gt;hbase.coprocessor,user.region.classes&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;name&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;value&lt;/span&gt;&amp;gt;&lt;/span&gt;org.apache.hadoop.hbase.coprocessor.RowCountEndPoint&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;value&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;property&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;ul&gt;
&lt;li&gt;启用表aggregation，只对特定的表生效。通过HBase shell来实现&lt;/li&gt;
&lt;/ul&gt;
&lt;figure class=&quot;highlight xml&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1.disable指定表&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2.添加aggregation: alter &#39;test&#39;, METHOD=&amp;gt;&#39;table_att&#39;, &#39;coprocessor1&#39;=&amp;gt;&#39;|org.acache/hadoop.coprocessor.RowCountEndPoint||&#39;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3.重启指定表： enable &#39;test&#39;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;协处理器配置格式&lt;br&gt;以”|”分割的几个属性&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;file path文件路径&lt;/li&gt;
&lt;li&gt;classname协处理器的类名&lt;/li&gt;
&lt;li&gt;priorty优先级&lt;/li&gt;
&lt;li&gt;arguments参数&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;API调用&lt;/li&gt;
&lt;/ul&gt;
&lt;figure class=&quot;highlight java&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;HTableDescriptor htd = &lt;span class=&quot;keyword&quot;&gt;new&lt;/span&gt; HTableDescriptor(&lt;span class=&quot;string&quot;&gt;&quot;test&quot;&lt;/span&gt;);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;htd.setValue(&lt;span class=&quot;string&quot;&gt;&quot;COPROCESSOR$1&quot;&lt;/span&gt;, path.toString() + &lt;span class=&quot;string&quot;&gt;&quot;|&quot;&lt;/span&gt; + RowCountEndpoint.class.getCanonicalName() + &lt;span class=&quot;string&quot;&gt;&quot;|&quot;&lt;/span&gt; +&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;                                      Coprocessor.PRIORITY_USER);&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;协处理器配置的加载顺序：先加载配置文件中定义的协处理器，后加载表描述符中的协处理器&lt;/p&gt;
&lt;p&gt;COPROCESSOR$&lt;number&gt;中的number定义了加载顺序&lt;/number&gt;&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;使用Scan的时候，可以配合各种Filter进行数据的筛选以减少返回的数据量，同样也可以通过选择特定的列族和列来减少返回的数据量。若是能将该特性进一步的优化则HBase会更强大。HBase在0.92版本后引入了协处理器来实现该功能。&lt;br&gt;
    
    </summary>
    
    
      <category term="hbase" scheme="http://dxer.github.io/tags/hbase/"/>
    
  </entry>
  
  <entry>
    <title>HBase的RowKey设计</title>
    <link href="http://dxer.github.io/2016/06/16/hbase_rowkey/"/>
    <id>http://dxer.github.io/2016/06/16/hbase_rowkey/</id>
    <published>2016-06-16T11:25:38.000Z</published>
    <updated>2016-06-17T09:22:55.394Z</updated>
    
    <content type="html">&lt;p&gt;HBase是三维有序存储的，通过rowkey（行键），column key（column family和qualifier）和TimeStamp（时间戳）这个三个维度可以对HBase中的数据进行快速定位。&lt;/p&gt;
&lt;p&gt;HBase中rowkey可以唯一标识一行记录，在HBase查询的时候，有两种方式：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;通过get方式，指定rowkey获取唯一一条记录&lt;/li&gt;
&lt;li&gt;通过scan方式，设置startRow和stopRow参数进行范围匹配&lt;/li&gt;
&lt;li&gt;全表扫描，即直接扫描整张表中所有行记录&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&quot;rowkey长度原则&quot;&gt;&lt;a href=&quot;#rowkey长度原则&quot; class=&quot;headerlink&quot; title=&quot;rowkey长度原则&quot;&gt;&lt;/a&gt;rowkey长度原则&lt;/h2&gt;&lt;p&gt;rowkey是一个二进制码流，可以是任意字符串，最大长度&lt;em&gt;64kb&lt;/em&gt;，实际应用中一般为10-100bytes，以&lt;code&gt;byte[]&lt;/code&gt;形式保存，一般设计成定长。&lt;br&gt;建议越短越好，不要超过16个字节，原因如下：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;数据的持久化文件HFile中是按照KeyValue存储的，如果rowkey过长，比如超过100字节，1000w行数据，光rowkey就要占用100*1000w=10亿个字节，将近1G数据，这样会极大影响HFile的存储效率；&lt;/li&gt;
&lt;li&gt;MemStore将缓存部分数据到内存，如果rowkey字段过长，内存的有效利用率就会降低，系统不能缓存更多的数据，这样会降低检索效率。&lt;/li&gt;
&lt;li&gt;目前操作系统都是64位系统，内存8字节对齐，控制在16个字节，8字节的整数倍利用了操作系统的最佳特性。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&quot;rowkey散列原则&quot;&gt;&lt;a href=&quot;#rowkey散列原则&quot; class=&quot;headerlink&quot; title=&quot;rowkey散列原则&quot;&gt;&lt;/a&gt;rowkey散列原则&lt;/h2&gt;&lt;p&gt;如果rowkey按照时间戳的方式递增，不要将时间放在二进制码的前面，建议将rowkey的高位作为散列字段，由程序随机生成，低位放时间字段，这样将提高数据均衡分布在每个RegionServer，以实现负载均衡的几率。如果没有散列字段，首字段直接是时间信息，所有的数据都会集中在一个RegionServer上，这样在数据检索的时候负载会集中在个别的RegionServer上，造成热点问题，会降低查询效率。&lt;/p&gt;
&lt;h2 id=&quot;rowkey唯一原则&quot;&gt;&lt;a href=&quot;#rowkey唯一原则&quot; class=&quot;headerlink&quot; title=&quot;rowkey唯一原则&quot;&gt;&lt;/a&gt;rowkey唯一原则&lt;/h2&gt;&lt;p&gt;必须在设计上保证其唯一性，rowkey是按照字典顺序排序存储的，因此，设计rowkey的时候，要充分利用这个排序的特点，将经常读取的数据存储到一块，将最近可能会被访问的数据放到一块。&lt;/p&gt;
&lt;h2 id=&quot;什么是热点&quot;&gt;&lt;a href=&quot;#什么是热点&quot; class=&quot;headerlink&quot; title=&quot;什么是热点&quot;&gt;&lt;/a&gt;什么是热点&lt;/h2&gt;&lt;p&gt;HBase中的行是按照rowkey的字典顺序排序的，这种设计优化了scan操作，可以将相关的行以及会被一起读取的行存取在临近位置，便于scan。然而糟糕的rowkey设计是热点的源头。&lt;strong&gt;热点发生在大量的client直接访问集群的一个或极少数个节点（访问可能是读，写或者其他操作）。大量访问会使热点region所在的单个机器超出自身承受能力，引起性能下降甚至region不可用，这也会影响同一个RegionServer上的其他region，由于主机无法服务其他region的请求。&lt;/strong&gt;设计良好的数据访问模式以使集群被充分，均衡的利用。&lt;/p&gt;
&lt;p&gt;为了避免写热点，设计rowkey使得不同行在同一个region，但是在更多数据情况下，数据应该被写入集群的多个region，而不是一个。&lt;/p&gt;
&lt;p&gt;下面是一些常见的避免热点的方法以及它们的优缺点：&lt;/p&gt;
&lt;h4 id=&quot;加盐&quot;&gt;&lt;a href=&quot;#加盐&quot; class=&quot;headerlink&quot; title=&quot;加盐&quot;&gt;&lt;/a&gt;加盐&lt;/h4&gt;&lt;p&gt;这里所说的加盐不是密码学中的加盐，而是在rowkey的前面增加随机数，具体就是给rowkey分配一个随机前缀以使得它和之前的rowkey的开头不同。分配的前缀种类数量应该和你想使用数据分散到不同的region的数量一致。加盐之后的rowkey就会根据随机生成的前缀分散到各个region上，以避免热点。&lt;/p&gt;
&lt;h4 id=&quot;哈希&quot;&gt;&lt;a href=&quot;#哈希&quot; class=&quot;headerlink&quot; title=&quot;哈希&quot;&gt;&lt;/a&gt;哈希&lt;/h4&gt;&lt;p&gt;哈希会使同一行永远用一个前缀加盐。哈希也可以使负载分散到整个集群，但是读却是可以预测的。使用确定的哈希可以让客户端重构完整的rowkey，可以使用get操作准确获取某一个行数据&lt;/p&gt;
&lt;h4 id=&quot;反转&quot;&gt;&lt;a href=&quot;#反转&quot; class=&quot;headerlink&quot; title=&quot;反转&quot;&gt;&lt;/a&gt;反转&lt;/h4&gt;&lt;p&gt;第三种防止热点的方法时反转固定长度或者数字格式的rowkey。这样可以使得rowkey中经常改变的部分（最没有意义的部分）放在前面。这样可以有效的随机rowkey，但是牺牲了rowkey的有序性。&lt;/p&gt;
&lt;p&gt;反转rowkey的例子&lt;br&gt;以手机号为rowkey，可以将手机号反转后的字符串作为rowkey，这样的就避免了以手机号那样比较固定开头导致热点问题&lt;/p&gt;
&lt;h4 id=&quot;时间戳反转&quot;&gt;&lt;a href=&quot;#时间戳反转&quot; class=&quot;headerlink&quot; title=&quot;时间戳反转&quot;&gt;&lt;/a&gt;时间戳反转&lt;/h4&gt;&lt;p&gt;一个常见的数据处理问题是快速获取数据的最近版本，使用反转的时间戳作为rowkey的一部分对这个问题十分有用，可以用&lt;code&gt;Long.Max_Value - timestamp&lt;/code&gt;追加到key的末尾，例如&lt;code&gt;[key][reverse_timestamp]&lt;/code&gt;,&lt;code&gt;[key]&lt;/code&gt;的最新值可以通过scan [key]获得[key]的第一条记录，因为HBase中rowkey是有序的，第一条记录是最后录入的数据。&lt;/p&gt;
&lt;p&gt;比如需要保存一个用户的操作记录，按照操作时间倒序排序，在设计rowkey的时候，可以这样设计&lt;br&gt;[userId反转][Long.Max_Value - timestamp]，在查询用户的所有操作记录数据的时候，直接指定反转后的userId，startRow是[userId反转][000000000000],stopRow是[userId反转][Long.Max_Value - timestamp]&lt;br&gt;如果需要查询某段时间的操作记录，startRow是[user反转][Long.Max_Value - 起始时间]，stopRow是[userId反转][Long.Max_Value - 结束时间]&lt;/p&gt;
&lt;p&gt;其他一些建议&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;尽量减少行和列的大小&lt;br&gt;在HBase中，value永远和它的key一起传输的。当具体的值在系统间传输时，它的rowkey，列名，时间戳也会一起传输。如果你的rowkey和列名很大，甚至可以和具体的值相比较，那么你将会遇到一些有趣的问题。HBase storefiles中的索引（有助于随机访问）最终占据了HBase分配的大量内存，因为具体的值和它的key很大。可以增加block大小使得storefiles索引再更大的时间间隔增加，或者修改表的模式以减小rowkey和列名的大小。压缩也有助于更大的索引。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;列族尽可能越短越好，最好是一个字符&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;冗长的属性名虽然可读性好，但是更短的属性名存储在HBase中会更好&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;HBase是三维有序存储的，通过rowkey（行键），column key（column family和qualifier）和TimeStamp（时间戳）这个三个维度可以对HBase中的数据进行快速定位。&lt;/p&gt;
&lt;p&gt;HBase中rowkey可以唯一标识一行记录，在HBase查询的时候，有两种方式：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;通过get方式，指定rowkey获取唯一一条记录&lt;/li&gt;
&lt;li&gt;通过scan方式，设置startRow和stopRow参数进行范围匹配&lt;/li&gt;
&lt;li&gt;全表扫描，即直接扫描整张表中所有行记录
    
    </summary>
    
    
      <category term="hbase" scheme="http://dxer.github.io/tags/hbase/"/>
    
  </entry>
  
  <entry>
    <title>分布式文件系统FastDFS快速入门</title>
    <link href="http://dxer.github.io/2016/06/15/fastdfs/"/>
    <id>http://dxer.github.io/2016/06/15/fastdfs/</id>
    <published>2016-06-15T06:38:19.000Z</published>
    <updated>2016-06-17T03:57:00.438Z</updated>
    
    <content type="html">&lt;h2 id=&quot;什么是FastDFS？&quot;&gt;&lt;a href=&quot;#什么是FastDFS？&quot; class=&quot;headerlink&quot; title=&quot;什么是FastDFS？&quot;&gt;&lt;/a&gt;什么是FastDFS？&lt;/h2&gt;&lt;p&gt;FastDFS是一个开源的轻量级分布式文件系统。它解决了大数据量存储和负载均衡等问题。特别适合以中小文件（建议范围：4KB &amp;lt; file_size &lt;500mb）为载体的在线服务，如相册网站、视频网站等等。 &lt;a=&quot;&quot; id=&quot;more&quot;&gt;&lt;/500mb）为载体的在线服务，如相册网站、视频网站等等。&gt;&lt;/p&gt;
&lt;h2 id=&quot;FastDFS架构&quot;&gt;&lt;a href=&quot;#FastDFS架构&quot; class=&quot;headerlink&quot; title=&quot;FastDFS架构&quot;&gt;&lt;/a&gt;FastDFS架构&lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;/pic/20160615/FastDFS架构图1.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;从上图可知，FastDFS架构中有三个角色：&lt;strong&gt;跟踪服务器（tracker server）&lt;/strong&gt;、&lt;strong&gt;存储服务器（storage server）
&lt;/strong&gt;和&lt;strong&gt;客户端（client）&lt;/strong&gt;。&lt;/p&gt;
&lt;h3 id=&quot;tracker-server&quot;&gt;&lt;a href=&quot;#tracker-server&quot; class=&quot;headerlink&quot; title=&quot;tracker server&quot;&gt;&lt;/a&gt;tracker server&lt;/h3&gt;&lt;p&gt;跟踪服务器，主要做调度工作，起负载均衡的作用。负责管理所有的storage server和group，每个storage在启动后会连接tracker，告诉tracker自己所属的group，并保持周期性心跳，tracker根据storage的心跳信息，建立&lt;group，storage server=&quot;&quot;&gt;映射表，tracke管理的元数据很少（tracker上的元数据都是由storage汇报产生），并且直接存在内存中，本身不需要持久化任何数据。tracker之间是对等的，因此扩展tracker是很容易的，直接增加tracker服务，同时修改storage的配置，增加新增的tarcker服务的地址和端口，重启即可。所有的tracker都会接受storage的心跳信息，以生成元数据信息。&lt;/group，storage&gt;&lt;/p&gt;
&lt;h3 id=&quot;storage-server&quot;&gt;&lt;a href=&quot;#storage-server&quot; class=&quot;headerlink&quot; title=&quot;storage server&quot;&gt;&lt;/a&gt;storage server&lt;/h3&gt;&lt;p&gt;存储服务器（又称：存储节点或数据服务器），顾名思义是用来保存文件的和文件属性的。以group为单位，每个group内可以包含多台storage server，数据互为备份，存储容量空间以group中storage server容量最小的为准。以group为单位组织存储能够方便的进行应用隔离、负责均衡和副本数定制；确定是group的容量受单机容量的限制。group内机器故障，需要依赖group内其他机器重新同步数据来恢复数据（更换坏盘，重启fdfs_storaged即可）。storage存储依赖本地文件系统，storage课配置多个数据存储目录，磁盘不做raid，直接分别挂在到多个目录，将这些目录配置为storage的数据目录即可。&lt;/p&gt;
&lt;p&gt;storage接收写请求的时候，会根据配置好的规则，选择其中一个存储目录来存储文件；为了避免单个目录下的文件过多，storage第一次启动的时候，会在每个数据存储目录创建2级子目录，每级256，总共65536个目录，新写的文件会以hash的方式路由到其中一个子目录下，然后将文件数据直接作为一个本地文件存储。&lt;/p&gt;
&lt;h3 id=&quot;client&quot;&gt;&lt;a href=&quot;#client&quot; class=&quot;headerlink&quot; title=&quot;client&quot;&gt;&lt;/a&gt;client&lt;/h3&gt;&lt;p&gt;客户端，作为业务请求的发起方，通过专有接口，使用TCP/IP协议与跟踪器服务器或存储节点进行数据交互。&lt;/p&gt;
&lt;h2 id=&quot;FastDFS的工作流程&quot;&gt;&lt;a href=&quot;#FastDFS的工作流程&quot; class=&quot;headerlink&quot; title=&quot;FastDFS的工作流程&quot;&gt;&lt;/a&gt;FastDFS的工作流程&lt;/h2&gt;&lt;h3 id=&quot;文件上传&quot;&gt;&lt;a href=&quot;#文件上传&quot; class=&quot;headerlink&quot; title=&quot;文件上传&quot;&gt;&lt;/a&gt;文件上传&lt;/h3&gt;&lt;p&gt;&lt;img src=&quot;/pic/20160615/fastdfs_upload.jpg&quot; alt=&quot;文件上传&quot;&gt;&lt;/p&gt;
&lt;p&gt;上传的流程：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;client询问tracker上传到的storage&lt;/li&gt;
&lt;li&gt;tracker返回一台可用的storage&lt;/li&gt;
&lt;li&gt;client直接和storage通信，完成文件上传&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&quot;选择tracker-server&quot;&gt;&lt;a href=&quot;#选择tracker-server&quot; class=&quot;headerlink&quot; title=&quot;选择tracker server&quot;&gt;&lt;/a&gt;选择tracker server&lt;/h4&gt;&lt;p&gt;集群中tracker之间是对等关系，client在上传文件时可以使用任意一个tracker&lt;/p&gt;
&lt;h4 id=&quot;选择存储group&quot;&gt;&lt;a href=&quot;#选择存储group&quot; class=&quot;headerlink&quot; title=&quot;选择存储group&quot;&gt;&lt;/a&gt;选择存储group&lt;/h4&gt;&lt;p&gt;当tracker接收到上传文件的请求的时候，会为该文件分配一个可以存储的group。目前支持选择的group的规则有：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Round robin，轮询&lt;/li&gt;
&lt;li&gt;Sepcified group，上传的时候指定某个group&lt;/li&gt;
&lt;li&gt;Load balance，生成存储空间较多的group优先&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&quot;选择storage-server&quot;&gt;&lt;a href=&quot;#选择storage-server&quot; class=&quot;headerlink&quot; title=&quot;选择storage server&quot;&gt;&lt;/a&gt;选择storage server&lt;/h4&gt;&lt;p&gt;当选定group后，tracker会在group内选择一个storage server给client，目前支持选择server的规则有：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Round robin，轮询（默认）&lt;/li&gt;
&lt;li&gt;根据IP地址进行排序，选择第一个服务器（IP地址最小者）&lt;/li&gt;
&lt;li&gt;根据优先级进行排序，上传优先级由storage server来设置，参数为uoload_priority&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&quot;选择storage-path&quot;&gt;&lt;a href=&quot;#选择storage-path&quot; class=&quot;headerlink&quot; title=&quot;选择storage path&quot;&gt;&lt;/a&gt;选择storage path&lt;/h4&gt;&lt;p&gt;当分配好storage server后，客户端将向storage发送写文件请求，storage会将文件分配一个数据存储目录，目前支持选择存储路径选择的规则有：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Round robin，轮询（默认）&lt;/li&gt;
&lt;li&gt;load balance，选择使用剩余空间最大的存储路径&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&quot;生成file-id&quot;&gt;&lt;a href=&quot;#生成file-id&quot; class=&quot;headerlink&quot; title=&quot;生成file id&quot;&gt;&lt;/a&gt;生成file id&lt;/h4&gt;&lt;p&gt;选择存储目录之后，storage会生成一个file_id，采用base64编码，包含有：storage server ip，文件创建时间，文件大小，文件CRC32校验码和随机数。每个存储目录下有两个256*256个子目录，storage会按文件file_id进行两次hash，路由到其中一个子目录，然后将文件以file_id为名字存储。&lt;br&gt;文件路径如下：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;group0/M00/00/02/exwf8b8lFJIxx2234841AAAbpQt7xVI473456.txt&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;组名：group0   磁盘： M00   目录：00/02   文件名：exwf8b8lFJIxx2234841AAAbpQt7xVI473456.txt&lt;/p&gt;
&lt;p&gt;文件索引信息包括：&lt;strong&gt;组名，虚拟磁盘路径，数据两级目录，文件名&lt;/strong&gt;。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;组名：&lt;/strong&gt;文件上传后所在的存储组名称，在文件上传成功后有存储服务器返回，需要客户端自行保存。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;虚拟磁盘路径：&lt;/strong&gt;存储服务器配置的虚拟路径，与磁盘选项store_path*对应。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;数据两级目录：&lt;/strong&gt;存储服务器在每个虚拟磁盘路径下创建的两级目录，用于存储数据文件。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;文件名：与文件上传时不同。&lt;/strong&gt;是由存储服务器根据特定信息生成，文件名包含：源存储服务器IP地址、文件创建时间戳、文件大小、随机数和文件拓展名等信息。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;文件下载&quot;&gt;&lt;a href=&quot;#文件下载&quot; class=&quot;headerlink&quot; title=&quot;文件下载&quot;&gt;&lt;/a&gt;文件下载&lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;/pic/20160615/fastdfs_download.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;文件下载流程：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;client询问tracker要下载文件的所在的storage，参数为文件标识（group,文件名）&lt;/li&gt;
&lt;li&gt;tracker返回一台可用的storage&lt;/li&gt;
&lt;li&gt;client直接和storage通信，下载文件&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;client发送下载某个文件的请求到某个tracker，tracker从文件名中解析出文件的group，文件大小，创建时间等信息，然后为该请求选择一个storage用于读请求&lt;/p&gt;
&lt;h4 id=&quot;选择下载服务器&quot;&gt;&lt;a href=&quot;#选择下载服务器&quot; class=&quot;headerlink&quot; title=&quot;选择下载服务器&quot;&gt;&lt;/a&gt;选择下载服务器&lt;/h4&gt;&lt;p&gt;目前支持的规则有：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;轮询方式，可以下载当前文件的任意一个storage server&lt;/li&gt;
&lt;li&gt;从源storage server下载&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&quot;同步时间管理&quot;&gt;&lt;a href=&quot;#同步时间管理&quot; class=&quot;headerlink&quot; title=&quot;同步时间管理&quot;&gt;&lt;/a&gt;同步时间管理&lt;/h2&gt;&lt;p&gt;当一个文件上传成功后，客户端马上发起对该文件下载请求（或删除请求）时，tracker是如何选定一个适用的存储服务器呢？&lt;/p&gt;
&lt;p&gt;其实每个存储服务器都需要定时将自身的信息上报给tracker，这些信息就包括了本地同步时间（即，同步到的最新文件的时间戳）。而tracker根据各个存储服务器的上报情况，就能够知道刚刚上传的文件，在该存储组中是否已完成了同步。&lt;/p&gt;
&lt;h2 id=&quot;快速定位文件&quot;&gt;&lt;a href=&quot;#快速定位文件&quot; class=&quot;headerlink&quot; title=&quot;快速定位文件&quot;&gt;&lt;/a&gt;快速定位文件&lt;/h2&gt;&lt;p&gt;知道FastDFS FID的组成后，我们来看看FastDFS是如何通过这个精巧的FID定位到需要访问的文件。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;通过组名tracker能够很快的定位到客户端需要访问的存储服务器组，并将选择合适的存储服务器提供客户端访问；&lt;/li&gt;
&lt;li&gt;存储服务器根据“文件存储虚拟磁盘路径”和“数据文件两级目录”可以很快定位到文件所在目录，并根据文件名找到客户端需要访问的文件。&lt;/li&gt;
&lt;/ol&gt;
</content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;什么是FastDFS？&quot;&gt;&lt;a href=&quot;#什么是FastDFS？&quot; class=&quot;headerlink&quot; title=&quot;什么是FastDFS？&quot;&gt;&lt;/a&gt;什么是FastDFS？&lt;/h2&gt;&lt;p&gt;FastDFS是一个开源的轻量级分布式文件系统。它解决了大数据量存储和负载均衡等问题。特别适合以中小文件（建议范围：4KB &amp;lt; file_size &lt;500MB）为载体的在线服务，如相册网站、视频网站等等。
    
    </summary>
    
    
      <category term="fastdfs" scheme="http://dxer.github.io/tags/fastdfs/"/>
    
  </entry>
  
  <entry>
    <title>Hadoop不能加载本地库问题解决</title>
    <link href="http://dxer.github.io/2016/04/05/hadoop_native_lib/"/>
    <id>http://dxer.github.io/2016/04/05/hadoop_native_lib/</id>
    <published>2016-04-05T06:46:19.000Z</published>
    <updated>2016-06-16T05:08:46.951Z</updated>
    
    <content type="html">&lt;p&gt;在执行hadoop命令或者启动dfs、yarn的时候总会出现这个警告&lt;/p&gt;
&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;WARN util.NativeCodeLoader: Unable to load native-hadoop library &lt;span class=&quot;keyword&quot;&gt;for&lt;/span&gt; your platform... &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;using &lt;span class=&quot;built_in&quot;&gt;builtin&lt;/span&gt;-java classes &lt;span class=&quot;built_in&quot;&gt;where&lt;/span&gt; applicable&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;
&lt;p&gt;修改下log输出日志的级别，获取更多的信息，在执行hadoop命令之前设置下&lt;/p&gt;
&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;built_in&quot;&gt;export&lt;/span&gt; HADOOP_ROOT_LOGGER=DEBUG,console&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;再执行启动dfs命令，控制台输出了一些debug信息，快看看是啥原因导致这个警告的出现。发现&lt;code&gt;GLIBC_2.14&lt;/code&gt;这个东东没有找到&lt;/p&gt;
&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;`GLIBC_2.14&lt;span class=&quot;string&quot;&gt;&#39; not found (required by opt/hadoop/lib/native/libhadoop.so.1.0.0)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;glibc是什么东西呢？&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;glibc是GNU发布的libc库，即c运行库。glibc是linux系统中最底层的api，几乎其它任何运行库都会依赖于glibc。glibc除了封装linux操作系统所提供的系统服务外，它本身也提供了许多其它一些必要功能服务的实现。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;看来这个库在linux系统中很重要呀！！！&lt;/p&gt;
&lt;p&gt;我们先看下我们操作系统的glib版本是什么&lt;br&gt;&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;strings /lib64/libc.so.6 | grep GLIBC&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/pic/20160405/2016040501.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;系统是2.12版本的，hadoop需要2.14版本才行，下面来对libc库进行升级。&lt;/p&gt;
&lt;p&gt;下载&lt;br&gt;&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;wget http://mirror.bjtu.edu.cn/gnu/libc/glibc-2.14.tar.xz&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;解压&lt;br&gt;&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;tar xvf glibc-2.14.tar.gz&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;编译&lt;br&gt;&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;built_in&quot;&gt;cd&lt;/span&gt; glibc-2.14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;mkdir build&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;built_in&quot;&gt;cd&lt;/span&gt; build&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;../configure --prefix=/usr/&lt;span class=&quot;built_in&quot;&gt;local&lt;/span&gt;/glibc-2.14   // 配置glibc并设置当前glibc-2.14安装目录&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;make -j4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;make install&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;安装完了，我们接下来要去更新系统的lib库，先复制libc-2.14.so到/lib64目录下&lt;br&gt;&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;cp /usr/&lt;span class=&quot;built_in&quot;&gt;local&lt;/span&gt;/glibc-2.14/lib/libc-2.14.so /lib64/libc-2.14.so&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;备份原来的/lib64/libc.so.6&lt;/p&gt;
&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;mv /lib64/libc.so.6 /lib64/libc.so.6.bak&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;备份好了，&lt;code&gt;ls&lt;/code&gt;看一下&lt;br&gt;&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;[root@hadoop001 ~]&lt;span class=&quot;comment&quot;&gt;# ls&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;ls: error &lt;span class=&quot;keyword&quot;&gt;while&lt;/span&gt; loading shared libraries: libc.so.6: cannot open &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;shared object file: No such file or directory&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;如下图所示:&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/pic/20160405/2016040502.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;oh，No，&lt;code&gt;ls&lt;/code&gt;命令不能用啦，咋回事，这还能不能愉快的玩耍啦，不要着急，我们continue吧 &lt;/p&gt;
&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;LD_PRELOAD=/lib64/libc-2.14.so ln –s /lib64/libc-2.14.so  /lib64/libc.so.6&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;再来看下libc的版本&lt;br&gt;&lt;img src=&quot;/pic/20160405/2016040503.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;Ok，大功告成。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;在执行hadoop命令或者启动dfs、yarn的时候总会出现这个警告&lt;/p&gt;
&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;WARN util.NativeCodeLoader: Unable to load native-hadoop library &lt;span class=&quot;keyword&quot;&gt;for&lt;/span&gt; your platform... &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;using &lt;span class=&quot;built_in&quot;&gt;builtin&lt;/span&gt;-java classes &lt;span class=&quot;built_in&quot;&gt;where&lt;/span&gt; applicable&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
    
      <category term="hadoop" scheme="http://dxer.github.io/tags/hadoop/"/>
    
  </entry>
  
  <entry>
    <title>HBase性能优化方法总结</title>
    <link href="http://dxer.github.io/2016/04/01/hbase-optimize/"/>
    <id>http://dxer.github.io/2016/04/01/hbase-optimize/</id>
    <published>2016-04-01T07:25:38.000Z</published>
    <updated>2016-06-02T00:31:08.598Z</updated>
    
    <content type="html">&lt;p&gt;本文主要是从HBase应用程序设计与开发的角度，总结几种常用的性能优化方法。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&quot;Auto-Flash&quot;&gt;&lt;a href=&quot;#Auto-Flash&quot; class=&quot;headerlink&quot; title=&quot;Auto Flash&quot;&gt;&lt;/a&gt;Auto Flash&lt;/h3&gt;&lt;p&gt;通过调用&lt;code&gt;HTable.setAutoFlushTo(false)&lt;/code&gt;方法可以将HTable写客户端自动flush关闭，这样可以批量写入数据到HBase，而不是有一条put就执行一次更新，只有当put填满客户端写缓存的时候，才会向HBase服务端发起写请求。默认情况下auto flush是开启的。&lt;/p&gt;
&lt;h3 id=&quot;Write-Buffer&quot;&gt;&lt;a href=&quot;#Write-Buffer&quot; class=&quot;headerlink&quot; title=&quot;Write Buffer&quot;&gt;&lt;/a&gt;Write Buffer&lt;/h3&gt;&lt;p&gt;通过调用&lt;code&gt;HTable.setWriteBufferSize(writeBufferSize)&lt;/code&gt;方法可以设置HTable客户端的写buffer大小，如果新设置的buffer小于当前写buffer中的数据时，buffer将会被flush到服务端。其中，writeBufferSize的单位是byte字节数，可以根基实际写入数据量的多少来设置该值。&lt;/p&gt;
&lt;h3 id=&quot;WAL-Flag&quot;&gt;&lt;a href=&quot;#WAL-Flag&quot; class=&quot;headerlink&quot; title=&quot;WAL Flag&quot;&gt;&lt;/a&gt;WAL Flag&lt;/h3&gt;&lt;p&gt;在HBase中，客户端向集群中的RegionServer提交数据时（Put/Delete操作），首先会写到WAL（Write Ahead Log）日志，即HLog，一个RegionServer上的所有Region共享一个HLog，只有当WAL日志写成功后，再接着写MemStore，然后客户端被通知提交数据成功，如果写WAL日志失败，客户端被告知提交失败，这样做的好处是可以做到RegionServer宕机后的数据恢复。&lt;br&gt;对于不太重要的数据，可以在Put/Delete操作时，通过调用&lt;code&gt;Put.setWriteToWAL(false)&lt;/code&gt;或&lt;code&gt;Delete.setWriteToWAL(false)&lt;/code&gt;函数，放弃写WAL日志，以提高数据写入的性能。&lt;/p&gt;
&lt;p&gt;注：如果关闭WAL日志，一旦RegionServer宕机，Put/Delete的数据将会无法根据WAL日志进行恢复。&lt;/p&gt;
&lt;h3 id=&quot;Compression-压缩&quot;&gt;&lt;a href=&quot;#Compression-压缩&quot; class=&quot;headerlink&quot; title=&quot;Compression 压缩&quot;&gt;&lt;/a&gt;Compression 压缩&lt;/h3&gt;&lt;p&gt;数据量大，边压边写也会提升性能的，毕竟IO是大数据的最严重的瓶颈，哪怕使用了SSD也是一样。众多的压缩方式中，推荐使用SNAPPY。从压缩率和压缩速度来看，性价比最高。&lt;br&gt;&lt;figure class=&quot;highlight java&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;HColumnDescriptor hcd = &lt;span class=&quot;keyword&quot;&gt;new&lt;/span&gt; HColumnDescriptor(familyName);   &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;hcd.setCompressionType(Algorithm.SNAPPY);&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h3 id=&quot;批量写&quot;&gt;&lt;a href=&quot;#批量写&quot; class=&quot;headerlink&quot; title=&quot;批量写&quot;&gt;&lt;/a&gt;批量写&lt;/h3&gt;&lt;p&gt;通过调用&lt;code&gt;HTable.put(Put)&lt;/code&gt;方法可以将一个指定的row key记录写入HBase，同样HBase提供了另一个方法：通过调用&lt;code&gt;HTable.put(List&amp;lt;Put&amp;gt;)&lt;/code&gt;方法可以将指定的row key列表，批量写入多行记录，这样做的好处是批量执行，只需要一次网络I/O开销，这对于对数据实时性要求高，网络传输RTT高的情景下可能带来明显的性能提升。&lt;/p&gt;
&lt;h3 id=&quot;多线程并发写&quot;&gt;&lt;a href=&quot;#多线程并发写&quot; class=&quot;headerlink&quot; title=&quot;多线程并发写&quot;&gt;&lt;/a&gt;多线程并发写&lt;/h3&gt;&lt;p&gt;在客户端开启多个 HTable 写线程，每个写线程负责一个 HTable 对象的 flush 操作，这样结合定时 flush 和写 buffer（writeBufferSize），可以既保证在数据量小的时候，数据可以在较短时间内被 flush（如1秒内），同时又保证在数据量大的时候，写 buffer 一满就及时进行 flush。&lt;/p&gt;
&lt;h3 id=&quot;批量读&quot;&gt;&lt;a href=&quot;#批量读&quot; class=&quot;headerlink&quot; title=&quot;批量读&quot;&gt;&lt;/a&gt;批量读&lt;/h3&gt;&lt;p&gt;通过调用 &lt;code&gt;HTable.get(Get)&lt;/code&gt; 方法可以根据一个指定的 row key 获取一行记录，同样 HBase 提供了另一个方法：通过调用 &lt;code&gt;HTable.get(List)&lt;/code&gt; 方法可以根据一个指定的 row key 列表，批量获取多行记录，这样做的好处是批量执行，只需要一次网络 I/O 开销，这对于对数据实时性要求高而且网络传输 RTT 高的情景下可能带来明显的性能提升。&lt;/p&gt;
&lt;h3 id=&quot;缓存查询结果&quot;&gt;&lt;a href=&quot;#缓存查询结果&quot; class=&quot;headerlink&quot; title=&quot;缓存查询结果&quot;&gt;&lt;/a&gt;缓存查询结果&lt;/h3&gt;&lt;p&gt;对于频繁查询 HBase 的应用场景，可以考虑在应用程序中做缓存，当有新的查询请求时，首先在缓存中查找，如果存在则直接返回，不再查询 HBase；否则对 HBase 发起读请求查询，然后在应用程序中将查询结果缓存起来。至于缓存的替换策略，可以考虑 LRU 等常用的策略。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&quot;HBase数据表优化&quot;&gt;&lt;a href=&quot;#HBase数据表优化&quot; class=&quot;headerlink&quot; title=&quot;HBase数据表优化&quot;&gt;&lt;/a&gt;HBase数据表优化&lt;/h2&gt;&lt;h3 id=&quot;预分区&quot;&gt;&lt;a href=&quot;#预分区&quot; class=&quot;headerlink&quot; title=&quot;预分区&quot;&gt;&lt;/a&gt;预分区&lt;/h3&gt;&lt;p&gt;默认情况下，在创建HBase表的时候会自动创建一个Region分区，当导入数据的时候，所有的HBase客户端都向Region写数据，知道这个Region足够大才进行切分，一种可以加快批量写入速度的方法是通过预先创建一些空的Regions，这样当数据写入HBase的时候，会按照Region分区情况，在进群内做数据的负载均衡。&lt;/p&gt;
&lt;h3 id=&quot;Rowkey优化&quot;&gt;&lt;a href=&quot;#Rowkey优化&quot; class=&quot;headerlink&quot; title=&quot;Rowkey优化&quot;&gt;&lt;/a&gt;Rowkey优化&lt;/h3&gt;&lt;p&gt;rowkey是按照字典存储，因此设置rowkey时，要充分利用排序特点，将经常一起读取的数据存储到一块，将最近可能会被访问的数据放到一块。&lt;br&gt;rowkey若是递增生成的，建议不要使用正序直接写入，可以使用字符串反转方式写入，使得rowkey大致均衡分布，这样设计的好处是能将RegionServer的负载均衡，否则容易产生所有新数据都在集中在一个RegionServer上堆积的现象，这一点还可以结合table的与分区设计。&lt;/p&gt;
&lt;h3 id=&quot;减少Column-Family数量&quot;&gt;&lt;a href=&quot;#减少Column-Family数量&quot; class=&quot;headerlink&quot; title=&quot;减少Column Family数量&quot;&gt;&lt;/a&gt;减少Column Family数量&lt;/h3&gt;&lt;p&gt;不要在一张表中定义太多的column family。目前HBase并不能很好的处理超过2-3个column family的表，因为某个column family在flush的时候，它临近的column family也会因关联效应被触发flush，最终导致系统产生更过的I/O;&lt;/p&gt;
&lt;h3 id=&quot;设置最大版本数&quot;&gt;&lt;a href=&quot;#设置最大版本数&quot; class=&quot;headerlink&quot; title=&quot;设置最大版本数&quot;&gt;&lt;/a&gt;设置最大版本数&lt;/h3&gt;&lt;p&gt;创建表的时候，可以通过 &lt;code&gt;HColumnDescriptor.setMaxVersions(int maxVersions)&lt;/code&gt; 设置表中数据的最大版本，如果只需要保存最新版本的数据，那么可以设置 setMaxVersions(1)。&lt;/p&gt;
&lt;h3 id=&quot;缓存策略（setCaching）&quot;&gt;&lt;a href=&quot;#缓存策略（setCaching）&quot; class=&quot;headerlink&quot; title=&quot;缓存策略（setCaching）&quot;&gt;&lt;/a&gt;缓存策略（setCaching）&lt;/h3&gt;&lt;p&gt;创建表的时候，可以通过&lt;code&gt;HColumnDEscriptor.setInMemory(true)&lt;/code&gt;将表放到RegionServer的缓存中，保证在读取的时候被cache命中。&lt;/p&gt;
&lt;h3 id=&quot;设置存储生命期&quot;&gt;&lt;a href=&quot;#设置存储生命期&quot; class=&quot;headerlink&quot; title=&quot;设置存储生命期&quot;&gt;&lt;/a&gt;设置存储生命期&lt;/h3&gt;&lt;p&gt;创建表的时候，可以通过&lt;code&gt;HColumnDescriptor.setTimeToLive(int timeToLive)&lt;/code&gt;设置表中数据的存储生命周期，过期数据将自动被删除&lt;/p&gt;
&lt;h3 id=&quot;磁盘配置&quot;&gt;&lt;a href=&quot;#磁盘配置&quot; class=&quot;headerlink&quot; title=&quot;磁盘配置&quot;&gt;&lt;/a&gt;磁盘配置&lt;/h3&gt;&lt;p&gt;每台RegionServer管理10-1000个Regions。每个Region在1-2G，则每台server最少要10G，最大要1000*2G=2TB，考虑3备份，需要6TB。方案1是3块2TB磁盘，2是12块500G磁盘，带宽足够时，后者能提供更大的吞吐率，更细力度的冗余备份，更快速的单盘故障恢复。&lt;/p&gt;
&lt;h3 id=&quot;分配何时的内存给RegionServer&quot;&gt;&lt;a href=&quot;#分配何时的内存给RegionServer&quot; class=&quot;headerlink&quot; title=&quot;分配何时的内存给RegionServer&quot;&gt;&lt;/a&gt;分配何时的内存给RegionServer&lt;/h3&gt;&lt;p&gt;在不影响其他服务的情况下，越大越好。在HBase的conf目录下的hbase-env.sh的最后添加&lt;code&gt;export HBASE_REGIONSERVER_OPTS=&amp;quot;- Xmx16000m $HBASE_REGIONSERVER_OPTS&amp;quot;&lt;/code&gt;&lt;br&gt;其中16000m为分配给REgionServer的内存大小。&lt;/p&gt;
&lt;h3 id=&quot;写数据的备份数&quot;&gt;&lt;a href=&quot;#写数据的备份数&quot; class=&quot;headerlink&quot; title=&quot;写数据的备份数&quot;&gt;&lt;/a&gt;写数据的备份数&lt;/h3&gt;&lt;p&gt;备份数与读性能是成正比，与写性能成反比，且备份数影响高可用性。有两种配置方式，一种是将hdfs-site.xml拷贝到hbase的conf目录下，然后在其中添加或修改配置项&lt;code&gt;dfs.replication&lt;/code&gt;的值为要设置的备份数，这种修改所有的HBase用户都生效。另一种方式是改写HBase代码，让HBase支持针对列族设置备份数，在创建表时，设置列族备份数，默认为3，此种备份数支队设置的列族生效。&lt;/p&gt;
&lt;h3 id=&quot;客户端一次从服务器拉取的数量&quot;&gt;&lt;a href=&quot;#客户端一次从服务器拉取的数量&quot; class=&quot;headerlink&quot; title=&quot;客户端一次从服务器拉取的数量&quot;&gt;&lt;/a&gt;客户端一次从服务器拉取的数量&lt;/h3&gt;&lt;p&gt;通过配置一次拉取较大的数据量可以减少客户端获取数据的时间，但是他会占用客户端的内存，有三个地方可以进行配置&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;在HBase的conf配置文件中进行配置&lt;code&gt;hbase.client.scanner.caching&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;通过调用&lt;code&gt;HTble.setScannerCaching(int scannerCaching)&lt;/code&gt;进行配置；&lt;/li&gt;
&lt;li&gt;通过调用&lt;code&gt;Sacn.setCaching(int caching)&lt;/code&gt;进行配置，三者的优先级越来越高。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&quot;客户端拉取的时候指定列族&quot;&gt;&lt;a href=&quot;#客户端拉取的时候指定列族&quot; class=&quot;headerlink&quot; title=&quot;客户端拉取的时候指定列族&quot;&gt;&lt;/a&gt;客户端拉取的时候指定列族&lt;/h3&gt;&lt;p&gt;scan是指定需要column family，可以减少网络传输数据量，否则默认scan操作会返回整行所有column family的数据&lt;/p&gt;
&lt;h3 id=&quot;拉取完数据之后关闭ResultScanner&quot;&gt;&lt;a href=&quot;#拉取完数据之后关闭ResultScanner&quot; class=&quot;headerlink&quot; title=&quot;拉取完数据之后关闭ResultScanner&quot;&gt;&lt;/a&gt;拉取完数据之后关闭ResultScanner&lt;/h3&gt;&lt;p&gt;通过 scan 取完数据后，记得要关闭 ResultScanner，否则 RegionServer 可能会出现问题（对应的 Server 资源无法释放）。&lt;/p&gt;
&lt;h3 id=&quot;RegionServer的请求处理IO线程数&quot;&gt;&lt;a href=&quot;#RegionServer的请求处理IO线程数&quot; class=&quot;headerlink&quot; title=&quot;RegionServer的请求处理IO线程数&quot;&gt;&lt;/a&gt;RegionServer的请求处理IO线程数&lt;/h3&gt;&lt;p&gt;较少的IO线程适用于处理单次请求内存消耗较高的Big Put场景（大容量单词Put或设置了较大cache的scan，均数据Big Put）或RegionServer的内存比较紧张的场景。&lt;/p&gt;
&lt;p&gt;较多的IO线程，适用于单次请求内存消耗低，TPS要求（每次事务处理量）非常高的场景。这只该值的时候，以监控内存为主要参考&lt;/p&gt;
&lt;p&gt;在hbase-site.xml配置文件中配置项为&lt;code&gt;hbase.regionserver.handle.count&lt;/code&gt;&lt;/p&gt;
&lt;h3 id=&quot;Region大小设置&quot;&gt;&lt;a href=&quot;#Region大小设置&quot; class=&quot;headerlink&quot; title=&quot;Region大小设置&quot;&gt;&lt;/a&gt;Region大小设置&lt;/h3&gt;&lt;p&gt;配置项&lt;code&gt;hbase.hregion.max.filesize&lt;/code&gt;，所属配置文件为hbase-site.xml，默认大小是256m。&lt;/p&gt;
&lt;p&gt;在当前RegionServer上单个Region的最大存储空间，单个Region超过该值时，这个Region会被自动split成更小的Region。小Region对split和compaction友好，因为拆分Region或compact小Region里的StoreFile速度非常快，内存占用低。缺点是split和compaction会很频繁，特别是数量较多的小Region不同的split，compaction，会导致集群响应时间波动很大，Region数量太多不仅给管理上带来麻烦，设置会引起一些HBase个bug。一般 512M 以下的都算小 Region。大 Region 则不太适合经常 split 和 compaction，因为做一次 compact 和 split 会产生较长时间的停顿，对应用的读写性能冲击非常大。&lt;/p&gt;
&lt;p&gt;此外，大 Region 意味着较大的 StoreFile，compaction 时对内存也是一个挑战。如果你的应用场景中，某个时间点的访问量较低，那么在此时做 compact 和 split，既能顺利完成 split 和 compaction，又能保证绝大多数时间平稳的读写性能。compaction 是无法避免的，split 可以从自动调整为手动。只要通过将这个参数值调大到某个很难达到的值，比如 100G，就可以间接禁用自动 split(RegionServer 不会对未到达 100G 的 Region 做 split)。再配合 RegionSplitter 这个工具，在需要 split 时，手动 split。手动 split 在灵活性和稳定性上比起自动 split 要高很多，而且管理成本增加不多，比较推荐 online 实时系统使用。内存方面，小 Region 在设置 memstore 的大小值上比较灵活，大 Region 则过大过小都不行，过大会导致 flush 时 app 的 IO wait 增高，过小则因 StoreFile 过多影响读性能。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;本文主要是从HBase应用程序设计与开发的角度，总结几种常用的性能优化方法。&lt;br&gt;
    
    </summary>
    
    
      <category term="hbase" scheme="http://dxer.github.io/tags/hbase/"/>
    
  </entry>
  
  <entry>
    <title>Redis-消息队列</title>
    <link href="http://dxer.github.io/2016/03/20/redis-%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"/>
    <id>http://dxer.github.io/2016/03/20/redis-消息队列/</id>
    <published>2016-03-20T03:21:38.000Z</published>
    <updated>2016-06-07T00:39:08.402Z</updated>
    
    <content type="html">&lt;p&gt;在网站开发中，当页面需要进行如发送邮件、发送短信、复杂数据运算等耗时较长的操作时会阻塞页面的渲染。为了避免用户等待太久，应该使用独立的线程来完成这类操作。不过一些编程语言或框架不易实现多线程，这时很容易就会想到通过其他进程来实现。设想有一个进程能够完成发邮件的功能，那么在页面中只需要想办法通知这个进程向指定的地址发送邮件就可以了。&lt;/p&gt;
&lt;p&gt;更多的时候，服务器做的额外的事情，并不需要客户端等待，这时候就可以把这些额外的事情异步去做。处理异步任务的工具很多。主要还是处理通知消息，针对通知消息通常采用的是队列结构。这个异步处理的模型可以抽象为生产者和消费者模型。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;redis中提供了两种方式来做消息队列，一个是使用生产者消费者模式，一种是使用发布订阅者模式。生产者消费者模式会让一个或者多个客户端监听消息队列，一旦有队列中有消息，消费者会马上去消费，谁先获得这个消息，谁就去处理。如果队列为空，则消费者继续监听。发布订阅者模式也是使用了一个或者多个客户端订阅消息频道，只要发布者发布了消息，所有的订阅者都能收到消息。&lt;/p&gt;
&lt;p&gt;这里我们先看下生产者和消费者模型的消息队列。&lt;/p&gt;
&lt;h2 id=&quot;队列&quot;&gt;&lt;a href=&quot;#队列&quot; class=&quot;headerlink&quot; title=&quot;队列&quot;&gt;&lt;/a&gt;队列&lt;/h2&gt;&lt;p&gt;与任务队列进行交互的实体有两类：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;生产者（producer）：生产者会将需要处理的任务放入任务队列中&lt;/li&gt;
&lt;li&gt;消费者（consumer）：消费者不断从任务队列中读入任务信息并执行&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;使用任务队列的好处&quot;&gt;&lt;a href=&quot;#使用任务队列的好处&quot; class=&quot;headerlink&quot; title=&quot;使用任务队列的好处&quot;&gt;&lt;/a&gt;使用任务队列的好处&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;松耦合&lt;br&gt;生产者和消费者无需知道彼此的实现细节，只需要约定好任务的描述格式。这使得生产者和消费者可以由不同的团队使用不同的编程语言来进行开发。&lt;/li&gt;
&lt;li&gt;易扩展&lt;br&gt;可以很方便的将消费者阔这到很多个，而且可以分布在不同的服务器中。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&quot;普通队列&quot;&gt;&lt;a href=&quot;#普通队列&quot; class=&quot;headerlink&quot; title=&quot;普通队列&quot;&gt;&lt;/a&gt;普通队列&lt;/h3&gt;&lt;p&gt;在redis中，可以使用列表（list）类型来实现。使用LPUSH和RPOP命令，&lt;br&gt;生产者将任务使用LPUSH命令加入到某个键中，消费者不断的使用RPOP命令从该键中取出任务。&lt;br&gt;代码如下:&lt;/p&gt;
&lt;figure class=&quot;highlight java&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;while&lt;/span&gt; (&lt;span class=&quot;keyword&quot;&gt;true&lt;/span&gt;) &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	String task = jedis.rpop(&lt;span class=&quot;string&quot;&gt;&quot;queue.task&quot;&lt;/span&gt;);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&lt;span class=&quot;keyword&quot;&gt;if&lt;/span&gt;(task!=&lt;span class=&quot;keyword&quot;&gt;null&lt;/span&gt; &amp;amp;&amp;amp; task.length()&amp;gt;&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;)&amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		execute(task);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&amp;#125;&lt;span class=&quot;keyword&quot;&gt;else&lt;/span&gt;&amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		Thread.sleep(&lt;span class=&quot;number&quot;&gt;1000&lt;/span&gt;);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;上面是一个很简单的任务队列的程序，不过上面的代码还是有点不太完美的地方：当任务队列中没有任务的时候，消费者每秒都会调用一次RPOP命令查看是否有新的任务。这里我们可以借助BRPOP命令来实现一旦有新的任务队列就通知消费者，这样消费者每秒都去查看任务队列中是否有任务了。&lt;/p&gt;
&lt;p&gt;上面的程序可以修改为：&lt;br&gt;&lt;figure class=&quot;highlight java&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;while&lt;/span&gt; (&lt;span class=&quot;keyword&quot;&gt;true&lt;/span&gt;) &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	List&amp;lt;String&amp;gt; tasks = jedis.brpop(&lt;span class=&quot;number&quot;&gt;10&lt;/span&gt;, &lt;span class=&quot;string&quot;&gt;&quot;queue.task&quot;&lt;/span&gt;);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&lt;span class=&quot;keyword&quot;&gt;if&lt;/span&gt; (tasks != &lt;span class=&quot;keyword&quot;&gt;null&lt;/span&gt; &amp;amp;&amp;amp; tasks.size() &amp;gt; &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;) &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		execute(tasks.get(&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;)); &lt;span class=&quot;comment&quot;&gt;// 这里要获取index为1的数据，因为index为0的数据是该队列的名字&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;BRPOP&lt;/code&gt;命令和&lt;code&gt;RPOP&lt;/code&gt;命令相似，唯一的区别就是当列表中没有元数据的时候，BRPOP命令会一直阻塞住连接，直到有新元素加入。&lt;/p&gt;
&lt;p&gt;BRPOP命令接收两个参数，第一个是键名，第二个是超时时间（单位：s）。当超过了这个时间，任然没有获得到新的数据的话，就会返回nil。当设置超时时间为0的时候，表示不限制等待时间，也就是说没有新数据加入的时候，就会永远阻塞下去。&lt;/p&gt;
&lt;p&gt;redis还提供了BLPOP命令，和BRPOP的区别在与从队列取数据时，BLPOP会从队列左边开始取数据，而BRPOP是从队列的右边开始取数据。&lt;/p&gt;
&lt;h2 id=&quot;优先级队列&quot;&gt;&lt;a href=&quot;#优先级队列&quot; class=&quot;headerlink&quot; title=&quot;优先级队列&quot;&gt;&lt;/a&gt;优先级队列&lt;/h2&gt;&lt;p&gt;在产品给用户发送短信的时候，有验证短信和营销短信，同样都是将短信添加到任务队列，供消费者进行处理。在没有优先级队列的时候，系统现在正在给用户发送营销短信，这是有一个用户注册了，系统要给用户发送验证短信，但是系统正在处理营销短信，按照普通任务队列，验证短信，要在营销短信发送完成之后，才开始发送，这样多影响用户体验。要是不管在什么时候，只要有发送验证短信的任务，就能立刻去处理掉，这样就好啦。&lt;/p&gt;
&lt;p&gt;这样我们就需要一个具有优先级的任务队列啦，按照我们的业务逻辑，优先处理重要的任务。&lt;/p&gt;
&lt;p&gt;在redis中，&lt;code&gt;BRPOP&lt;/code&gt;命令可以同时接收多个键，完整的命令格式如下&lt;/p&gt;
&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;BRPOP queue.task.1 queue.task.2 0&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;它可以同时检测多个键，如果所有的键都没有数据则阻塞，如果其中有一个键有数据则会返回响应的数据。如果多个键都有数据，则按照命令中从左到右的键的顺序取第一个有数据的键中对应的数据。这样我们就可以实现一个具有优先级的任务队列了。&lt;/p&gt;
&lt;p&gt;代码如下：&lt;br&gt;&lt;figure class=&quot;highlight java&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;while&lt;/span&gt; (&lt;span class=&quot;keyword&quot;&gt;true&lt;/span&gt;) &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	List&amp;lt;String&amp;gt; tasks = jedis.brpop(&lt;span class=&quot;number&quot;&gt;10&lt;/span&gt;, &lt;span class=&quot;string&quot;&gt;&quot;queue.task.1&quot;&lt;/span&gt;, &lt;span class=&quot;string&quot;&gt;&quot;queue.task.2&quot;&lt;/span&gt;);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&lt;span class=&quot;keyword&quot;&gt;if&lt;/span&gt; (tasks != &lt;span class=&quot;keyword&quot;&gt;null&lt;/span&gt; &amp;amp;&amp;amp; tasks.size() &amp;gt; &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;) &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		execute(tasks.get(&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;)); &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;在网站开发中，当页面需要进行如发送邮件、发送短信、复杂数据运算等耗时较长的操作时会阻塞页面的渲染。为了避免用户等待太久，应该使用独立的线程来完成这类操作。不过一些编程语言或框架不易实现多线程，这时很容易就会想到通过其他进程来实现。设想有一个进程能够完成发邮件的功能，那么在页面中只需要想办法通知这个进程向指定的地址发送邮件就可以了。&lt;/p&gt;
&lt;p&gt;更多的时候，服务器做的额外的事情，并不需要客户端等待，这时候就可以把这些额外的事情异步去做。处理异步任务的工具很多。主要还是处理通知消息，针对通知消息通常采用的是队列结构。这个异步处理的模型可以抽象为生产者和消费者模型。&lt;br&gt;
    
    </summary>
    
    
      <category term="redis" scheme="http://dxer.github.io/tags/redis/"/>
    
  </entry>
  
  <entry>
    <title>HBase简介</title>
    <link href="http://dxer.github.io/2016/03/19/hbase%E7%AE%80%E4%BB%8B/"/>
    <id>http://dxer.github.io/2016/03/19/hbase简介/</id>
    <published>2016-03-19T03:21:38.000Z</published>
    <updated>2016-07-14T02:13:26.020Z</updated>
    
    <content type="html">&lt;p&gt;HBase是一个分布式的、面向列的开源数据库。HBase是Apache的Hadoop项目的子项目。HBase不同于一般的关系数据库，它是一个适合于非结构化数据存储的数据库。另一个不同的是HBase基于列的而不是基于行的模式。 &lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&quot;HBase表的特点&quot;&gt;&lt;a href=&quot;#HBase表的特点&quot; class=&quot;headerlink&quot; title=&quot;HBase表的特点&quot;&gt;&lt;/a&gt;HBase表的特点&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;大：一个表可以有有数以十亿行，上百万列&lt;/li&gt;
&lt;li&gt;面向列：面向列（族）的存储和权限访问，列（族）独立索引&lt;/li&gt;
&lt;li&gt;稀疏：对于未空（null）的列，并不占用存储空间，因此表可以设计的非常稀疏&lt;/li&gt;
&lt;li&gt;数据类型单一：HBase中的数据类型都是字符串（string）&lt;/li&gt;
&lt;li&gt;无模式：每行都有一个可排序的主键和任意多的列，列可以根据需要动态增加，同一张表中不同的行可以截然不同的列&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&quot;HBase和关系数据库区别&quot;&gt;&lt;a href=&quot;#HBase和关系数据库区别&quot; class=&quot;headerlink&quot; title=&quot;HBase和关系数据库区别&quot;&gt;&lt;/a&gt;HBase和关系数据库区别&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;数据库类型：HBase中的数据类型都是字符串类型（string）&lt;/li&gt;
&lt;li&gt;数据操作：HBase只有普通的增删改查等操作，没有表之间的关联查询&lt;/li&gt;
&lt;li&gt;存储模式：HBase是基于列式存储模式，而RDBMS是基于行式存储的&lt;/li&gt;
&lt;li&gt;应用场景：HBase适合存储大量数据，查询效率极高&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&quot;基本概念&quot;&gt;&lt;a href=&quot;#基本概念&quot; class=&quot;headerlink&quot; title=&quot;基本概念&quot;&gt;&lt;/a&gt;基本概念&lt;/h1&gt;&lt;p&gt;HBase以表的形式存储数据。表有行和列组成。列划分为若干个列族(column family)&lt;/p&gt;
&lt;h2 id=&quot;RowKey&quot;&gt;&lt;a href=&quot;#RowKey&quot; class=&quot;headerlink&quot; title=&quot;RowKey&quot;&gt;&lt;/a&gt;RowKey&lt;/h2&gt;&lt;p&gt;用来检索记录的主键 主键为任意字符串，最大长度为64kb，按字典顺序存储，在HBase内部保存为字节数组&lt;/p&gt;
&lt;p&gt;Rowkey是以字典顺序从大到小排序 Rowkey尽量散列设计，保证所有的数据不是在一个Region上，从而避免读写的时候负载会集中在个别Region上。 Rowkey的长度尽量短，如果太长存储开销会增加，影响存储效率，Rowkey字段过长，会导致内存的利用率降低，进而降低索引的命中率&lt;/p&gt;
&lt;h3 id=&quot;常见Rowkey设计方法：&quot;&gt;&lt;a href=&quot;#常见Rowkey设计方法：&quot; class=&quot;headerlink&quot; title=&quot;常见Rowkey设计方法：&quot;&gt;&lt;/a&gt;常见Rowkey设计方法：&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;反转userId，将userId字符串反转后存储&lt;/li&gt;
&lt;li&gt;散列userId，对userId进行散列&lt;/li&gt;
&lt;li&gt;userId取模后进行MD5，区前6位作为前缀加入到userId前面&lt;/li&gt;
&lt;li&gt;时间使用long型来表示&lt;/li&gt;
&lt;li&gt;尽量使用编码压缩&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;访问HBase表中的行，只有三种方式：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;通过rowkey&lt;/li&gt;
&lt;li&gt;通过rowkey的range&lt;/li&gt;
&lt;li&gt;全表扫描&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;列族（Column-Family）&quot;&gt;&lt;a href=&quot;#列族（Column-Family）&quot; class=&quot;headerlink&quot; title=&quot;列族（Column Family）&quot;&gt;&lt;/a&gt;列族（Column Family）&lt;/h2&gt;&lt;p&gt;列族在创建表的时候声明，一个列族可以包含多个列，列中的数据都是以二进制形式存在，没有数据类型 列族是一些列的集合 一个列族所有成员是有着相同的前缀。用”:”来分割列族和列名&lt;/p&gt;
&lt;h2 id=&quot;列（Column）&quot;&gt;&lt;a href=&quot;#列（Column）&quot; class=&quot;headerlink&quot; title=&quot;列（Column）&quot;&gt;&lt;/a&gt;列（Column）&lt;/h2&gt;&lt;p&gt;属于某一个column family，columnfamily:columnName，每条记录可动态添加&lt;/p&gt;
&lt;h2 id=&quot;时间戳和存储单元（TimeStamp-and-Cell）&quot;&gt;&lt;a href=&quot;#时间戳和存储单元（TimeStamp-and-Cell）&quot; class=&quot;headerlink&quot; title=&quot;时间戳和存储单元（TimeStamp and Cell）&quot;&gt;&lt;/a&gt;时间戳和存储单元（TimeStamp and Cell）&lt;/h2&gt;&lt;p&gt;HBase中通过row和columns确定的唯一个存储单元成为cell，每个cell都保存同一份数据的多个版本 在写入数据时，时间戳可以又HBase自动赋值（当前系统时间精确到毫秒），也阔以显示赋值 每个cell中，不同版本的数据按照时间的倒叙排序 {row，Column，version}元组就是HBase中的一个cell&lt;/p&gt;
&lt;h1 id=&quot;HBase物理模型&quot;&gt;&lt;a href=&quot;#HBase物理模型&quot; class=&quot;headerlink&quot; title=&quot;HBase物理模型&quot;&gt;&lt;/a&gt;HBase物理模型&lt;/h1&gt;&lt;p&gt;HBase存储细节 每个列族存储在HDFS上的一个单独文件夹中 Key和Version number会在每个列族中存储一份 空值不会被保存 HBase 为每个值维护了多级索引，即：&lt;/p&gt;
&lt;p&gt;&lt;key, column=&quot;&quot; family,=&quot;&quot; name,=&quot;&quot; timestamp=&quot;&quot;&gt;&lt;br&gt;&lt;/key,&gt;&lt;/p&gt;
&lt;p&gt;物理存储：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Table中所有行都按照row key的字典序排列；&lt;/li&gt;
&lt;li&gt;Table在行的方向上分割为多个Region；&lt;/li&gt;
&lt;li&gt;Region按大小分割的，每个表开始只有一个region，随着数据增多，region不断增大，当增大到一个阀值的时候，region就会等分会两个新的region，之后会有越来越多的region；&lt;/li&gt;
&lt;li&gt;Region是Hbase中分布式存储和负载均衡的最小单元，不同Region分布到不同RegionServer上。&lt;/li&gt;
&lt;li&gt;Region虽然是分布式存储的最小单元，但并不是存储的最小单元。Region由一个或者多个Store组成，每个store保存一个columns family；每个Strore又由一个memStore和0至多个StoreFile组成，StoreFile包含HFile；memStore存储在内存中，StoreFile存储在HDFS上。&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id=&quot;HBase架构与基本组件&quot;&gt;&lt;a href=&quot;#HBase架构与基本组件&quot; class=&quot;headerlink&quot; title=&quot;HBase架构与基本组件&quot;&gt;&lt;/a&gt;HBase架构与基本组件&lt;/h1&gt;&lt;h2 id=&quot;Client&quot;&gt;&lt;a href=&quot;#Client&quot; class=&quot;headerlink&quot; title=&quot;Client&quot;&gt;&lt;/a&gt;Client&lt;/h2&gt;&lt;p&gt;整个HBase集群的入口 使用HBase RPC机制与HMaster和HRegionServer通信 与HMaster通信进行管理类的操作 与HRegionServer通信进行读写类操作 包含访问HBase的接口，并维护cache来加快对HBase的访问，与HRegionServer交互&lt;/p&gt;
&lt;h2 id=&quot;ZooKeeper程序协调服务&quot;&gt;&lt;a href=&quot;#ZooKeeper程序协调服务&quot; class=&quot;headerlink&quot; title=&quot;ZooKeeper程序协调服务&quot;&gt;&lt;/a&gt;ZooKeeper程序协调服务&lt;/h2&gt;&lt;p&gt;保证任何时候，集群中只有一个Master（HA） 存储所有Region的寻址入口 实时监控Region server的上线和下线信息。并实时通知HMaster 存储HBase的schema和table元数据&lt;/p&gt;
&lt;h2 id=&quot;HBase主节点HMaster&quot;&gt;&lt;a href=&quot;#HBase主节点HMaster&quot; class=&quot;headerlink&quot; title=&quot;HBase主节点HMaster&quot;&gt;&lt;/a&gt;HBase主节点HMaster&lt;/h2&gt;&lt;p&gt;管理用户对Table的增删改查操作（表操作） 管理HRegionServer的负载均衡，调整Region分布 在Region split后，负责新Region的分配 在HRegionServer停机后，负责将失效的HRegionServer上的Region迁移 HMaster失效仅会导致所有元数据无法被修改，但是表的数据读写还是可以正常进行&lt;/p&gt;
&lt;h2 id=&quot;HRegionServer节点&quot;&gt;&lt;a href=&quot;#HRegionServer节点&quot; class=&quot;headerlink&quot; title=&quot;HRegionServer节点&quot;&gt;&lt;/a&gt;HRegionServer节点&lt;/h2&gt;&lt;p&gt;维护HRegion并往HDFS中写数据 当表的大小超过设置值时，split HRegion 在HRegionServer停机后，负责失效HRegionServer上的HRegion迁移&lt;/p&gt;
&lt;h1 id=&quot;HBase与Zookeeper&quot;&gt;&lt;a href=&quot;#HBase与Zookeeper&quot; class=&quot;headerlink&quot; title=&quot;HBase与Zookeeper&quot;&gt;&lt;/a&gt;HBase与Zookeeper&lt;/h1&gt;&lt;p&gt;HBase元数据存储在Zookeeper中 默认情况下,HBase管理Zookeeper实例，比如，启动或者停止Zookeeper Zookeeper解决HBase单点故障问题 HMaster与HRegionServer启动时会向Zookeeper注册&lt;/p&gt;
&lt;h1 id=&quot;WAL&quot;&gt;&lt;a href=&quot;#WAL&quot; class=&quot;headerlink&quot; title=&quot;WAL&quot;&gt;&lt;/a&gt;WAL&lt;/h1&gt;&lt;p&gt;WAL是Regionserver在处理插入和删除的过程中用来记录操作内容的一种日志&lt;/p&gt;
&lt;p&gt;一个表由一个region或者多个region组成，region由regionserver进行管理 每个region包含memstore和storeFile，memstore存储在内存中，storeFile存储在磁盘中&lt;/p&gt;
&lt;h1 id=&quot;HBase在HDFS中存储&quot;&gt;&lt;a href=&quot;#HBase在HDFS中存储&quot; class=&quot;headerlink&quot; title=&quot;HBase在HDFS中存储&quot;&gt;&lt;/a&gt;HBase在HDFS中存储&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;&lt;code&gt;/hbase/.tmp&lt;/code&gt;：临时目录，当对表做创建和删除的时候，会将表move到该目录，然后进行操作&lt;/li&gt;
&lt;li&gt;&lt;code&gt;/hbase/data&lt;/code&gt;：核心目录，存储HBase表的数据 默认情况下，目录下有两个目录&lt;/li&gt;
&lt;li&gt;&lt;code&gt;/hbase/data/default&lt;/code&gt;: 在用户创建表的时候，没有指定namespace时，表就创建在此目录下&lt;/li&gt;
&lt;li&gt;&lt;code&gt;/hbase/data/hbase&lt;/code&gt;：系统内部创建的表，.META.表（region的详细信息）和namespace表（namespace信息）&lt;/li&gt;
&lt;li&gt;&lt;code&gt;/hbase/hbase.id&lt;/code&gt;：存储的是集群的唯一cluster id（uuid）&lt;/li&gt;
&lt;li&gt;&lt;code&gt;/hbase/hbase.version&lt;/code&gt;：集群的版本号&lt;/li&gt;
&lt;li&gt;&lt;code&gt;/hbase/oldWALs&lt;/code&gt;: 对应0.94.x版本中.oldlogs目录 当/hbase/WALs目录中的logs没有之后，会将这些logs移动到此目录下，HMaster会定期清理&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&quot;HBase使用场景&quot;&gt;&lt;a href=&quot;#HBase使用场景&quot; class=&quot;headerlink&quot; title=&quot;HBase使用场景&quot;&gt;&lt;/a&gt;HBase使用场景&lt;/h1&gt;&lt;ol&gt;
&lt;li&gt;大数据量存储，大数据量高并发操作&lt;/li&gt;
&lt;li&gt;需要对数据随机读写操作&lt;/li&gt;
&lt;li&gt;读写访问均是非常简单的操作&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id=&quot;HBase与HDFS对比&quot;&gt;&lt;a href=&quot;#HBase与HDFS对比&quot; class=&quot;headerlink&quot; title=&quot;HBase与HDFS对比&quot;&gt;&lt;/a&gt;HBase与HDFS对比&lt;/h1&gt;&lt;ol&gt;
&lt;li&gt;两者都具有良好的容错性和扩展性，都可以扩展到成百上千个节点；&lt;/li&gt;
&lt;li&gt;HDFS适合批处理场景，不支持数据随机查找，不适合增量数据处理，不支持数据更新&lt;/li&gt;
&lt;/ol&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;HBase是一个分布式的、面向列的开源数据库。HBase是Apache的Hadoop项目的子项目。HBase不同于一般的关系数据库，它是一个适合于非结构化数据存储的数据库。另一个不同的是HBase基于列的而不是基于行的模式。
    
    </summary>
    
    
      <category term="hbase" scheme="http://dxer.github.io/tags/hbase/"/>
    
  </entry>
  
  <entry>
    <title>HBase入门</title>
    <link href="http://dxer.github.io/2016/03/18/hbase/"/>
    <id>http://dxer.github.io/2016/03/18/hbase/</id>
    <published>2016-03-18T11:25:38.000Z</published>
    <updated>2016-07-13T04:19:54.336Z</updated>
    
    <content type="html">&lt;h1 id=&quot;HBase一些基本概念&quot;&gt;&lt;a href=&quot;#HBase一些基本概念&quot; class=&quot;headerlink&quot; title=&quot;HBase一些基本概念&quot;&gt;&lt;/a&gt;HBase一些基本概念&lt;/h1&gt;&lt;p&gt;1、Row key 行主键，在对HBase进行查询时候只能依靠Row key，HBase不支持条件查询等类似于一些主流数据库的查询方式，读取记录只能依赖行主键以及进行全局扫面，可以将行主键想象成主流数据库查询过程中用到的主键（例如，id）。&lt;/p&gt;
&lt;p&gt;2、Column Family 列族，可以将列族想象成日常主流数据库中的表结构的所有列的一个大管家，列族中存储了所有列的名称，整个表包括多少列，列族就包括多少（除去Row key和Timestamp列）。&lt;/p&gt;
&lt;p&gt;3、Column 列，HBase的每个列都隶属于一个列族，以列族名称作为前缀，同一列族中的所有列会聚集在一个存储单元上，同时按照Column key进行排序。&lt;/p&gt;
&lt;p&gt;4、Timestamp 在HBase中，通过row key 和 Colum Family确定一份数据，同一个row key和Colum Family可能有多份不同的数据，HBase通过时间戳来区分这些数据，同时按照时间戳对左右的数据进行排序，最新的数据排在最前面，时间戳默认为系统当前时间（精确到毫秒），同时也可以人为设置该值。&lt;/p&gt;
&lt;p&gt;5、Value 我们在HBase表中精确查询数据时，通过TableName找到表，接着通过Row key找到对应的行，然后通过ColumnKey找到相应的列，最后根据时间戳找到最新的需要查询的值，这个值就是value。&lt;/p&gt;
&lt;p&gt;6、存储类型 在HBase中，表名称是字符串，行键和列名称是二进制值（即就是Java中的Byte[]），时间戳是一个64为的整数（Java中的long类型），最后的查询结果Value是字节数组（Java中的byte[]类型）。&lt;/p&gt;
&lt;p&gt;7、存储结构&lt;/p&gt;
&lt;p&gt;在HBase中，整个数据表是按照行键进行排序，每行包括任意数量的列，列和列之间通过列键进行排序，每列包括若干的数据，整个HBase的存储结构可以理解如下：&lt;/p&gt;
&lt;figure class=&quot;highlight sql&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;Table(&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    Row key，List(&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        SortedMap(&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            Column，list(&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            Value，Timestamp&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            )&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        )&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    )&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;hr&gt;
&lt;h1 id=&quot;HBase数据模型&quot;&gt;&lt;a href=&quot;#HBase数据模型&quot; class=&quot;headerlink&quot; title=&quot;HBase数据模型&quot;&gt;&lt;/a&gt;HBase数据模型&lt;/h1&gt;&lt;ol&gt;
&lt;li&gt;表（table）：HBase用表组织数据。表名是字符串（String），由可以在文件系统路径里使用的字符组成。&lt;/li&gt;
&lt;li&gt;行（row）：在表里，数据按行存储。行由行健（rowkey）唯一标识。行健没有数据类型，视为字节数组byte[]。&lt;/li&gt;
&lt;li&gt;列族（column family）：行里的数据按照列族进行分组，列族也影响到HBase数据的物理存放。因此，他们必须事前定义并且不轻易修改。表中每行拥有相同列族，尽管行不需要在每个列族里存储数据，列族名字是字符串（String），由可以在文件系统路径里使用的字符组成。&lt;/li&gt;
&lt;li&gt;列限定符（column qualifier）：列族里的数据通过列限定符或列来定位。列限定符不必事前定义。列限定符不必在不同行之间保持一致。就像行健一样，类限定符没有数据类型，视为字节数据byte[]。&lt;/li&gt;
&lt;li&gt;单元（cell）：行健、列族和列限定符一起确定一个单元。存储在单元里的数据成为单元值（value）。值没有数据类型，视为字节数组byte[]。&lt;/li&gt;
&lt;li&gt;时间版本（version）：单元值有时间版本。时间版本用时间戳标识，是一个long型。没有指定时间版本时，当前时间戳作为操作的基础。HBase保留单元值时间版本的数量基于列族进行配置。默认3个版本。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;数据坐标&lt;/p&gt;
&lt;p&gt;行健、列族、列限定符和时间版本&lt;/p&gt;
&lt;h2 id=&quot;写&quot;&gt;&lt;a href=&quot;#写&quot; class=&quot;headerlink&quot; title=&quot;写&quot;&gt;&lt;/a&gt;写&lt;/h2&gt;&lt;p&gt;执行写入的时候会写到两个文件：预写式日志（write-ahead log，也称HLog）和MemStore。HBase的默认方式是把写入动作记录在这两个地方，以保证数据持久化。只有当这两个地方的变化信息都写入并确认后，才认为写动作完成。&lt;/p&gt;
&lt;p&gt;&lt;em&gt;MemStore&lt;/em&gt;是内存里的写入缓冲区，HBase中数据在永久写入硬盘之前在这里积累。当MemStore填满后，其中的数据会刷写到硬盘，生成一个HFile文件。HFile是HBase使用底层存储格式。HFile对应列族，一个列族可以有多个HFile，但一个HFile不能存储多个列族的数据。在集群的每个节点上，每个列族都有一个MemStore。&lt;/p&gt;
&lt;p&gt;注：不写入WAL会在RegionServer故障时增加丢失数据的风险。关闭WAL，出现故障时HBase可能无法恢复数据，没有刷写到硬盘的所有写入数据都会丢失。&lt;/p&gt;
&lt;h3 id=&quot;读&quot;&gt;&lt;a href=&quot;#读&quot; class=&quot;headerlink&quot; title=&quot;读&quot;&gt;&lt;/a&gt;读&lt;/h3&gt;&lt;p&gt;HBase在读操作上使用了LRU（最近最少使用算法）缓存技术。也叫作BlockCache。BlockCache设计用来保存从HFile里读入内存的频繁访问的数据，避免硬盘读。每个列族都有自己的BlockCache。&lt;/p&gt;
&lt;p&gt;BlockCache中的Block是HBase从硬盘完成一次读取的数据单位。HFile物理存放形式是一个Block的序列外加这些Block的索引。从HBase中读取一个Block需要先将索引上查找一次改Block然后从硬盘读出、Block是建立索引的最小数据单位，也是从硬盘读取的最小数据单位。Block大小按照列族设定，默认是64kb。如果主要用于随机查询，可能需要细粒度的Block索引，小一点儿的Block更好一些。Block变小会导致索引变大，进而消耗更多内存。如果经常执行顺序扫描，一次读取多个Block，大一点的Block更好一些。Block变大意味着索引项变少，索引编写，因此节省内存。&lt;/p&gt;
&lt;p&gt;从HBase总读出一行，首先会检查MemStore等待修改的队列，然后检查BlockCache看包含改行的Blocj是否最近被访问过，最后访问硬盘上对应的HFile。&lt;/p&gt;
&lt;h3 id=&quot;删&quot;&gt;&lt;a href=&quot;#删&quot; class=&quot;headerlink&quot; title=&quot;删&quot;&gt;&lt;/a&gt;删&lt;/h3&gt;&lt;p&gt;执行HBase删除命令的时候，实际上数据并不会立即删除，只是会在该数据上打上删除的记录。被标记的记录不能在Get和Scan命令中返回结果。因为HFile文件是不能改变的，直到执行一次大合并，含有这些标记的数据才会被处理，被删除的数据占用的空间才会释放。&lt;/p&gt;
&lt;p&gt;&lt;em&gt;大合并（major compaction）&lt;/em&gt;：处理给定region的一个列族的所有HFile。大合并完成后，这个列族的所有HFile合并成一个文件，可以从Shell中收工出发整个表（或者特定region）的大合并。大合并是HBase清理被删除记录的唯一机会&lt;/p&gt;
&lt;p&gt;&lt;em&gt;小合并（minor compaction）&lt;/em&gt;：把多个小HFile合并成一个大HFile。&lt;/p&gt;
&lt;hr&gt;
&lt;h1 id=&quot;HBase-Shell命令&quot;&gt;&lt;a href=&quot;#HBase-Shell命令&quot; class=&quot;headerlink&quot; title=&quot;HBase Shell命令&quot;&gt;&lt;/a&gt;HBase Shell命令&lt;/h1&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Command&lt;/th&gt;
&lt;th&gt;描述&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;alter&lt;/td&gt;
&lt;td&gt;修改列族模式&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;count&lt;/td&gt;
&lt;td&gt;统计表中行的数量&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;create&lt;/td&gt;
&lt;td&gt;创建表&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;describe&lt;/td&gt;
&lt;td&gt;显示表相关的详细信息&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;delete&lt;/td&gt;
&lt;td&gt;删除指定对象的值（可以为表，行，列对应的值，另外也可以指定时间戳的值）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;deleteall&lt;/td&gt;
&lt;td&gt;删除指定行的所有元素值&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;disable&lt;/td&gt;
&lt;td&gt;使表无效&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;enable&lt;/td&gt;
&lt;td&gt;使表有效&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;drop&lt;/td&gt;
&lt;td&gt;删除表&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;exists&lt;/td&gt;
&lt;td&gt;测试表是否存在&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;exit&lt;/td&gt;
&lt;td&gt;退出HBase Shell的值&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;get&lt;/td&gt;
&lt;td&gt;获取行或单元的值&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;incr&lt;/td&gt;
&lt;td&gt;增加指定表、行或列的值&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;list&lt;/td&gt;
&lt;td&gt;列出HBase中存在的所有表&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;put&lt;/td&gt;
&lt;td&gt;向指定的表单元添加值&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;tools&lt;/td&gt;
&lt;td&gt;列出HBase所支持的工具&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;scan&lt;/td&gt;
&lt;td&gt;通过对表的扫描来获取对应的值&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;status&lt;/td&gt;
&lt;td&gt;返回HBase集群的状态信息&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;shutdown&lt;/td&gt;
&lt;td&gt;关闭HBase集群（与exit不同）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;truncate&lt;/td&gt;
&lt;td&gt;重新创建指定表&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;version&lt;/td&gt;
&lt;td&gt;返回HBase版本信息&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&quot;create&quot;&gt;&lt;a href=&quot;#create&quot; class=&quot;headerlink&quot; title=&quot;create&quot;&gt;&lt;/a&gt;create&lt;/h2&gt;&lt;p&gt;创建表&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;create &amp;apos;t1&amp;apos;, &amp;#123;NAME =&amp;gt; &amp;apos;f1&amp;apos;, VERSIONS =&amp;gt; 5&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;create &amp;apos;t1&amp;apos;, &amp;#123;Name =&amp;gt; &amp;apos;f1&amp;apos;&amp;#125;, &amp;#123;NAME =&amp;gt; &amp;apos;f2&amp;apos;&amp;#125;, &amp;#123;NAME =&amp;gt; &amp;apos;f3&amp;apos;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;#等价于：&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;create &amp;apos;t1&amp;apos;, &amp;apos;cf&amp;apos;, &amp;apos;cf2&amp;apos;, &amp;apos;cf3&amp;apos;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h2 id=&quot;list&quot;&gt;&lt;a href=&quot;#list&quot; class=&quot;headerlink&quot; title=&quot;list&quot;&gt;&lt;/a&gt;list&lt;/h2&gt;&lt;p&gt;列出HBase中包含的表名称&lt;/p&gt;
&lt;h2 id=&quot;put&quot;&gt;&lt;a href=&quot;#put&quot; class=&quot;headerlink&quot; title=&quot;put&quot;&gt;&lt;/a&gt;put&lt;/h2&gt;&lt;p&gt;向指定表中添加值&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;put &amp;apos;t1&amp;apos;, &amp;apos;rowkey&amp;apos;, &amp;apos;cf:name&amp;apos;, &amp;apos;test&amp;apos;, ts&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;#向t1表的rowkey，列cf:name添加值name，并指定时间戳为ts&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h2 id=&quot;scan&quot;&gt;&lt;a href=&quot;#scan&quot; class=&quot;headerlink&quot; title=&quot;scan&quot;&gt;&lt;/a&gt;scan&lt;/h2&gt;&lt;p&gt;对表的扫描来获取对应的值&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;scan &amp;apos;t1&amp;apos;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;scan &amp;apos;t1&amp;apos;, &amp;#123;COLUMNS =&amp;gt; &amp;apos;cf&amp;apos;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;scan &amp;apos;t1&amp;apos;, &amp;#123;COLUMNS =&amp;gt; &amp;apos;cf&amp;apos;,  LIMIT =&amp;gt; 10&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h2 id=&quot;get&quot;&gt;&lt;a href=&quot;#get&quot; class=&quot;headerlink&quot; title=&quot;get&quot;&gt;&lt;/a&gt;get&lt;/h2&gt;&lt;p&gt;获取行或者单元的值。&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;get &amp;apos;t1&amp;apos;, &amp;apos;rowkey&amp;apos;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;get &amp;apos;t1&amp;apos;, &amp;apos;rowkey&amp;apos;, &amp;#123;COLUMN =&amp;gt; &amp;apos;cf:name&amp;apos;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;&lt;em&gt;注：COLUMN和COLUMNS是不同的，scan操作中的COLUMNS指定的是表的列族，get操作中的COLUMN指定的是特定的列，COLUMN的值是指上是”列族+列修饰符”&lt;/em&gt;&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;HBase一些基本概念&quot;&gt;&lt;a href=&quot;#HBase一些基本概念&quot; class=&quot;headerlink&quot; title=&quot;HBase一些基本概念&quot;&gt;&lt;/a&gt;HBase一些基本概念&lt;/h1&gt;&lt;p&gt;1、Row key 行主键，在对HBase进行查询时候只能依靠Row
    
    </summary>
    
    
      <category term="hbase" scheme="http://dxer.github.io/tags/hbase/"/>
    
  </entry>
  
  <entry>
    <title>Hive入门</title>
    <link href="http://dxer.github.io/2016/03/11/hive02/"/>
    <id>http://dxer.github.io/2016/03/11/hive02/</id>
    <published>2016-03-11T02:14:20.000Z</published>
    <updated>2016-04-28T10:43:14.167Z</updated>
    
    <content type="html">&lt;p&gt;Hive是建立在 Hadoop 上的数据仓库基础构架。它提供了一系列的工具，可以用来进行数据提取转化加载（ETL），这是一种可以存储、查询和分析存储在 Hadoop 中的大规模数据的机制。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;那什么是数据仓库呢&quot;&gt;&lt;a href=&quot;#那什么是数据仓库呢&quot; class=&quot;headerlink&quot; title=&quot;那什么是数据仓库呢?&quot;&gt;&lt;/a&gt;那什么是数据仓库呢?&lt;/h2&gt;&lt;p&gt;数据仓库是一个面向主题的，集成的，不可更新的，随时间不变化的数据集合，它用于支持企业或组织的决策分析处理(主要是查询操作),数据仓库实际上就是一个数据库，可以利用数据仓库来保存数据，但是数据仓库有别于我们一般的数据库&lt;/p&gt;
&lt;h2 id=&quot;数据仓库的结构和建立过程&quot;&gt;&lt;a href=&quot;#数据仓库的结构和建立过程&quot; class=&quot;headerlink&quot; title=&quot;数据仓库的结构和建立过程&quot;&gt;&lt;/a&gt;数据仓库的结构和建立过程&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;数据源（业务数据系统，文档资料，其他数据）&lt;br&gt;数据存储和管理（ETL，抽取Extract，转换Transform，装载Load）&lt;br&gt;数据仓库引擎&lt;br&gt;前端展示（数据查询，数据报表，数据分析，各类应用）&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;什么是Hive？&quot;&gt;&lt;a href=&quot;#什么是Hive？&quot; class=&quot;headerlink&quot; title=&quot;什么是Hive？&quot;&gt;&lt;/a&gt;什么是Hive？&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;hive是建立在hadoop hdfs上的数据仓库基础架构,hive中的表和文件其实就是hdfs中的目录和文件&lt;/li&gt;
&lt;li&gt;hive可以用来进行数据提取转化加载（ETL）&lt;/li&gt;
&lt;li&gt;hive定义了简单的类似SQL查询语言（HQL），它允许熟悉SQL的用户查询数据&lt;/li&gt;
&lt;li&gt;hive允许熟悉MapReduce开发者开发自定义的mapper和reducer来处理內建的mapper和reducer无法完成的复杂的分析工作&lt;/li&gt;
&lt;li&gt;hive是SQL解析引擎，它将SQL语句转义成MapReduce Job然后在hadoop上执行&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;hive的元数据&quot;&gt;&lt;a href=&quot;#hive的元数据&quot; class=&quot;headerlink&quot; title=&quot;hive的元数据&quot;&gt;&lt;/a&gt;hive的元数据&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;hive将元数据存储在数据库中（metastore），支持mysql和derby（默认）等数据库&lt;br&gt;hive中的元数据包括表的名字，表的列和分区及其属性，表的属性（是否为外部表等），表的数据所在目录等&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;HQL的执行过程&quot;&gt;&lt;a href=&quot;#HQL的执行过程&quot; class=&quot;headerlink&quot; title=&quot;HQL的执行过程&quot;&gt;&lt;/a&gt;HQL的执行过程&lt;/h2&gt;&lt;p&gt;解释器，编译器，优化器完成HQL查询语句从此法分析，语法分析，编译，优化以及查询计划（plan）的生成。生成的查询计划存储在HDFS中，并在随后又MapReduce调用执行&lt;/p&gt;
&lt;p&gt;HQL执行过程如下：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;HQL select语句&lt;/li&gt;
&lt;li&gt;解释器进行此法分析&lt;/li&gt;
&lt;li&gt;编译器生成HQL的执行计划（类似javac命令，将java文件编译成class文件）&lt;/li&gt;
&lt;li&gt;优化器生成最佳的执行计划&lt;/li&gt;
&lt;li&gt;执行&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&quot;hive的三种安装模式&quot;&gt;&lt;a href=&quot;#hive的三种安装模式&quot; class=&quot;headerlink&quot; title=&quot;hive的三种安装模式&quot;&gt;&lt;/a&gt;hive的三种安装模式&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;&lt;p&gt;嵌入模式&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;元数据信息保存在hive自带的derby数据库中&lt;/li&gt;
&lt;li&gt;只允许创建一个连接&lt;/li&gt;
&lt;li&gt;多用于Demo&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;本地模式&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;元数据信息被存储在MySQL数据库中&lt;/li&gt;
&lt;li&gt;MySQL数据库与Hive运行在同一台物理机器上&lt;/li&gt;
&lt;li&gt;多用于开发和测试&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;远程模式&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;元数据信息被保存在远程的MySQL数据库中&lt;/li&gt;
&lt;li&gt;多用于实际的生产运行环境&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&quot;常用的CLI命令&quot;&gt;&lt;a href=&quot;#常用的CLI命令&quot; class=&quot;headerlink&quot; title=&quot;常用的CLI命令&quot;&gt;&lt;/a&gt;常用的CLI命令&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;进入CLI&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;交互模式&lt;br&gt;hive  # 进入命令行交互模式，非静默&lt;br&gt;hive -S # 静默模式，不显示调试信息&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;直接执行一条语句&lt;br&gt;hive -e ‘show tables’;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;执行一个文件的文件&lt;br&gt;hive -f ~/test.hql&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;清屏&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Ctrl + L或者 !clear;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;查看数据仓库中的表&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;show tables;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;查看数据仓库中内置的函数&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;show functions;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;查看表的结构&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;desc 表名&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;查看HDFS上的文件&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;dfs -ls 目录&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;执行操作系统的命令&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;!命令&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;执行HQL语句&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;select &lt;strong&gt;&lt;em&gt; from &lt;/em&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;执行SQL的脚本&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;source SQL文件&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;hive的数据类型&quot;&gt;&lt;a href=&quot;#hive的数据类型&quot; class=&quot;headerlink&quot; title=&quot;hive的数据类型&quot;&gt;&lt;/a&gt;hive的数据类型&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;基本数据类型&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;tinyint/smallint/int/bigint：整数类型&lt;/li&gt;
&lt;li&gt;float/double：浮点数类型&lt;/li&gt;
&lt;li&gt;boolean：布尔类型&lt;/li&gt;
&lt;li&gt;string：字符串类型&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;复杂数据类型&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Array：数组类型，由一系列相同数据类型的元素组成&lt;/li&gt;
&lt;li&gt;Map：集合类型，包含key-&amp;gt;value，可以通过key来访问元素&lt;/li&gt;
&lt;li&gt;Struct：结构类型，可以包含不同数据类型的元素，这些元素可以通过“点语法”的方式来得到所需要的元素&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;时间类型&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Date：从Hive0.12.0开始支持&lt;/li&gt;
&lt;li&gt;Timestamp：从Hive0.8.0开始支持&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;figure class=&quot;highlight sql&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;TABLE&lt;/span&gt; employees(&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;name&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;STRING&lt;/span&gt;,&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;salary &lt;span class=&quot;built_in&quot;&gt;FLOAT&lt;/span&gt;,&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;subordintes &lt;span class=&quot;built_in&quot;&gt;ARRAY&lt;/span&gt;&amp;lt;&lt;span class=&quot;keyword&quot;&gt;STRING&lt;/span&gt;&amp;gt;,&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;deucations &lt;span class=&quot;keyword&quot;&gt;MAP&lt;/span&gt;&amp;lt;&lt;span class=&quot;keyword&quot;&gt;STRING&lt;/span&gt;, &lt;span class=&quot;built_in&quot;&gt;FLOAT&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;address &lt;span class=&quot;keyword&quot;&gt;STRUCT&lt;/span&gt;&amp;lt;street:&lt;span class=&quot;keyword&quot;&gt;STRING&lt;/span&gt;, city:&lt;span class=&quot;keyword&quot;&gt;STRING&lt;/span&gt;, state:&lt;span class=&quot;keyword&quot;&gt;STRING&lt;/span&gt;, zip:&lt;span class=&quot;built_in&quot;&gt;INT&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;Hive中的数据都是保存在HDFS中&lt;br&gt;没有专门的数据存储格式&lt;br&gt;存储结构主要包括：数据库，文件，表，视图&lt;br&gt;Hive可以直接加载文本文件&lt;br&gt;创建表的时候，指定Hive数据的列分隔符与行分隔符&lt;/p&gt;
&lt;h6 id=&quot;数据库database&quot;&gt;&lt;a href=&quot;#数据库database&quot; class=&quot;headerlink&quot; title=&quot;数据库database&quot;&gt;&lt;/a&gt;数据库database&lt;/h6&gt;&lt;ul&gt;
&lt;li&gt;相当于关系数据库中的命名空间（namespace），它的作用是将用户和数据库的应用隔离到不同的数据库或模式中&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;表&quot;&gt;&lt;a href=&quot;#表&quot; class=&quot;headerlink&quot; title=&quot;表&quot;&gt;&lt;/a&gt;表&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Table内部表&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;与数据库中的Table在概念上是类似的&lt;/li&gt;
&lt;li&gt;每一个Table在Hive中都有一个相应的目录存储数据&lt;/li&gt;
&lt;li&gt;所有的Table数据（不包括External Table）都保存在这个目录中&lt;/li&gt;
&lt;li&gt;删除表的时候，元数据与数据都会被删除&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Partition分区表&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Partition对应于数据库的Partition列的密集索引&lt;/li&gt;
&lt;li&gt;在Hive中，表中的一个Partition对应于表下的一个目录，多有的Partition的数据都存储在对应的目录中&lt;/li&gt;
&lt;li&gt;在数据量特别大的时候，需要将数据按照一定的条件进行分区，这样在进行查询操作的时候能够降低扫描的数据，从而提高查询的效率（通过执行计划知道）&lt;/li&gt;
&lt;li&gt;Hive把表组织成”分区“，这是一种根据“分区列”（如日期）的值对表的数据进行粗略划分的机制。使用分区可以加快数据分片（slice）的查询速度&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;External Table 外部表&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;指向已经存在于HDFS中的数据，也可以创建Patition&lt;/li&gt;
&lt;li&gt;它和内部表在元数据的组织上是相同的，而实际数据的存储则有较大的差异&lt;/li&gt;
&lt;li&gt;外部表只有一个过程，加载数据和创建表同时完成，并不会移动到数据仓库目录中，只是与外部数据建立一个链接。当删除一个外部表是，仅删除该链接&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Bucket Table 桶表&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;桶表是对数据进行哈希取值，然后放到不同文件中存储&lt;/li&gt;
&lt;li&gt;降低系统的热块，从而提高查询的速度&lt;/li&gt;
&lt;li&gt;表和分区可以进一步分为“桶”，它会为数据提供额外的结构以获得更高效的查询处理。例如，可以根据用户ID来划分桶，这则是对数据源数据文件本身来拆分数据。使用桶的表会将源数据文件按一定规律拆分成多个文件，要使用bucket&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;视图&quot;&gt;&lt;a href=&quot;#视图&quot; class=&quot;headerlink&quot; title=&quot;视图&quot;&gt;&lt;/a&gt;视图&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;视图是一种虚表，是一个逻辑概念，不存数据；可以跨越多张表&lt;/li&gt;
&lt;li&gt;视图建立在已有表的基础上，视图赖以建立的这些表成为基表&lt;/li&gt;
&lt;li&gt;视图可以简化复杂的查询&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;内部表和外部表的区别？&quot;&gt;&lt;a href=&quot;#内部表和外部表的区别？&quot; class=&quot;headerlink&quot; title=&quot;内部表和外部表的区别？&quot;&gt;&lt;/a&gt;内部表和外部表的区别？&lt;/h2&gt;&lt;p&gt;内部表也叫做管理表，Hive会控制着数据的生命周期，默认情况下会将这些表的数据存储在由配置项&lt;code&gt;hive.metastore.warehourse.dir&lt;/code&gt;所定义的目录的子目录下&lt;br&gt;当删除一个内部表的时候，Hive也会删除这个表中的数据&lt;/p&gt;
&lt;p&gt;外部表&lt;br&gt;先看一个例子：&lt;/p&gt;
&lt;figure class=&quot;highlight sql&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;18&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;create&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;external&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;table&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;exists&lt;/span&gt; pimaccess(&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    accesstime &lt;span class=&quot;built_in&quot;&gt;BIGINT&lt;/span&gt;,&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;keyword&quot;&gt;account&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;STRING&lt;/span&gt;,&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    ip &lt;span class=&quot;keyword&quot;&gt;STRING&lt;/span&gt;,&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    appkey &lt;span class=&quot;keyword&quot;&gt;STRING&lt;/span&gt;,&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    prelinkmannum &lt;span class=&quot;built_in&quot;&gt;INT&lt;/span&gt;,&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    aftlinkmannum &lt;span class=&quot;built_in&quot;&gt;INT&lt;/span&gt;,&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    pregroupnum &lt;span class=&quot;built_in&quot;&gt;INT&lt;/span&gt;,&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    aftgroupnum &lt;span class=&quot;built_in&quot;&gt;INT&lt;/span&gt;,&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    resultcode &lt;span class=&quot;built_in&quot;&gt;INT&lt;/span&gt;,&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    costtime &lt;span class=&quot;built_in&quot;&gt;INT&lt;/span&gt;,&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    requesttype &lt;span class=&quot;built_in&quot;&gt;INT&lt;/span&gt;,&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    responsetype &lt;span class=&quot;built_in&quot;&gt;INT&lt;/span&gt;,&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    apiname &lt;span class=&quot;keyword&quot;&gt;STRING&lt;/span&gt;,&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    requestdata &lt;span class=&quot;keyword&quot;&gt;STRING&lt;/span&gt;,&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    responsedata &lt;span class=&quot;keyword&quot;&gt;STRING&lt;/span&gt;,&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    rtime &lt;span class=&quot;keyword&quot;&gt;STRING&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;)&lt;span class=&quot;keyword&quot;&gt;ROW&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;FORMAT&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;DELIMITED&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;FIELDS&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;TERMINATED&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;&#39;\t&#39;&lt;/span&gt; LOCATION &lt;span class=&quot;string&quot;&gt;&#39;/pimaccess&#39;&lt;/span&gt;;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;在创建表的时候使用&lt;code&gt;EXTENAL&lt;/code&gt;关键字，用来告诉Hive这个表是外部表，&lt;code&gt;LOCATION&lt;/code&gt;子句则用于告诉Hive数据位于哪个路径下。&lt;br&gt;对于外部表，Hive认为没有完全拥有这份数据，因此在删除该表的时候不会删除掉这份数据，不过描述表的元数据信息会被删除。&lt;/p&gt;
&lt;h2 id=&quot;Hive常见的数据导入方式&quot;&gt;&lt;a href=&quot;#Hive常见的数据导入方式&quot; class=&quot;headerlink&quot; title=&quot;Hive常见的数据导入方式&quot;&gt;&lt;/a&gt;Hive常见的数据导入方式&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;从本地文件系统中导入&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;load data local inpath ‘test.txt’ into table test;&lt;/li&gt;
&lt;li&gt;load data local inpath ‘test.txt’ overwrite into table test;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;从HDFS上导入&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;load data inpath ‘/test.txt’ into table test;&lt;/li&gt;
&lt;li&gt;load data inpath ‘/test.txt’ overwrite into table test;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;从别的表中查询出相应数据并导入 &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;insert into table test partition(age=’25’) select id, name, tel from test;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;在创建表的时候通过从别的表中查询出相应的记录并插入到所创建的表中&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;create table test2 as select id, name, tel from test;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;Hive是建立在 Hadoop 上的数据仓库基础构架。它提供了一系列的工具，可以用来进行数据提取转化加载（ETL），这是一种可以存储、查询和分析存储在 Hadoop 中的大规模数据的机制。&lt;br&gt;
    
    </summary>
    
    
      <category term="bigdata" scheme="http://dxer.github.io/tags/bigdata/"/>
    
      <category term="hive" scheme="http://dxer.github.io/tags/hive/"/>
    
  </entry>
  
  <entry>
    <title>zookeeper伪集群模式安装和配置</title>
    <link href="http://dxer.github.io/2016/03/07/zookeeper01/"/>
    <id>http://dxer.github.io/2016/03/07/zookeeper01/</id>
    <published>2016-03-07T02:25:38.000Z</published>
    <updated>2016-04-28T10:39:34.349Z</updated>
    
    <content type="html">&lt;p&gt;伪分布式集群：在一台Server中，启动多个ZooKeeper的实例。&lt;br&gt;下面来看看zookeeper怎么进行安装的吧。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;下载&quot;&gt;&lt;a href=&quot;#下载&quot; class=&quot;headerlink&quot; title=&quot;下载&quot;&gt;&lt;/a&gt;下载&lt;/h2&gt;&lt;p&gt;选择一个稳定版本进行下载，我这里下载的是zookeeper-3.4.6版本。&lt;/p&gt;
&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;wget http://mirror.bit.edu.cn/apache/zookeeper/zookeeper-3.4.6/zookeeper-3.4.6.tar.gz&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h2 id=&quot;解压&quot;&gt;&lt;a href=&quot;#解压&quot; class=&quot;headerlink&quot; title=&quot;解压&quot;&gt;&lt;/a&gt;解压&lt;/h2&gt;&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;tar -zxvf  zookeeper-3.4.6.tar.gz&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# 3个实例，复制三份 zk1，zk2，zk3&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;cp -r zookeeper-3.4.6 zk1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;cp -r zookeeper-3.4.6 zk2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;cp -r zookeeper-3.4.6 zk3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h2 id=&quot;创建实例配置文件&quot;&gt;&lt;a href=&quot;#创建实例配置文件&quot; class=&quot;headerlink&quot; title=&quot;创建实例配置文件&quot;&gt;&lt;/a&gt;创建实例配置文件&lt;/h2&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;cd zookeeper-3.4.6/conf&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;cp zoo_sample.cfg zoo1.cfg&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;cp zoo_sample.cfg zoo2.cfg&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;cp zoo_sample.cfg zoo3.cfg&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h2 id=&quot;修改配置&quot;&gt;&lt;a href=&quot;#修改配置&quot; class=&quot;headerlink&quot; title=&quot;修改配置&quot;&gt;&lt;/a&gt;修改配置&lt;/h2&gt;&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;tickTime=2000  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;dataDir=/opt/zk1/data  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;clientPort=2181  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;initLimit=10  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;syncLimit=5  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;server.1=127.0.0.1:2881:3881  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;server.2=127.0.0.1:2882:3882  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;server.3=127.0.0.1:2883:3883&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;ol&gt;
&lt;li&gt;分别配置三个实例的clientPort端口为2181, 2182, 2183&lt;/li&gt;
&lt;li&gt;分别配置是哪个实例的dataDir目录为&lt;code&gt;/opt/zk1/data&lt;/code&gt;，&lt;code&gt;/opt/zk2/data&lt;/code&gt;，&lt;code&gt;/opt/zk3/data&lt;/code&gt;，并创建这三个目录,没有创建该目录会启动出错&lt;/li&gt;
&lt;li&gt;定义zookeeper集群的各个实例的ip和端口，server.1=127.0.0.1:2881:3881 ,server.2=127.0.0.1:2882:3882,server.3=127.0.0.1:2883:3883 &lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;解释：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;dataDir&lt;br&gt;定义zookeeper实例存储持久出具的本地文件系统位置&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;clientPort&lt;br&gt;定义zookeeper客户端连接zookeeper服务端时使用的端口&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;server&lt;br&gt;定义zookeeper集群的各个实例的ip和端口&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;tickTime&lt;br&gt;指定了zookeeper中的基本时间单元（以毫秒为单位）&lt;br&gt;zookeeper集群中，每个服务器都有一个id（数字），服务器id在集群中是唯一的，并且取值范围是1~255，通过一个名为myid的纯文本设置，这个文件保存在dataDir中&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;server.n=hostname:port:port&lt;br&gt;n是服务器id，第一个port是follower用来连接leader的端口，第二个port是用于leader选举&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;clientPort&lt;br&gt;监听client连接的端口号&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;initLimit&lt;br&gt;设定了所有follower与leader进行连接并同步的时间范围。如果在设定的时间段内，半数以上的follower跟随者未能完成同步，leader会宣布放弃领导地位，然后进行另外一次leader选举，如果这种情况经常发生，则表明设定的值太小&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;syncLimit&lt;br&gt;设定了允许一个follower与leader这进行同步的时间。如果在设定的时间段内，一个follower未能完成同步，会自己重启，所有关联到follower的客户端将连接到另一个follower&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;h6 id=&quot;创建dataDir和实例id文件&quot;&gt;&lt;a href=&quot;#创建dataDir和实例id文件&quot; class=&quot;headerlink&quot; title=&quot;创建dataDir和实例id文件&quot;&gt;&lt;/a&gt;创建dataDir和实例id文件&lt;/h6&gt;&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;mkdir -p /opt/zk1/data  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;mkdir -p /opt/zk2/data  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;mkdir -p /opt/zk3/data  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;built_in&quot;&gt;echo&lt;/span&gt; 1 &amp;gt; /opt/zk1/data/myid  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;built_in&quot;&gt;echo&lt;/span&gt; 2 &amp;gt; /opt/zk2/data/myid  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;built_in&quot;&gt;echo&lt;/span&gt; 3 &amp;gt; /opt/zk3/data/myid&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h2 id=&quot;启动zookeeper服务&quot;&gt;&lt;a href=&quot;#启动zookeeper服务&quot; class=&quot;headerlink&quot; title=&quot;启动zookeeper服务&quot;&gt;&lt;/a&gt;启动zookeeper服务&lt;/h2&gt;&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;bin/zkServer.sh start zoo1.cfg&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;bin/zkServer.sh start zoo2.cfg&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;bin/zkServer.sh start zoo3.cfg&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h2 id=&quot;查看是否启动成功&quot;&gt;&lt;a href=&quot;#查看是否启动成功&quot; class=&quot;headerlink&quot; title=&quot;查看是否启动成功&quot;&gt;&lt;/a&gt;查看是否启动成功&lt;/h2&gt;&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;jps&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;blockquote&gt;
&lt;p&gt;看到类似下面的进程就表示3个实例均启动成功&lt;br&gt;13419 QuorumPeerMain&lt;br&gt;13460 QuorumPeerMain&lt;br&gt;13561 Jps&lt;br&gt;13392 QuorumPeerMain&lt;br&gt;如果未成功启动，可以到zookeeper.out文件中查看启动失败的日志信息。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;客户端连接&quot;&gt;&lt;a href=&quot;#客户端连接&quot; class=&quot;headerlink&quot; title=&quot;客户端连接&quot;&gt;&lt;/a&gt;客户端连接&lt;/h2&gt;&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;./zkCli.sh -server 127.0.0.1:2181&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h2 id=&quot;关闭zookeeper&quot;&gt;&lt;a href=&quot;#关闭zookeeper&quot; class=&quot;headerlink&quot; title=&quot;关闭zookeeper&quot;&gt;&lt;/a&gt;关闭zookeeper&lt;/h2&gt;&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;bin/zkServer.sh stop&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h2 id=&quot;重启zookeeper&quot;&gt;&lt;a href=&quot;#重启zookeeper&quot; class=&quot;headerlink&quot; title=&quot;重启zookeeper&quot;&gt;&lt;/a&gt;重启zookeeper&lt;/h2&gt;&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;bin/zkServer.sh restart&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;伪分布式集群：在一台Server中，启动多个ZooKeeper的实例。&lt;br&gt;下面来看看zookeeper怎么进行安装的吧。&lt;br&gt;
    
    </summary>
    
    
      <category term="zookeeper" scheme="http://dxer.github.io/tags/zookeeper/"/>
    
  </entry>
  
  <entry>
    <title>Neo4j - Cypher</title>
    <link href="http://dxer.github.io/2015/12/02/neo4j-cypher/"/>
    <id>http://dxer.github.io/2015/12/02/neo4j-cypher/</id>
    <published>2015-12-02T04:17:19.000Z</published>
    <updated>2016-05-13T01:13:39.707Z</updated>
    
    <content type="html">&lt;p&gt;Neo4j是一种图数据库。它将结构化数据存储在图上而不是传统的数据库表中。 相对于关系数据库来说，图数据库善于处理大量复杂、互连接、低结构化的数据，这些数据变化迅速，需要频繁的查询。在关系数据库中， 这些查询会导致大量的表连接，因此会产生性能上的问题,但是使用Neo4j就可以解决查询时出现的性能衰退问题。 同时Neo4j还提供了非常快的图算法、推荐系统和OLAP风格的分析。下面主要简单记录一下Cypher查询语言的使用方法。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;这个查询语言包含以下几个明显的部分：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;START：在图中的开始点，通过元素的ID或所以查找获得。&lt;/li&gt;
&lt;li&gt;MATCH：图形的匹配模式，束缚于开始点。&lt;/li&gt;
&lt;li&gt;WHERE：过滤条件。&lt;/li&gt;
&lt;li&gt;RETURN：返回所需要的。&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Operators&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Mathematical&lt;/td&gt;
&lt;td&gt;+, -, *, /, %, ^&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Comparison&lt;/td&gt;
&lt;td&gt;=, &amp;lt;&amp;gt;, &amp;lt;, &amp;gt;, &amp;lt;=, &amp;gt;=&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Boolean&lt;/td&gt;
&lt;td&gt;AND, OR, XOR, NOT&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;String&lt;/td&gt;
&lt;td&gt;+&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Collection&lt;/td&gt;
&lt;td&gt;+, IN, [x], [x .. y]&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Regular Expression&lt;/td&gt;
&lt;td&gt;=~&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;String matching&lt;/td&gt;
&lt;td&gt;STARTS WITH, ENDS WITH, CONTAINS&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h4 id=&quot;Create&quot;&gt;&lt;a href=&quot;#Create&quot; class=&quot;headerlink&quot; title=&quot;Create&quot;&gt;&lt;/a&gt;Create&lt;/h4&gt;&lt;ol&gt;
&lt;li&gt;&lt;p&gt;创建节点&lt;/p&gt;
&lt;figure class=&quot;highlight sql&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;17&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;-- 创建单节点&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;CREATE&lt;/span&gt; (n)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;-- 创建多节点&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;CREATE&lt;/span&gt; (n),(m)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt; &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;-- 创建一个节点并含有一个label&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;CREATE&lt;/span&gt; (n:Person) &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;-- 创建一个节点并含有多个label&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;CREATE&lt;/span&gt; (n:Person:Swedish) &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;-- 创建一个节点并含有label和properties&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;CREATE&lt;/span&gt; (n:Person &amp;#123; &lt;span class=&quot;keyword&quot;&gt;name&lt;/span&gt; : &lt;span class=&quot;string&quot;&gt;&#39;Andres&#39;&lt;/span&gt;, title : &lt;span class=&quot;string&quot;&gt;&#39;Developer&#39;&lt;/span&gt; &amp;#125;) &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;-- 创建一个节点并返回该节点&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;CREATE&lt;/span&gt; (a &amp;#123; &lt;span class=&quot;keyword&quot;&gt;name&lt;/span&gt; : &lt;span class=&quot;string&quot;&gt;&#39;Andres&#39;&lt;/span&gt; &amp;#125;) &lt;span class=&quot;keyword&quot;&gt;RETURN&lt;/span&gt; a&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;创建关系&lt;/p&gt;
&lt;figure class=&quot;highlight sql&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;MATCH (a:Person),(b:Person)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;WHERE a.name = &#39;Node A&#39; AND b.name = &#39;Node B&#39;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;CREATE&lt;/span&gt; (a)-[r:RELTYPE]-&amp;gt;(b)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;RETURN&lt;/span&gt; r&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;创建关系并设置属性&lt;/p&gt;
&lt;figure class=&quot;highlight sql&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;MATCH (a:Person),(b:Person)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;WHERE a.name = &#39;Node A&#39; AND b.name = &#39;Node B&#39;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;CREATE&lt;/span&gt; (a)-[r:RELTYPE &amp;#123; &lt;span class=&quot;keyword&quot;&gt;name&lt;/span&gt; : a.name + &lt;span class=&quot;string&quot;&gt;&#39;&amp;lt;-&amp;gt;&#39;&lt;/span&gt; + b.name &amp;#125;]-&amp;gt;(b)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;RETURN&lt;/span&gt; r&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&quot;Merge&quot;&gt;&lt;a href=&quot;#Merge&quot; class=&quot;headerlink&quot; title=&quot;Merge&quot;&gt;&lt;/a&gt;Merge&lt;/h4&gt;&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Use ON CREATE and ON MATCH&lt;/p&gt;
&lt;figure class=&quot;highlight sql&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;MERGE&lt;/span&gt; (keanu:Person &amp;#123; &lt;span class=&quot;keyword&quot;&gt;name&lt;/span&gt;:&lt;span class=&quot;string&quot;&gt;&#39;Keanu Reeves&#39;&lt;/span&gt; &amp;#125;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;ON&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;SET&lt;/span&gt; keanu.created = &lt;span class=&quot;keyword&quot;&gt;timestamp&lt;/span&gt;()&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;RETURN&lt;/span&gt; keanu.name, keanu.created&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Merge with ON CREATE and ON MATCH&lt;/p&gt;
&lt;figure class=&quot;highlight sql&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;MERGE&lt;/span&gt; (keanu:Person &amp;#123; &lt;span class=&quot;keyword&quot;&gt;name&lt;/span&gt;:&lt;span class=&quot;string&quot;&gt;&#39;Keanu Reeves&#39;&lt;/span&gt; &amp;#125;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;ON&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;SET&lt;/span&gt; keanu.created = &lt;span class=&quot;keyword&quot;&gt;timestamp&lt;/span&gt;()&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;ON&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;MATCH&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;SET&lt;/span&gt; keanu.lastSeen = &lt;span class=&quot;keyword&quot;&gt;timestamp&lt;/span&gt;()&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;RETURN&lt;/span&gt; keanu.name, keanu.created, keanu.lastSeen&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Merge relationships&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;MATCH (charlie:Person &amp;#123; name:&#39;Charlie Sheen&#39; &amp;#125;),(wallStreet:Movie &amp;#123; title:&#39;Wall Street&#39; &amp;#125;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;MERGE (charlie)-[r:ACTED_IN]-&amp;gt;(wallStreet)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;RETURN charlie.name, type(r), wallStreet.title&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;MATCH (oliver:Person &amp;#123; name:&#39;Oliver Stone&#39; &amp;#125;),(reiner:Person &amp;#123; name:&#39;Rob Reiner&#39; &amp;#125;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;MERGE (oliver)-[:DIRECTED]-&amp;gt;(movie:Movie)&amp;lt;-[:ACTED_IN]-(reiner)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;RETURN movie&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h3 id=&quot;查询&quot;&gt;&lt;a href=&quot;#查询&quot; class=&quot;headerlink&quot; title=&quot;查询&quot;&gt;&lt;/a&gt;查询&lt;/h3&gt;&lt;p&gt;语法&lt;br&gt;&lt;figure class=&quot;highlight sql&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;[MATCH WHERE] &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;[OPTIONAL MATCH WHERE] &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;[WITH [ORDER BY] [SKIP] [LIMIT]] &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;RETURN [ORDER BY] [SKIP] [LIMIT]&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;示例&lt;br&gt;&lt;figure class=&quot;highlight&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;MATCH (n:Person)-[:KNOWS]-&amp;gt;(m:Person)WHERE n.name=&quot;Alice&quot;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Node patterns can contain labels and properties.&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;MATCH (n)--&amp;gt;(m)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Any pattern can be used in MATCH.&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;MATCH (n &amp;#123;name:&#39;Alice&#39;&amp;#125;)--&amp;gt;(m)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Patterns with node properties.&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;MATCH p = (n)--&amp;gt;(m)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Assign a path to p.&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;OPTIONAL MATCH (n)-[r]-&amp;gt;(m)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Optional pattern, NULLs will be used for missing parts&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h3 id=&quot;唯一约束&quot;&gt;&lt;a href=&quot;#唯一约束&quot; class=&quot;headerlink&quot; title=&quot;唯一约束&quot;&gt;&lt;/a&gt;唯一约束&lt;/h3&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;CREATE CONSTRAINT ON (p:Person) ASSERT p.name IS UNIQUE&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;DROP CONSTRAINT ON (p:Person) ASSERT p.name IS UNIQUE&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h3 id=&quot;索引&quot;&gt;&lt;a href=&quot;#索引&quot; class=&quot;headerlink&quot; title=&quot;索引&quot;&gt;&lt;/a&gt;索引&lt;/h3&gt;&lt;figure class=&quot;highlight sql&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1. 创建索引&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;INDEX&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;ON&lt;/span&gt; :Person(&lt;span class=&quot;keyword&quot;&gt;name&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;number&quot;&gt;2.&lt;/span&gt; 删除索引&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;DROP&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;INDEX&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;ON&lt;/span&gt; :Person(&lt;span class=&quot;keyword&quot;&gt;name&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h2 id=&quot;参考&quot;&gt;&lt;a href=&quot;#参考&quot; class=&quot;headerlink&quot; title=&quot;参考:&quot;&gt;&lt;/a&gt;参考:&lt;/h2&gt;&lt;p&gt;&lt;a href=&quot;http://neo4j.com/docs/stable/cypher-query-lang.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;neo4j官网Cypher文档&lt;/a&gt;&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;Neo4j是一种图数据库。它将结构化数据存储在图上而不是传统的数据库表中。 相对于关系数据库来说，图数据库善于处理大量复杂、互连接、低结构化的数据，这些数据变化迅速，需要频繁的查询。在关系数据库中， 这些查询会导致大量的表连接，因此会产生性能上的问题,但是使用Neo4j就可以解决查询时出现的性能衰退问题。 同时Neo4j还提供了非常快的图算法、推荐系统和OLAP风格的分析。下面主要简单记录一下Cypher查询语言的使用方法。&lt;br&gt;
    
    </summary>
    
    
      <category term="Neo4j" scheme="http://dxer.github.io/tags/Neo4j/"/>
    
      <category term="Cypher" scheme="http://dxer.github.io/tags/Cypher/"/>
    
  </entry>
  
  <entry>
    <title>Neo4j</title>
    <link href="http://dxer.github.io/2015/12/02/neo4j-01/"/>
    <id>http://dxer.github.io/2015/12/02/neo4j-01/</id>
    <published>2015-12-02T01:13:19.000Z</published>
    <updated>2016-04-29T07:35:08.003Z</updated>
    
    <content type="html">&lt;p&gt;最近在用图形数据库来完成对项目的支持。在使用过程中觉得这种图形数据库实际上挺有意思的。因此在这里给大家做一个简单的介绍。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;图数据库&quot;&gt;&lt;a href=&quot;#图数据库&quot; class=&quot;headerlink&quot; title=&quot;图数据库&quot;&gt;&lt;/a&gt;图数据库&lt;/h2&gt;&lt;p&gt;图形数据库是一种非关系型数据库，它应用图形理论存储实体之间的关系信息。最常见的一个例子，就是社会网络中人与人之间的关系。关系型数据库用于存储“关系型”数据的效果并不好，其查询复杂、缓慢、超出预期，而图形数据库的独特设计恰恰弥补了这个缺陷。&lt;/p&gt;
&lt;h2 id=&quot;Neo4j&quot;&gt;&lt;a href=&quot;#Neo4j&quot; class=&quot;headerlink&quot; title=&quot;Neo4j&quot;&gt;&lt;/a&gt;Neo4j&lt;/h2&gt;&lt;p&gt;Neo4j是一个流行的图形数据库，它是开源的。Neo4j基于Java实现，兼容ACID特性，也支持其他编程语言，如Ruby和Python。&lt;/p&gt;
&lt;p&gt;Neo4j是一个高性能的,NOSQL图形数据库，它将结构化数据存储在网络上而不是表中。Neo4j 使用图（graph）相关的概念来描述数据模型，把数据保存为图中的节点以及节点之间的关系。很多应用中数据之间的关系，可以很直接地使用图中节点和关系的概念来建模。对于这样的应用，使用 Neo4j 来存储数据会非常的自然，要优于使用关系数据库。&lt;/p&gt;
&lt;p&gt;Neo4j 使用数据结构中图（graph）的概念来进行建模。Neo4j 中两个最基本的概念是节点和边。节点表示实体，边则表示实体之间的关系。节点和边都可以有自己的属性。不同实体通过各种不同的关系关联起来，形成复杂的对象图。Neo4j 同时提供了在对象图上进行查找和遍历的功能。&lt;/p&gt;
&lt;h3 id=&quot;Neo4j特点&quot;&gt;&lt;a href=&quot;#Neo4j特点&quot; class=&quot;headerlink&quot; title=&quot;Neo4j特点&quot;&gt;&lt;/a&gt;Neo4j特点&lt;/h3&gt;&lt;p&gt;作为一款强健的，可伸缩的高性能数据库，Neo4j最适合完整的企业部署或者用于一个轻量级项目中完整服务器的一个子集存在。&lt;/p&gt;
&lt;p&gt;它包括如下几个显著特点:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;完整的ACID支持&lt;/li&gt;
&lt;li&gt;高可用性&lt;/li&gt;
&lt;li&gt;轻易扩展到上亿级别的节点和关系&lt;/li&gt;
&lt;li&gt;通过遍历工具高速检索数据&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;适当的ACID操作是保证数据一致性的基础。Neo4j确保了在一个事务里面的多个操作同时发生，保证数据一致性。不管是采用嵌入模式还是多服务器集群部署，都支持这一特性。&lt;/p&gt;
&lt;p&gt;可靠的图型存储可以非常轻松的集成到任何一个应用中。随着我们开发的应用在运营中不断发展，性能问题肯定会逐步凸显出来，而Neo4j不管应用如何变化，他只会受到计算机硬件性能的影响，不受业务本身的约束。&lt;/p&gt;
&lt;p&gt;部署一个neo4j服务器便可以承载上亿级的节点和关系。当然，当单节点无法承载我们的数据需求时，我们可以进行分布式集群部署（含有集群方案的版本是商业版）。&lt;/p&gt;
&lt;p&gt;将图数据库用于存储关系复杂的数据是他最大的优势。通过Neo4j提供的遍历工具，可以非常高效的进行数据检索，每秒可以达到上亿级的检索量。一个检索操作类似于RDBMS里面的连接（&lt;em&gt;join&lt;/em&gt;）操作。&lt;/p&gt;
&lt;h3 id=&quot;Cypher查询语言&quot;&gt;&lt;a href=&quot;#Cypher查询语言&quot; class=&quot;headerlink&quot; title=&quot;Cypher查询语言&quot;&gt;&lt;/a&gt;Cypher查询语言&lt;/h3&gt;&lt;p&gt;&lt;em&gt;Cypher&lt;/em&gt;查询语言，是一种不需要手动遍历图结构数据，就可高效完成查询功能的陈述性查询语言。Cypher用于在图数据库中存储和检索数据，可以实现对Neo4j数据库的添加、删除及更新操作。Cypher受启于陈述性查询语言，很多关键字如WHERE、ORDER BY等来源于SQL；模式匹配方法来源于SPARQL。Cypher语言更专注于检索内容的图结构形式化描述，而不是实现。&lt;/p&gt;
&lt;p&gt;在查询语言中包含以下几个明显的部分：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;START：在图中的开始点，通过元素的ID或所以查找获得。&lt;/li&gt;
&lt;li&gt;MATCH：图形的匹配模式，束缚于开始点。&lt;/li&gt;
&lt;li&gt;WHERE：过滤条件。&lt;/li&gt;
&lt;li&gt;RETURN：返回所需要的。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;使用Neo4j图数据库的优势&quot;&gt;&lt;a href=&quot;#使用Neo4j图数据库的优势&quot; class=&quot;headerlink&quot; title=&quot;使用Neo4j图数据库的优势&quot;&gt;&lt;/a&gt;使用Neo4j图数据库的优势&lt;/h3&gt;&lt;p&gt;使用Neo4j图数据库的优势如下：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;自带一套易于学习的Cypher查询语言，减少在开发过程中的学习成本；&lt;/li&gt;
&lt;li&gt;与关系型数据库相比，对于高度关联的数据（图形数据）的查询快速要快上许多；&lt;/li&gt;
&lt;li&gt;它的实体与关系结构非常自然地切合人类的直观感受；&lt;/li&gt;
&lt;li&gt;支持兼容ACID的事务操作；&lt;/li&gt;
&lt;li&gt;提供了一个高可用性模型，以支持大规模数据量的查询，支持备份、数据局部性以及冗余；&lt;/li&gt;
&lt;li&gt;提供了一个可视化的查询控制台，方便在控制台进行查询操作。&lt;/li&gt;
&lt;/ol&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;最近在用图形数据库来完成对项目的支持。在使用过程中觉得这种图形数据库实际上挺有意思的。因此在这里给大家做一个简单的介绍。&lt;br&gt;
    
    </summary>
    
    
      <category term="Neo4j" scheme="http://dxer.github.io/tags/Neo4j/"/>
    
      <category term="NoSQL" scheme="http://dxer.github.io/tags/NoSQL/"/>
    
  </entry>
  
  <entry>
    <title>【Hadoop学习】Hadoop配额实战</title>
    <link href="http://dxer.github.io/2015/11/23/hadoop_quota/"/>
    <id>http://dxer.github.io/2015/11/23/hadoop_quota/</id>
    <published>2015-11-23T06:46:19.000Z</published>
    <updated>2016-06-12T09:24:01.634Z</updated>
    
    <content type="html">&lt;p&gt;在HDFS中，管理员可以为每一个目录设置基于名称或者空间上的配额。可以设置名称配额和空间配额，名称配额和空间配额可以单独设置。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&quot;名称配额（Name-Quota）&quot;&gt;&lt;a href=&quot;#名称配额（Name-Quota）&quot; class=&quot;headerlink&quot; title=&quot;名称配额（Name Quota）&quot;&gt;&lt;/a&gt;名称配额（Name Quota）&lt;/h3&gt;&lt;p&gt;名称配额是在对应的目录下所有文件和目录名称的数量上的限制。当超过这个配额的时候，文件或目录就会创建失败，重命名后名称配额仍然有效。如果重命名操作违反配额的限制，那么重命名会失败，新建的目录不会有任何配额设置，名字配额的上限是Long.Max_Value，如果配额为1，那么这个目录会强制为空，因为目录自身也会占用1个配额。配额的设置是持久化在fsimage中，如果fsimage发现违反了配额限制，会输出警告。&lt;/p&gt;
&lt;p&gt;只有管理员可以设置名称配额和空间配额。下面的命令设置/清理名称配额：&lt;/p&gt;
&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# 设置目录的名称配额&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;hdfs dfsadmin -setQuota N &amp;lt;DirName&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# 清除目录的名称配额&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;hdfs dfsadmin -clrQuota &amp;lt;DirName&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# 查询目录的配额和当前可用余额&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;hdfs dfs -count -q &amp;lt;DirName&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h3 id=&quot;空间配额（Space-Quota）&quot;&gt;&lt;a href=&quot;#空间配额（Space-Quota）&quot; class=&quot;headerlink&quot; title=&quot;空间配额（Space Quota）&quot;&gt;&lt;/a&gt;空间配额（Space Quota）&lt;/h3&gt;&lt;p&gt;空间配额是目录的空间大小限制。如果超过这个配额，块写入操作会失败。副本也算配额中的一部分。空间配额为0的时候，可以创建文件，但是不能向文件中写入内容。创建空间配额的命令如下:&lt;/p&gt;
&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# 设置目录的空间配额&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;hdfs dfsadmin -setSpaceQuota &amp;lt;quota&amp;gt; &amp;lt;dirname&amp;gt;...&amp;lt;dirname&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# 清除目录的空间配额&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;hdfs dfsadmin -clrSpaceQuota &amp;lt;dirname&amp;gt;...&amp;lt;dirname&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# 查询目录的配额和当前可用余额&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;hdfs dfs -count -q &amp;lt;DirName&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;其中可以通过&lt;br&gt;&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;fs -count -q directory ... directory&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;使用-q选项，可以显示目录的名称配额，剩余名称配额，空间配额，可用空间配额。如果目录没有设置配额，会显示为none和inf。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;在HDFS中，管理员可以为每一个目录设置基于名称或者空间上的配额。可以设置名称配额和空间配额，名称配额和空间配额可以单独设置。&lt;br&gt;
    
    </summary>
    
    
      <category term="hadoop" scheme="http://dxer.github.io/tags/hadoop/"/>
    
  </entry>
  
  <entry>
    <title>【Hadoop学习】YARN学习</title>
    <link href="http://dxer.github.io/2015/11/03/yarn/"/>
    <id>http://dxer.github.io/2015/11/03/yarn/</id>
    <published>2015-11-03T06:46:19.000Z</published>
    <updated>2016-05-25T03:40:23.138Z</updated>
    
    <content type="html">&lt;p&gt;YARN采用Master/Slave架构，ResourceManager为Master，NodeManager为Slave。ResourceManager负责对各个NodeManager上的资源进行统一管理和调度，当用户提交一个应用程序时，需要提供一个用来跟踪和管理这个程序的ApplicationMaster，它负责向ResourceManager申请资源，并要求NodeManager启动可以占用一定资源的任务。由于不同的ApplicationMaster被分布到不同的节点上，因此它们之间不会相互影响。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;ResourceManager&quot;&gt;&lt;a href=&quot;#ResourceManager&quot; class=&quot;headerlink&quot; title=&quot;ResourceManager&quot;&gt;&lt;/a&gt;ResourceManager&lt;/h2&gt;&lt;p&gt;ResourceManager简称RM，是一个全局的资源管理器，负责整个系统的资源管理和分配工作。主要由调度器（Scheduler）和应用程序管理器（Applications Master，ASM）两部分组成。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;调度器（Scheduler）&lt;br&gt;调度器根据容量，队列等限制条件将系统中的资源分配给各个正在运行的应用程序。&lt;/li&gt;
&lt;li&gt;应用程序管理器（Applications Master）&lt;br&gt;ApplicationMaster负责管理整个系统中所有应用程序，包括应用程序提交、与调度器协商资源以启动ApplicationMaster，监控ApplicationMaster运行状态并在失败时重新启动它等。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&quot;ApplicationMaster&quot;&gt;&lt;a href=&quot;#ApplicationMaster&quot; class=&quot;headerlink&quot; title=&quot;ApplicationMaster&quot;&gt;&lt;/a&gt;ApplicationMaster&lt;/h2&gt;&lt;p&gt;ApplicationMaster简称AM。YARN中每个应用都会启动一个AM。&lt;br&gt;主要功能包括：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;与RM调度器协商以获取资源&lt;/li&gt;
&lt;li&gt;将得到的任务进一步分配给内部的任务&lt;/li&gt;
&lt;li&gt;与NM通信以启动/停止任务&lt;/li&gt;
&lt;li&gt;监控所有任务运行状态，并在任务失败时重新为任务申请资源以重新运行任务&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&quot;NodeManager&quot;&gt;&lt;a href=&quot;#NodeManager&quot; class=&quot;headerlink&quot; title=&quot;NodeManager&quot;&gt;&lt;/a&gt;NodeManager&lt;/h2&gt;&lt;p&gt;NodeManager简称NM，NM是每个节点上的资源和任务管理器&lt;br&gt;主要功能包括：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;定时向RM汇报本节点上的资源使用情况和各个Continer的运行状态&lt;/li&gt;
&lt;li&gt;接收并处理来自AM的Container启动/停止等各种请求&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&quot;Container&quot;&gt;&lt;a href=&quot;#Container&quot; class=&quot;headerlink&quot; title=&quot;Container&quot;&gt;&lt;/a&gt;Container&lt;/h2&gt;&lt;p&gt;Container是YARN中资源容器。它封装了某个节点上的多维度资源，如内存、cpu、磁盘、网络等。YARN中所有的应用都是在container上运行的。AM也是在container上运行的，不过AM的container是向RM申请的。YARN会为每一个任务分配一个Container，并且该任务只能使用该Container中描述的资源。&lt;/p&gt;
&lt;h2 id=&quot;YARN工作流程&quot;&gt;&lt;a href=&quot;#YARN工作流程&quot; class=&quot;headerlink&quot; title=&quot;YARN工作流程&quot;&gt;&lt;/a&gt;YARN工作流程&lt;/h2&gt;&lt;p&gt;YARN上运行的应用程序主要分为两类：短应用程序和长应用程序。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;短应用程序是指一定时间内（可能是秒级、分钟级或小时级，尽管天级别或者更长时间的也存在，但是非常少）可运行完成并征程退出的应用程序&lt;/li&gt;
&lt;li&gt;长应用程序是指不出意外，永不终止运行的应用程序，通常是一些服务，如Storm，HBase等&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;YARN的工作流程包括：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;向YARN中提交一个应用程序，其中包括ApplicationMaster程序，启动ApplicationMaster的命令，用户程序等&lt;/li&gt;
&lt;li&gt;ResourceManager为该应用程序分配一个Container，并与对应的NodeManager通信，要求它在这个Container中启动应用程序的ApplicationMaster&lt;/li&gt;
&lt;li&gt;ApplicationMaster首先向ResourceManager注册（注册之后可以直接通过ResourceManager查看应用程序的运行状态），然后它将为各个任务申请资源，并监控它的运行状态，直到运行结束&lt;/li&gt;
&lt;li&gt;ApplicationMaster采用轮询的方式通过RPC协议向ResourceManager申请和领取资源&lt;/li&gt;
&lt;li&gt;一旦ApplicationMaster申请到资源后，便与对应的NodeManager通信，要求它启动任务&lt;/li&gt;
&lt;li&gt;NodeManager为任务设置好运行环境（包括环境变量，jar包，二进制程序等）后，将任务启动命令写到一个脚本中，并通过运行该脚本启动任务&lt;/li&gt;
&lt;li&gt;各个任务通过RPC协议向ApplicationMaster汇报自己的状态和进度，使得ApplicationMaster随时掌握各个任务的运行状态，从而可以在任务失败时重新启动任务&lt;/li&gt;
&lt;/ol&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;YARN采用Master/Slave架构，ResourceManager为Master，NodeManager为Slave。ResourceManager负责对各个NodeManager上的资源进行统一管理和调度，当用户提交一个应用程序时，需要提供一个用来跟踪和管理这个程序的ApplicationMaster，它负责向ResourceManager申请资源，并要求NodeManager启动可以占用一定资源的任务。由于不同的ApplicationMaster被分布到不同的节点上，因此它们之间不会相互影响。&lt;br&gt;
    
    </summary>
    
    
      <category term="hadoop" scheme="http://dxer.github.io/tags/hadoop/"/>
    
      <category term="bigdata" scheme="http://dxer.github.io/tags/bigdata/"/>
    
      <category term="YAR" scheme="http://dxer.github.io/tags/YAR/"/>
    
  </entry>
  
  <entry>
    <title>【Hadoop学习】Hadoop2.0高可用性</title>
    <link href="http://dxer.github.io/2015/11/03/hadoop_ha/"/>
    <id>http://dxer.github.io/2015/11/03/hadoop_ha/</id>
    <published>2015-11-03T06:38:19.000Z</published>
    <updated>2016-05-25T06:53:29.068Z</updated>
    
    <content type="html">&lt;p&gt;在Hadoop2.0之前，只有一个NameNode，虽然有SecondaryNameNode（不能迅速切换，需要花费一定时间恢复），还是存在单点问题。NameNode在Hadoop中就好比是人的心脏，不能停止工作。如果NameNode数据丢失或者不能工作，那整个集群就不能恢复了。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;在Hadoop2.0中解决了这个问题，在Hadoop2.0中NameNode不再只是一个，可以有多个。每一个都具有相同的职能，一个NameNode是active状态，一个是standby状态。当集群在运行的时候，只有active状态的NameNode是正常工作的，standBy状态的NameNode是处于待命状态，时刻同步active状态NameNode的数据。一旦active状态的NameNode不能工作了，通过手工或者自动切换，standby状态的NameNode就可以转变为active状态了，这样集群还是正常工作了，这样集群就具有高可用性了。&lt;/p&gt;
&lt;p&gt;Hadoop2.0的HA机制官方介绍了2中方式：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;NFS（Network File System）&lt;/li&gt;
&lt;li&gt;QJM（Quorum Journal Manager）&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&quot;基本原理&quot;&gt;&lt;a href=&quot;#基本原理&quot; class=&quot;headerlink&quot; title=&quot;基本原理&quot;&gt;&lt;/a&gt;基本原理&lt;/h3&gt;&lt;p&gt;&lt;img src=&quot;/pic/20151103/HDFS_HA_arch.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;Hadoop2.0中有两个NameNode，一个是active状态NameNode，一个是standby状态NameNode。两者的状态是可以切换的，但是不能同时都是active状态，最多只有一个active状态。只有active状态的NameNode对外提供服务，standby状态的NameNode不对外服务。active状态的NameNode和standby状态的NameNode之间通过NFS或者JN（journalnode，QJM方式）来同步数据。&lt;/p&gt;
&lt;p&gt;active状态的NameNode会把最近的操作记录写到本地的edits文件中（edits file），并传输到NFS或者JN中。standby状态的NameNode定期检查，从NFS或者JN中把最近的edit文件读过来，然后把edits文件和fsimage文件合并成一个新的fsimage，合并完成之后会通知active状态NameNode来获取新的fsiamge，active状态NameNode获得到这个新的fsimage文件后，替换掉原来旧的fsimage文件。&lt;/p&gt;
&lt;h3 id=&quot;NFS方式&quot;&gt;&lt;a href=&quot;#NFS方式&quot; class=&quot;headerlink&quot; title=&quot;NFS方式&quot;&gt;&lt;/a&gt;NFS方式&lt;/h3&gt;&lt;p&gt;&lt;img src=&quot;/pic/20151103/ha_nfs.jpg&quot; alt=&quot;&quot;&gt;&lt;br&gt;NFS作为active NameNode和standby NameNode之间数据共享的存储，active状态的 NameNode会把最近的edits文件写到NFS，而standby状态的NameNode从NFS中读取edits文件。这个方式的缺点就是，如果active状态的NameNode或standby状态的NameNode有一个和NFS之间网络有问题是，就会造成它们之间数据的同步出现问题。&lt;/p&gt;
&lt;h3 id=&quot;QJM方式&quot;&gt;&lt;a href=&quot;#QJM方式&quot; class=&quot;headerlink&quot; title=&quot;QJM方式&quot;&gt;&lt;/a&gt;QJM方式&lt;/h3&gt;&lt;p&gt;&lt;img src=&quot;/pic/20151103/ha_qjm.jpg&quot; alt=&quot;&quot;&gt;&lt;br&gt;QJM方式可以解决NFS容错机制不足的问题，active状态NameNode和standby状态NameNode之间通过一组journalnode（奇数个，2n+1）来共享数据，active状态NameNode把最近的edits文件写到这组journalnode上，只要有n+1个写入成功就认为这次写入操作是成功的，然后standby状态NameNode就可以从journalnode上读取数据了。QJM方式有容错机制，可以容忍n个journalnode的失败&lt;/p&gt;
&lt;h3 id=&quot;NameNode故障切换&quot;&gt;&lt;a href=&quot;#NameNode故障切换&quot; class=&quot;headerlink&quot; title=&quot;NameNode故障切换&quot;&gt;&lt;/a&gt;NameNode故障切换&lt;/h3&gt;&lt;p&gt;active和standby状态NameNode可以随时切换，当active挂掉后，可以把standby切换成active状态。&lt;br&gt;故障切换可以通过人工切换和自动切换方式完成。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;人工切换是通过HA管理的命令来改变NameNode的状态&lt;/li&gt;
&lt;li&gt;自动切换是在active状态NameNode挂掉的时候，standby状态NameNode自动切换成active状态，取代原来的active状态NameNode成为新的active状态NameNode，确保HDFS继续正常工作&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&quot;/pic/20151103/ha.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;自动切换需要配置zookeeper。集群中两个NameNode都在zookeeper中注册，当active状态的NameNode出现故障时，zookeeper能检查到这种情况，它就会自动把standby状态的NameNode切换为active状态。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;在Hadoop2.0之前，只有一个NameNode，虽然有SecondaryNameNode（不能迅速切换，需要花费一定时间恢复），还是存在单点问题。NameNode在Hadoop中就好比是人的心脏，不能停止工作。如果NameNode数据丢失或者不能工作，那整个集群就不能恢复了。&lt;br&gt;
    
    </summary>
    
    
      <category term="hadoop" scheme="http://dxer.github.io/tags/hadoop/"/>
    
      <category term="bigdata" scheme="http://dxer.github.io/tags/bigdata/"/>
    
      <category term="ha" scheme="http://dxer.github.io/tags/ha/"/>
    
  </entry>
  
  <entry>
    <title>【Hadoop学习】Hadoop 1.0 &amp; Hadoop 2.0</title>
    <link href="http://dxer.github.io/2015/11/03/hadoop%20v1.0%20and%20hadoopv2.0/"/>
    <id>http://dxer.github.io/2015/11/03/hadoop v1.0 and hadoopv2.0/</id>
    <published>2015-11-03T01:29:19.000Z</published>
    <updated>2016-05-25T03:40:47.130Z</updated>
    
    <content type="html">&lt;h2 id=&quot;Hadoop-1-0&quot;&gt;&lt;a href=&quot;#Hadoop-1-0&quot; class=&quot;headerlink&quot; title=&quot;Hadoop 1.0&quot;&gt;&lt;/a&gt;Hadoop 1.0&lt;/h2&gt;&lt;p&gt;Hadoop 1.0即第一代Hadoop，由分布式存储系统HDFS和分布式和分布式计算框架MapReduce组成。其中HDFS由一个NameNode和多个DataNode组成MapReduce由一个JobTracker和多个TaskTracker组成，对应的Hadoop版本为Apache Hadoop 0.20.x、1.x、0.21.x、0.22.x和CDH3。&lt;/p&gt;
&lt;h2 id=&quot;Hadoop-2-0&quot;&gt;&lt;a href=&quot;#Hadoop-2-0&quot; class=&quot;headerlink&quot; title=&quot;Hadoop 2.0&quot;&gt;&lt;/a&gt;Hadoop 2.0&lt;/h2&gt;&lt;p&gt;Hadoop 2.0即第二代Hadoop，为了克服Hadooop 1.0中HDFS和MapReduce存在的各种问题而提出的。针对Hadoop 1.0中的单NameNode制约HDFS的扩展性问题，提出了HDFS Federation，它让多个NameNode分管不同的目录进而实现访问隔离和横向扩展，同时解决了NameNode的单点故障问题。针对Hadoop 1.0中的MapReduce在扩展性和多框架支持等方面的不足，它将JobTracker中的资源管理和作业控制功能分开，分别由组件ResourceManager和ApplicationMaster实现，其中，ResourceManager负责所有应用程序的资源分配，ApplicationMaster仅负责管理一个应用程序，着便是全新的通用的资源管理框架YARN。Hadoop 2.0对应的Hadoop的版本为Apache Hadoop 0.23.x、2.x和CDH4。&lt;/p&gt;
&lt;h2 id=&quot;MRv1&quot;&gt;&lt;a href=&quot;#MRv1&quot; class=&quot;headerlink&quot; title=&quot;MRv1&quot;&gt;&lt;/a&gt;MRv1&lt;/h2&gt;&lt;p&gt;MapReduce 1.0计算框架主要由三部分组成，分别是编程模型，数据处理引擎和运行时环境。它的编程模型是将问题抽象成Map和Reduce两个阶段，其中Map阶段将输入数据解析成key/value，迭代调用map()函数处理后，再以key/value的形式输出到本地目录，而Reduce阶段则是将Map阶段输出的数据按照key相同的value进行归约处理，并将最终结果写到HDFS上。它的数据处理引擎由MapTask和ReduceTask组成，分别负责Map阶段逻辑和Reduce阶段逻辑的处理。运行时的环境由一个JobTracker和若干个TaskTracker组成，JobTracker负责资源管理和所有作业的控制，TaskTracker负责接收来自JobTracker的命令并执行它。&lt;/p&gt;
&lt;h2 id=&quot;MRv2&quot;&gt;&lt;a href=&quot;#MRv2&quot; class=&quot;headerlink&quot; title=&quot;MRv2&quot;&gt;&lt;/a&gt;MRv2&lt;/h2&gt;&lt;p&gt;MRv2具有与MRv1相同的编程模型和数据处理引擎，唯一不同的是运行时环境。MRv2是在MRv1基础上经加工之后，运行于资源管理框架YARN之上的计算框架。它由资源管理系统YARN和作业控制进程ApplicationMaster组成，其中YARN负责资源管理和调度，而ApplicationMaster仅负责一个作业的管理。MRv1仅是一个独立的离线计算框架，而MRv2则是运行于YARN之上的MapReduce。&lt;/p&gt;
&lt;h2 id=&quot;YARN&quot;&gt;&lt;a href=&quot;#YARN&quot; class=&quot;headerlink&quot; title=&quot;YARN&quot;&gt;&lt;/a&gt;YARN&lt;/h2&gt;&lt;p&gt;YARN是Hadoop 2.0中的资源管理系统，它是一个通用的资源管理模块，可以为各类应用横须进行资源管理和调度。YARN不仅限于MapReduce一种框架使用，也可以供其他框架使用，比如Spark,Storm等。&lt;/p&gt;
&lt;h2 id=&quot;HDFS-Federation&quot;&gt;&lt;a href=&quot;#HDFS-Federation&quot; class=&quot;headerlink&quot; title=&quot;HDFS Federation&quot;&gt;&lt;/a&gt;HDFS Federation&lt;/h2&gt;&lt;p&gt;在Hadoop 2.0中，对HDFS进行改进，是的NameNode可以横向扩展成多个，每个NameNode分管一部分目录，进而产生了HDFS Federation，该机制的引入不仅增强了HDFS的扩展性，也使HDFS具备了隔离性。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;Hadoop-1-0&quot;&gt;&lt;a href=&quot;#Hadoop-1-0&quot; class=&quot;headerlink&quot; title=&quot;Hadoop 1.0&quot;&gt;&lt;/a&gt;Hadoop 1.0&lt;/h2&gt;&lt;p&gt;Hadoop 1.0即第一代Hadoop，由分布式存储系统HDFS和分布式和
    
    </summary>
    
    
      <category term="hadoop" scheme="http://dxer.github.io/tags/hadoop/"/>
    
      <category term="mapreduce" scheme="http://dxer.github.io/tags/mapreduce/"/>
    
      <category term="bigdata" scheme="http://dxer.github.io/tags/bigdata/"/>
    
  </entry>
  
  <entry>
    <title>【Hadoop学习】Secondary NameNode解读</title>
    <link href="http://dxer.github.io/2015/10/26/secondarynamenode/"/>
    <id>http://dxer.github.io/2015/10/26/secondarynamenode/</id>
    <published>2015-10-26T12:18:19.000Z</published>
    <updated>2016-05-25T08:17:31.947Z</updated>
    
    <content type="html">&lt;p&gt;Secondary NameNode从它的名字上来看，给人的感觉是NameNode的备份。但实际上不是这样。那到底Secondary NameNode在HDFS中扮演的是什么角色呢？&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;从名字上来看Secondary NameNode与NameNode，都包含着NameNode，这两者是不是存在某种关系呢，先来看下NameNode是干什么的。&lt;/p&gt;
&lt;h3 id=&quot;NameNode&quot;&gt;&lt;a href=&quot;#NameNode&quot; class=&quot;headerlink&quot; title=&quot;NameNode&quot;&gt;&lt;/a&gt;NameNode&lt;/h3&gt;&lt;p&gt;NameNode主要是用来保存HDFS的元数据信息，比如命名空间信息，快信息等。当它运行的时候，这些信息会保存在内存中。同时这部分信息也会持久化到磁盘上。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/pic/20151026/nn.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;fsimage:是在NameNode启动时对整个文件系统的快照&lt;/li&gt;
&lt;li&gt;edits:在NameNode启动后，对文件系统改动序列&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;只有在NameNode重启时，edits才会合并到fsimage文件中，从而得到一个文件系统的最新快照。但是在产品集群中NameNode是很少重启的，这也意味着当NameNode运行了很长时间后，edits文件会变得很大。就会面临如下问题：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;edits文件会变的很大，怎么去管理这个文件是一个挑战&lt;/li&gt;
&lt;li&gt;NameNode的重启会花费很长时间，因为有很多edits中改动要合并到fsimage文件上。&lt;/li&gt;
&lt;li&gt;如果NameNode挂掉了，就会丢失了很多改动，因为此时的fsimage文件非常旧。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;这个时候Secondary NameNode就出场了，Secondary NameNode可以来帮助解决上面问题，它的职责就是用来合并NameNode的edits到fsimage中。&lt;/p&gt;
&lt;h3 id=&quot;Secondary-NameNode&quot;&gt;&lt;a href=&quot;#Secondary-NameNode&quot; class=&quot;headerlink&quot; title=&quot;Secondary NameNode&quot;&gt;&lt;/a&gt;Secondary NameNode&lt;/h3&gt;&lt;p&gt;HDFS文件系统的写操作不是直接被修改到fsimage中，而是edits中，Secondary NameNode节点负责将两者进行整合。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/pic/20151026/checkpoint.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;checkpoint过程如下：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Secondary Namenode请求Namenode停止使用edits文件，暂时将新的写操作记录到一个新文件中，如edits.new。&lt;/li&gt;
&lt;li&gt;Secondary Namenode节点从Namenode节点获取fsimage和edits文件（采用HTTP GET）&lt;/li&gt;
&lt;li&gt;Secondary Namenode将fsimage文件载入到内存，逐一执行edits文件中的操作，创建新的fsimage文件&lt;/li&gt;
&lt;li&gt;Secondary Namenode将新的fsimage文件发送回Namenode（使用HTTP POST）&lt;/li&gt;
&lt;li&gt;Namenode节点将从Secondary Namenode节点接收的fsimage文件替换旧的fsimage文件，用步骤1产生的edits.new文件替换旧的edits文件（即改名）。同时更新fstime文件来记录检查点执行的时间&lt;br&gt;注：从Hadoop0.21.0开始，辅助Namenode已经放弃不用，由checkpoint节点取而代之，功能不变。新版本同时引入一种新的Namenode，名为BackupNode。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Secondary NameNode的整个目的在HDFS中提供一个Checkpoint Node，它只是NameNode的一个助手节点&lt;/p&gt;
&lt;p&gt;现在，我们明白Secondary NameNode所做的是在文件系统这设置一个Checkpoint来帮助NameNode更好的工作；它不是取代NameNode，也不是NameNode的备份。&lt;/p&gt;
&lt;p&gt;Secondary NameNode的检查点进程启动，是由两个配置参数控制的：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;fs.checkpoint.period，指定连续两次检查点的最大时间间隔， 默认值是1小时。&lt;/li&gt;
&lt;li&gt;fs.checkpoint.size定义了edits日志文件的最大值，一旦超过这个值会导致强制执行检查点（即使没到检查点的最大时间间隔）。默认值是64MB。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;关于NameNode是什么时候将改动写到edit logs中的？&lt;br&gt;这个操作实际上是由DataNode的写操作触发的，当我们往DataNode写文件时，DataNode会跟NameNode通信，告诉NameNode什么文件的第几个block放在它那里，NameNode这个时候会将这些元数据信息写到edit logs文件中。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;Secondary NameNode从它的名字上来看，给人的感觉是NameNode的备份。但实际上不是这样。那到底Secondary NameNode在HDFS中扮演的是什么角色呢？&lt;br&gt;
    
    </summary>
    
    
      <category term="hadoop" scheme="http://dxer.github.io/tags/hadoop/"/>
    
      <category term="hdfs" scheme="http://dxer.github.io/tags/hdfs/"/>
    
  </entry>
  
</feed>
