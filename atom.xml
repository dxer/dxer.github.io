<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>dxer</title>
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://dxer.github.io/"/>
  <updated>2016-06-17T03:57:00.438Z</updated>
  <id>http://dxer.github.io/</id>
  
  <author>
    <name>dxer</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>分布式文件系统FastDFS快速入门</title>
    <link href="http://dxer.github.io/2016/06/15/fastdfs/"/>
    <id>http://dxer.github.io/2016/06/15/fastdfs/</id>
    <published>2016-06-15T06:38:19.000Z</published>
    <updated>2016-06-17T03:57:00.438Z</updated>
    
    <content type="html">&lt;h2 id=&quot;什么是FastDFS？&quot;&gt;&lt;a href=&quot;#什么是FastDFS？&quot; class=&quot;headerlink&quot; title=&quot;什么是FastDFS？&quot;&gt;&lt;/a&gt;什么是FastDFS？&lt;/h2&gt;&lt;p&gt;FastDFS是一个开源的轻量级分布式文件系统。它解决了大数据量存储和负载均衡等问题。特别适合以中小文件（建议范围：4KB &amp;lt; file_size &lt;500mb）为载体的在线服务，如相册网站、视频网站等等。 &lt;a=&quot;&quot; id=&quot;more&quot;&gt;&lt;/500mb）为载体的在线服务，如相册网站、视频网站等等。&gt;&lt;/p&gt;
&lt;h2 id=&quot;FastDFS架构&quot;&gt;&lt;a href=&quot;#FastDFS架构&quot; class=&quot;headerlink&quot; title=&quot;FastDFS架构&quot;&gt;&lt;/a&gt;FastDFS架构&lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;/pic/20160615/FastDFS架构图1.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;从上图可知，FastDFS架构中有三个角色：&lt;strong&gt;跟踪服务器（tracker server）&lt;/strong&gt;、&lt;strong&gt;存储服务器（storage server）
&lt;/strong&gt;和&lt;strong&gt;客户端（client）&lt;/strong&gt;。&lt;/p&gt;
&lt;h3 id=&quot;tracker-server&quot;&gt;&lt;a href=&quot;#tracker-server&quot; class=&quot;headerlink&quot; title=&quot;tracker server&quot;&gt;&lt;/a&gt;tracker server&lt;/h3&gt;&lt;p&gt;跟踪服务器，主要做调度工作，起负载均衡的作用。负责管理所有的storage server和group，每个storage在启动后会连接tracker，告诉tracker自己所属的group，并保持周期性心跳，tracker根据storage的心跳信息，建立&lt;group，storage server=&quot;&quot;&gt;映射表，tracke管理的元数据很少（tracker上的元数据都是由storage汇报产生），并且直接存在内存中，本身不需要持久化任何数据。tracker之间是对等的，因此扩展tracker是很容易的，直接增加tracker服务，同时修改storage的配置，增加新增的tarcker服务的地址和端口，重启即可。所有的tracker都会接受storage的心跳信息，以生成元数据信息。&lt;/group，storage&gt;&lt;/p&gt;
&lt;h3 id=&quot;storage-server&quot;&gt;&lt;a href=&quot;#storage-server&quot; class=&quot;headerlink&quot; title=&quot;storage server&quot;&gt;&lt;/a&gt;storage server&lt;/h3&gt;&lt;p&gt;存储服务器（又称：存储节点或数据服务器），顾名思义是用来保存文件的和文件属性的。以group为单位，每个group内可以包含多台storage server，数据互为备份，存储容量空间以group中storage server容量最小的为准。以group为单位组织存储能够方便的进行应用隔离、负责均衡和副本数定制；确定是group的容量受单机容量的限制。group内机器故障，需要依赖group内其他机器重新同步数据来恢复数据（更换坏盘，重启fdfs_storaged即可）。storage存储依赖本地文件系统，storage课配置多个数据存储目录，磁盘不做raid，直接分别挂在到多个目录，将这些目录配置为storage的数据目录即可。&lt;/p&gt;
&lt;p&gt;storage接收写请求的时候，会根据配置好的规则，选择其中一个存储目录来存储文件；为了避免单个目录下的文件过多，storage第一次启动的时候，会在每个数据存储目录创建2级子目录，每级256，总共65536个目录，新写的文件会以hash的方式路由到其中一个子目录下，然后将文件数据直接作为一个本地文件存储。&lt;/p&gt;
&lt;h3 id=&quot;client&quot;&gt;&lt;a href=&quot;#client&quot; class=&quot;headerlink&quot; title=&quot;client&quot;&gt;&lt;/a&gt;client&lt;/h3&gt;&lt;p&gt;客户端，作为业务请求的发起方，通过专有接口，使用TCP/IP协议与跟踪器服务器或存储节点进行数据交互。&lt;/p&gt;
&lt;h2 id=&quot;FastDFS的工作流程&quot;&gt;&lt;a href=&quot;#FastDFS的工作流程&quot; class=&quot;headerlink&quot; title=&quot;FastDFS的工作流程&quot;&gt;&lt;/a&gt;FastDFS的工作流程&lt;/h2&gt;&lt;h3 id=&quot;文件上传&quot;&gt;&lt;a href=&quot;#文件上传&quot; class=&quot;headerlink&quot; title=&quot;文件上传&quot;&gt;&lt;/a&gt;文件上传&lt;/h3&gt;&lt;p&gt;&lt;img src=&quot;/pic/20160615/fastdfs_upload.jpg&quot; alt=&quot;文件上传&quot;&gt;&lt;/p&gt;
&lt;p&gt;上传的流程：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;client询问tracker上传到的storage&lt;/li&gt;
&lt;li&gt;tracker返回一台可用的storage&lt;/li&gt;
&lt;li&gt;client直接和storage通信，完成文件上传&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&quot;选择tracker-server&quot;&gt;&lt;a href=&quot;#选择tracker-server&quot; class=&quot;headerlink&quot; title=&quot;选择tracker server&quot;&gt;&lt;/a&gt;选择tracker server&lt;/h4&gt;&lt;p&gt;集群中tracker之间是对等关系，client在上传文件时可以使用任意一个tracker&lt;/p&gt;
&lt;h4 id=&quot;选择存储group&quot;&gt;&lt;a href=&quot;#选择存储group&quot; class=&quot;headerlink&quot; title=&quot;选择存储group&quot;&gt;&lt;/a&gt;选择存储group&lt;/h4&gt;&lt;p&gt;当tracker接收到上传文件的请求的时候，会为该文件分配一个可以存储的group。目前支持选择的group的规则有：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Round robin，轮询&lt;/li&gt;
&lt;li&gt;Sepcified group，上传的时候指定某个group&lt;/li&gt;
&lt;li&gt;Load balance，生成存储空间较多的group优先&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&quot;选择storage-server&quot;&gt;&lt;a href=&quot;#选择storage-server&quot; class=&quot;headerlink&quot; title=&quot;选择storage server&quot;&gt;&lt;/a&gt;选择storage server&lt;/h4&gt;&lt;p&gt;当选定group后，tracker会在group内选择一个storage server给client，目前支持选择server的规则有：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Round robin，轮询（默认）&lt;/li&gt;
&lt;li&gt;根据IP地址进行排序，选择第一个服务器（IP地址最小者）&lt;/li&gt;
&lt;li&gt;根据优先级进行排序，上传优先级由storage server来设置，参数为uoload_priority&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&quot;选择storage-path&quot;&gt;&lt;a href=&quot;#选择storage-path&quot; class=&quot;headerlink&quot; title=&quot;选择storage path&quot;&gt;&lt;/a&gt;选择storage path&lt;/h4&gt;&lt;p&gt;当分配好storage server后，客户端将向storage发送写文件请求，storage会将文件分配一个数据存储目录，目前支持选择存储路径选择的规则有：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Round robin，轮询（默认）&lt;/li&gt;
&lt;li&gt;load balance，选择使用剩余空间最大的存储路径&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&quot;生成file-id&quot;&gt;&lt;a href=&quot;#生成file-id&quot; class=&quot;headerlink&quot; title=&quot;生成file id&quot;&gt;&lt;/a&gt;生成file id&lt;/h4&gt;&lt;p&gt;选择存储目录之后，storage会生成一个file_id，采用base64编码，包含有：storage server ip，文件创建时间，文件大小，文件CRC32校验码和随机数。每个存储目录下有两个256*256个子目录，storage会按文件file_id进行两次hash，路由到其中一个子目录，然后将文件以file_id为名字存储。&lt;br&gt;文件路径如下：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;group0/M00/00/02/exwf8b8lFJIxx2234841AAAbpQt7xVI473456.txt&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;组名：group0   磁盘： M00   目录：00/02   文件名：exwf8b8lFJIxx2234841AAAbpQt7xVI473456.txt&lt;/p&gt;
&lt;p&gt;文件索引信息包括：&lt;strong&gt;组名，虚拟磁盘路径，数据两级目录，文件名&lt;/strong&gt;。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;组名：&lt;/strong&gt;文件上传后所在的存储组名称，在文件上传成功后有存储服务器返回，需要客户端自行保存。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;虚拟磁盘路径：&lt;/strong&gt;存储服务器配置的虚拟路径，与磁盘选项store_path*对应。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;数据两级目录：&lt;/strong&gt;存储服务器在每个虚拟磁盘路径下创建的两级目录，用于存储数据文件。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;文件名：与文件上传时不同。&lt;/strong&gt;是由存储服务器根据特定信息生成，文件名包含：源存储服务器IP地址、文件创建时间戳、文件大小、随机数和文件拓展名等信息。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;文件下载&quot;&gt;&lt;a href=&quot;#文件下载&quot; class=&quot;headerlink&quot; title=&quot;文件下载&quot;&gt;&lt;/a&gt;文件下载&lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;/pic/20160615/fastdfs_download.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;文件下载流程：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;client询问tracker要下载文件的所在的storage，参数为文件标识（group,文件名）&lt;/li&gt;
&lt;li&gt;tracker返回一台可用的storage&lt;/li&gt;
&lt;li&gt;client直接和storage通信，下载文件&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;client发送下载某个文件的请求到某个tracker，tracker从文件名中解析出文件的group，文件大小，创建时间等信息，然后为该请求选择一个storage用于读请求&lt;/p&gt;
&lt;h4 id=&quot;选择下载服务器&quot;&gt;&lt;a href=&quot;#选择下载服务器&quot; class=&quot;headerlink&quot; title=&quot;选择下载服务器&quot;&gt;&lt;/a&gt;选择下载服务器&lt;/h4&gt;&lt;p&gt;目前支持的规则有：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;轮询方式，可以下载当前文件的任意一个storage server&lt;/li&gt;
&lt;li&gt;从源storage server下载&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&quot;同步时间管理&quot;&gt;&lt;a href=&quot;#同步时间管理&quot; class=&quot;headerlink&quot; title=&quot;同步时间管理&quot;&gt;&lt;/a&gt;同步时间管理&lt;/h2&gt;&lt;p&gt;当一个文件上传成功后，客户端马上发起对该文件下载请求（或删除请求）时，tracker是如何选定一个适用的存储服务器呢？&lt;/p&gt;
&lt;p&gt;其实每个存储服务器都需要定时将自身的信息上报给tracker，这些信息就包括了本地同步时间（即，同步到的最新文件的时间戳）。而tracker根据各个存储服务器的上报情况，就能够知道刚刚上传的文件，在该存储组中是否已完成了同步。&lt;/p&gt;
&lt;h2 id=&quot;快速定位文件&quot;&gt;&lt;a href=&quot;#快速定位文件&quot; class=&quot;headerlink&quot; title=&quot;快速定位文件&quot;&gt;&lt;/a&gt;快速定位文件&lt;/h2&gt;&lt;p&gt;知道FastDFS FID的组成后，我们来看看FastDFS是如何通过这个精巧的FID定位到需要访问的文件。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;通过组名tracker能够很快的定位到客户端需要访问的存储服务器组，并将选择合适的存储服务器提供客户端访问；&lt;/li&gt;
&lt;li&gt;存储服务器根据“文件存储虚拟磁盘路径”和“数据文件两级目录”可以很快定位到文件所在目录，并根据文件名找到客户端需要访问的文件。&lt;/li&gt;
&lt;/ol&gt;
</content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;什么是FastDFS？&quot;&gt;&lt;a href=&quot;#什么是FastDFS？&quot; class=&quot;headerlink&quot; title=&quot;什么是FastDFS？&quot;&gt;&lt;/a&gt;什么是FastDFS？&lt;/h2&gt;&lt;p&gt;FastDFS是一个开源的轻量级分布式文件系统。它解决了大数据量存储和负载均衡等问题。特别适合以中小文件（建议范围：4KB &amp;lt; file_size &lt;500MB）为载体的在线服务，如相册网站、视频网站等等。
    
    </summary>
    
    
      <category term="fastdfs" scheme="http://dxer.github.io/tags/fastdfs/"/>
    
  </entry>
  
  <entry>
    <title>Hadoop不能加载本地库问题解决</title>
    <link href="http://dxer.github.io/2016/04/05/hadoop_native_lib/"/>
    <id>http://dxer.github.io/2016/04/05/hadoop_native_lib/</id>
    <published>2016-04-05T06:46:19.000Z</published>
    <updated>2016-06-16T05:08:46.951Z</updated>
    
    <content type="html">&lt;p&gt;在执行hadoop命令或者启动dfs、yarn的时候总会出现这个警告&lt;/p&gt;
&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;WARN util.NativeCodeLoader: Unable to load native-hadoop library &lt;span class=&quot;keyword&quot;&gt;for&lt;/span&gt; your platform... &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;using &lt;span class=&quot;built_in&quot;&gt;builtin&lt;/span&gt;-java classes &lt;span class=&quot;built_in&quot;&gt;where&lt;/span&gt; applicable&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;
&lt;p&gt;修改下log输出日志的级别，获取更多的信息，在执行hadoop命令之前设置下&lt;/p&gt;
&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;built_in&quot;&gt;export&lt;/span&gt; HADOOP_ROOT_LOGGER=DEBUG,console&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;再执行启动dfs命令，控制台输出了一些debug信息，快看看是啥原因导致这个警告的出现。发现&lt;code&gt;GLIBC_2.14&lt;/code&gt;这个东东没有找到&lt;/p&gt;
&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;`GLIBC_2.14&lt;span class=&quot;string&quot;&gt;&#39; not found (required by opt/hadoop/lib/native/libhadoop.so.1.0.0)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;glibc是什么东西呢？&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;glibc是GNU发布的libc库，即c运行库。glibc是linux系统中最底层的api，几乎其它任何运行库都会依赖于glibc。glibc除了封装linux操作系统所提供的系统服务外，它本身也提供了许多其它一些必要功能服务的实现。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;看来这个库在linux系统中很重要呀！！！&lt;/p&gt;
&lt;p&gt;我们先看下我们操作系统的glib版本是什么&lt;br&gt;&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;strings /lib64/libc.so.6 | grep GLIBC&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/pic/20160405/2016040501.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;系统是2.12版本的，hadoop需要2.14版本才行，下面来对libc库进行升级。&lt;/p&gt;
&lt;p&gt;下载&lt;br&gt;&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;wget http://mirror.bjtu.edu.cn/gnu/libc/glibc-2.14.tar.xz&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;解压&lt;br&gt;&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;tar xvf glibc-2.14.tar.gz&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;编译&lt;br&gt;&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;built_in&quot;&gt;cd&lt;/span&gt; glibc-2.14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;mkdir build&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;built_in&quot;&gt;cd&lt;/span&gt; build&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;../configure --prefix=/usr/&lt;span class=&quot;built_in&quot;&gt;local&lt;/span&gt;/glibc-2.14   // 配置glibc并设置当前glibc-2.14安装目录&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;make -j4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;make install&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;安装完了，我们接下来要去更新系统的lib库，先复制libc-2.14.so到/lib64目录下&lt;br&gt;&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;cp /usr/&lt;span class=&quot;built_in&quot;&gt;local&lt;/span&gt;/glibc-2.14/lib/libc-2.14.so /lib64/libc-2.14.so&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;备份原来的/lib64/libc.so.6&lt;/p&gt;
&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;mv /lib64/libc.so.6 /lib64/libc.so.6.bak&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;备份好了，&lt;code&gt;ls&lt;/code&gt;看一下&lt;br&gt;&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;[root@hadoop001 ~]&lt;span class=&quot;comment&quot;&gt;# ls&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;ls: error &lt;span class=&quot;keyword&quot;&gt;while&lt;/span&gt; loading shared libraries: libc.so.6: cannot open &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;shared object file: No such file or directory&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;如下图所示:&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/pic/20160405/2016040502.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;oh，No，&lt;code&gt;ls&lt;/code&gt;命令不能用啦，咋回事，这还能不能愉快的玩耍啦，不要着急，我们continue吧 &lt;/p&gt;
&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;LD_PRELOAD=/lib64/libc-2.14.so ln –s /lib64/libc-2.14.so  /lib64/libc.so.6&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;再来看下libc的版本&lt;br&gt;&lt;img src=&quot;/pic/20160405/2016040503.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;Ok，大功告成。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;在执行hadoop命令或者启动dfs、yarn的时候总会出现这个警告&lt;/p&gt;
&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;WARN util.NativeCodeLoader: Unable to load native-hadoop library &lt;span class=&quot;keyword&quot;&gt;for&lt;/span&gt; your platform... &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;using &lt;span class=&quot;built_in&quot;&gt;builtin&lt;/span&gt;-java classes &lt;span class=&quot;built_in&quot;&gt;where&lt;/span&gt; applicable&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
    
      <category term="hadoop" scheme="http://dxer.github.io/tags/hadoop/"/>
    
  </entry>
  
  <entry>
    <title>HBase性能优化方法总结</title>
    <link href="http://dxer.github.io/2016/04/01/hbase-optimize/"/>
    <id>http://dxer.github.io/2016/04/01/hbase-optimize/</id>
    <published>2016-04-01T07:25:38.000Z</published>
    <updated>2016-06-02T00:31:08.598Z</updated>
    
    <content type="html">&lt;p&gt;本文主要是从HBase应用程序设计与开发的角度，总结几种常用的性能优化方法。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&quot;Auto-Flash&quot;&gt;&lt;a href=&quot;#Auto-Flash&quot; class=&quot;headerlink&quot; title=&quot;Auto Flash&quot;&gt;&lt;/a&gt;Auto Flash&lt;/h3&gt;&lt;p&gt;通过调用&lt;code&gt;HTable.setAutoFlushTo(false)&lt;/code&gt;方法可以将HTable写客户端自动flush关闭，这样可以批量写入数据到HBase，而不是有一条put就执行一次更新，只有当put填满客户端写缓存的时候，才会向HBase服务端发起写请求。默认情况下auto flush是开启的。&lt;/p&gt;
&lt;h3 id=&quot;Write-Buffer&quot;&gt;&lt;a href=&quot;#Write-Buffer&quot; class=&quot;headerlink&quot; title=&quot;Write Buffer&quot;&gt;&lt;/a&gt;Write Buffer&lt;/h3&gt;&lt;p&gt;通过调用&lt;code&gt;HTable.setWriteBufferSize(writeBufferSize)&lt;/code&gt;方法可以设置HTable客户端的写buffer大小，如果新设置的buffer小于当前写buffer中的数据时，buffer将会被flush到服务端。其中，writeBufferSize的单位是byte字节数，可以根基实际写入数据量的多少来设置该值。&lt;/p&gt;
&lt;h3 id=&quot;WAL-Flag&quot;&gt;&lt;a href=&quot;#WAL-Flag&quot; class=&quot;headerlink&quot; title=&quot;WAL Flag&quot;&gt;&lt;/a&gt;WAL Flag&lt;/h3&gt;&lt;p&gt;在HBase中，客户端向集群中的RegionServer提交数据时（Put/Delete操作），首先会写到WAL（Write Ahead Log）日志，即HLog，一个RegionServer上的所有Region共享一个HLog，只有当WAL日志写成功后，再接着写MemStore，然后客户端被通知提交数据成功，如果写WAL日志失败，客户端被告知提交失败，这样做的好处是可以做到RegionServer宕机后的数据恢复。&lt;br&gt;对于不太重要的数据，可以在Put/Delete操作时，通过调用&lt;code&gt;Put.setWriteToWAL(false)&lt;/code&gt;或&lt;code&gt;Delete.setWriteToWAL(false)&lt;/code&gt;函数，放弃写WAL日志，以提高数据写入的性能。&lt;/p&gt;
&lt;p&gt;注：如果关闭WAL日志，一旦RegionServer宕机，Put/Delete的数据将会无法根据WAL日志进行恢复。&lt;/p&gt;
&lt;h3 id=&quot;Compression-压缩&quot;&gt;&lt;a href=&quot;#Compression-压缩&quot; class=&quot;headerlink&quot; title=&quot;Compression 压缩&quot;&gt;&lt;/a&gt;Compression 压缩&lt;/h3&gt;&lt;p&gt;数据量大，边压边写也会提升性能的，毕竟IO是大数据的最严重的瓶颈，哪怕使用了SSD也是一样。众多的压缩方式中，推荐使用SNAPPY。从压缩率和压缩速度来看，性价比最高。&lt;br&gt;&lt;figure class=&quot;highlight java&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;HColumnDescriptor hcd = &lt;span class=&quot;keyword&quot;&gt;new&lt;/span&gt; HColumnDescriptor(familyName);   &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;hcd.setCompressionType(Algorithm.SNAPPY);&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h3 id=&quot;批量写&quot;&gt;&lt;a href=&quot;#批量写&quot; class=&quot;headerlink&quot; title=&quot;批量写&quot;&gt;&lt;/a&gt;批量写&lt;/h3&gt;&lt;p&gt;通过调用&lt;code&gt;HTable.put(Put)&lt;/code&gt;方法可以将一个指定的row key记录写入HBase，同样HBase提供了另一个方法：通过调用&lt;code&gt;HTable.put(List&amp;lt;Put&amp;gt;)&lt;/code&gt;方法可以将指定的row key列表，批量写入多行记录，这样做的好处是批量执行，只需要一次网络I/O开销，这对于对数据实时性要求高，网络传输RTT高的情景下可能带来明显的性能提升。&lt;/p&gt;
&lt;h3 id=&quot;多线程并发写&quot;&gt;&lt;a href=&quot;#多线程并发写&quot; class=&quot;headerlink&quot; title=&quot;多线程并发写&quot;&gt;&lt;/a&gt;多线程并发写&lt;/h3&gt;&lt;p&gt;在客户端开启多个 HTable 写线程，每个写线程负责一个 HTable 对象的 flush 操作，这样结合定时 flush 和写 buffer（writeBufferSize），可以既保证在数据量小的时候，数据可以在较短时间内被 flush（如1秒内），同时又保证在数据量大的时候，写 buffer 一满就及时进行 flush。&lt;/p&gt;
&lt;h3 id=&quot;批量读&quot;&gt;&lt;a href=&quot;#批量读&quot; class=&quot;headerlink&quot; title=&quot;批量读&quot;&gt;&lt;/a&gt;批量读&lt;/h3&gt;&lt;p&gt;通过调用 &lt;code&gt;HTable.get(Get)&lt;/code&gt; 方法可以根据一个指定的 row key 获取一行记录，同样 HBase 提供了另一个方法：通过调用 &lt;code&gt;HTable.get(List)&lt;/code&gt; 方法可以根据一个指定的 row key 列表，批量获取多行记录，这样做的好处是批量执行，只需要一次网络 I/O 开销，这对于对数据实时性要求高而且网络传输 RTT 高的情景下可能带来明显的性能提升。&lt;/p&gt;
&lt;h3 id=&quot;缓存查询结果&quot;&gt;&lt;a href=&quot;#缓存查询结果&quot; class=&quot;headerlink&quot; title=&quot;缓存查询结果&quot;&gt;&lt;/a&gt;缓存查询结果&lt;/h3&gt;&lt;p&gt;对于频繁查询 HBase 的应用场景，可以考虑在应用程序中做缓存，当有新的查询请求时，首先在缓存中查找，如果存在则直接返回，不再查询 HBase；否则对 HBase 发起读请求查询，然后在应用程序中将查询结果缓存起来。至于缓存的替换策略，可以考虑 LRU 等常用的策略。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&quot;HBase数据表优化&quot;&gt;&lt;a href=&quot;#HBase数据表优化&quot; class=&quot;headerlink&quot; title=&quot;HBase数据表优化&quot;&gt;&lt;/a&gt;HBase数据表优化&lt;/h2&gt;&lt;h3 id=&quot;预分区&quot;&gt;&lt;a href=&quot;#预分区&quot; class=&quot;headerlink&quot; title=&quot;预分区&quot;&gt;&lt;/a&gt;预分区&lt;/h3&gt;&lt;p&gt;默认情况下，在创建HBase表的时候会自动创建一个Region分区，当导入数据的时候，所有的HBase客户端都向Region写数据，知道这个Region足够大才进行切分，一种可以加快批量写入速度的方法是通过预先创建一些空的Regions，这样当数据写入HBase的时候，会按照Region分区情况，在进群内做数据的负载均衡。&lt;/p&gt;
&lt;h3 id=&quot;Rowkey优化&quot;&gt;&lt;a href=&quot;#Rowkey优化&quot; class=&quot;headerlink&quot; title=&quot;Rowkey优化&quot;&gt;&lt;/a&gt;Rowkey优化&lt;/h3&gt;&lt;p&gt;rowkey是按照字典存储，因此设置rowkey时，要充分利用排序特点，将经常一起读取的数据存储到一块，将最近可能会被访问的数据放到一块。&lt;br&gt;rowkey若是递增生成的，建议不要使用正序直接写入，可以使用字符串反转方式写入，使得rowkey大致均衡分布，这样设计的好处是能将RegionServer的负载均衡，否则容易产生所有新数据都在集中在一个RegionServer上堆积的现象，这一点还可以结合table的与分区设计。&lt;/p&gt;
&lt;h3 id=&quot;减少Column-Family数量&quot;&gt;&lt;a href=&quot;#减少Column-Family数量&quot; class=&quot;headerlink&quot; title=&quot;减少Column Family数量&quot;&gt;&lt;/a&gt;减少Column Family数量&lt;/h3&gt;&lt;p&gt;不要在一张表中定义太多的column family。目前HBase并不能很好的处理超过2-3个column family的表，因为某个column family在flush的时候，它临近的column family也会因关联效应被触发flush，最终导致系统产生更过的I/O;&lt;/p&gt;
&lt;h3 id=&quot;设置最大版本数&quot;&gt;&lt;a href=&quot;#设置最大版本数&quot; class=&quot;headerlink&quot; title=&quot;设置最大版本数&quot;&gt;&lt;/a&gt;设置最大版本数&lt;/h3&gt;&lt;p&gt;创建表的时候，可以通过 &lt;code&gt;HColumnDescriptor.setMaxVersions(int maxVersions)&lt;/code&gt; 设置表中数据的最大版本，如果只需要保存最新版本的数据，那么可以设置 setMaxVersions(1)。&lt;/p&gt;
&lt;h3 id=&quot;缓存策略（setCaching）&quot;&gt;&lt;a href=&quot;#缓存策略（setCaching）&quot; class=&quot;headerlink&quot; title=&quot;缓存策略（setCaching）&quot;&gt;&lt;/a&gt;缓存策略（setCaching）&lt;/h3&gt;&lt;p&gt;创建表的时候，可以通过&lt;code&gt;HColumnDEscriptor.setInMemory(true)&lt;/code&gt;将表放到RegionServer的缓存中，保证在读取的时候被cache命中。&lt;/p&gt;
&lt;h3 id=&quot;设置存储生命期&quot;&gt;&lt;a href=&quot;#设置存储生命期&quot; class=&quot;headerlink&quot; title=&quot;设置存储生命期&quot;&gt;&lt;/a&gt;设置存储生命期&lt;/h3&gt;&lt;p&gt;创建表的时候，可以通过&lt;code&gt;HColumnDescriptor.setTimeToLive(int timeToLive)&lt;/code&gt;设置表中数据的存储生命周期，过期数据将自动被删除&lt;/p&gt;
&lt;h3 id=&quot;磁盘配置&quot;&gt;&lt;a href=&quot;#磁盘配置&quot; class=&quot;headerlink&quot; title=&quot;磁盘配置&quot;&gt;&lt;/a&gt;磁盘配置&lt;/h3&gt;&lt;p&gt;每台RegionServer管理10-1000个Regions。每个Region在1-2G，则每台server最少要10G，最大要1000*2G=2TB，考虑3备份，需要6TB。方案1是3块2TB磁盘，2是12块500G磁盘，带宽足够时，后者能提供更大的吞吐率，更细力度的冗余备份，更快速的单盘故障恢复。&lt;/p&gt;
&lt;h3 id=&quot;分配何时的内存给RegionServer&quot;&gt;&lt;a href=&quot;#分配何时的内存给RegionServer&quot; class=&quot;headerlink&quot; title=&quot;分配何时的内存给RegionServer&quot;&gt;&lt;/a&gt;分配何时的内存给RegionServer&lt;/h3&gt;&lt;p&gt;在不影响其他服务的情况下，越大越好。在HBase的conf目录下的hbase-env.sh的最后添加&lt;code&gt;export HBASE_REGIONSERVER_OPTS=&amp;quot;- Xmx16000m $HBASE_REGIONSERVER_OPTS&amp;quot;&lt;/code&gt;&lt;br&gt;其中16000m为分配给REgionServer的内存大小。&lt;/p&gt;
&lt;h3 id=&quot;写数据的备份数&quot;&gt;&lt;a href=&quot;#写数据的备份数&quot; class=&quot;headerlink&quot; title=&quot;写数据的备份数&quot;&gt;&lt;/a&gt;写数据的备份数&lt;/h3&gt;&lt;p&gt;备份数与读性能是成正比，与写性能成反比，且备份数影响高可用性。有两种配置方式，一种是将hdfs-site.xml拷贝到hbase的conf目录下，然后在其中添加或修改配置项&lt;code&gt;dfs.replication&lt;/code&gt;的值为要设置的备份数，这种修改所有的HBase用户都生效。另一种方式是改写HBase代码，让HBase支持针对列族设置备份数，在创建表时，设置列族备份数，默认为3，此种备份数支队设置的列族生效。&lt;/p&gt;
&lt;h3 id=&quot;客户端一次从服务器拉取的数量&quot;&gt;&lt;a href=&quot;#客户端一次从服务器拉取的数量&quot; class=&quot;headerlink&quot; title=&quot;客户端一次从服务器拉取的数量&quot;&gt;&lt;/a&gt;客户端一次从服务器拉取的数量&lt;/h3&gt;&lt;p&gt;通过配置一次拉取较大的数据量可以减少客户端获取数据的时间，但是他会占用客户端的内存，有三个地方可以进行配置&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;在HBase的conf配置文件中进行配置&lt;code&gt;hbase.client.scanner.caching&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;通过调用&lt;code&gt;HTble.setScannerCaching(int scannerCaching)&lt;/code&gt;进行配置；&lt;/li&gt;
&lt;li&gt;通过调用&lt;code&gt;Sacn.setCaching(int caching)&lt;/code&gt;进行配置，三者的优先级越来越高。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&quot;客户端拉取的时候指定列族&quot;&gt;&lt;a href=&quot;#客户端拉取的时候指定列族&quot; class=&quot;headerlink&quot; title=&quot;客户端拉取的时候指定列族&quot;&gt;&lt;/a&gt;客户端拉取的时候指定列族&lt;/h3&gt;&lt;p&gt;scan是指定需要column family，可以减少网络传输数据量，否则默认scan操作会返回整行所有column family的数据&lt;/p&gt;
&lt;h3 id=&quot;拉取完数据之后关闭ResultScanner&quot;&gt;&lt;a href=&quot;#拉取完数据之后关闭ResultScanner&quot; class=&quot;headerlink&quot; title=&quot;拉取完数据之后关闭ResultScanner&quot;&gt;&lt;/a&gt;拉取完数据之后关闭ResultScanner&lt;/h3&gt;&lt;p&gt;通过 scan 取完数据后，记得要关闭 ResultScanner，否则 RegionServer 可能会出现问题（对应的 Server 资源无法释放）。&lt;/p&gt;
&lt;h3 id=&quot;RegionServer的请求处理IO线程数&quot;&gt;&lt;a href=&quot;#RegionServer的请求处理IO线程数&quot; class=&quot;headerlink&quot; title=&quot;RegionServer的请求处理IO线程数&quot;&gt;&lt;/a&gt;RegionServer的请求处理IO线程数&lt;/h3&gt;&lt;p&gt;较少的IO线程适用于处理单次请求内存消耗较高的Big Put场景（大容量单词Put或设置了较大cache的scan，均数据Big Put）或RegionServer的内存比较紧张的场景。&lt;/p&gt;
&lt;p&gt;较多的IO线程，适用于单次请求内存消耗低，TPS要求（每次事务处理量）非常高的场景。这只该值的时候，以监控内存为主要参考&lt;/p&gt;
&lt;p&gt;在hbase-site.xml配置文件中配置项为&lt;code&gt;hbase.regionserver.handle.count&lt;/code&gt;&lt;/p&gt;
&lt;h3 id=&quot;Region大小设置&quot;&gt;&lt;a href=&quot;#Region大小设置&quot; class=&quot;headerlink&quot; title=&quot;Region大小设置&quot;&gt;&lt;/a&gt;Region大小设置&lt;/h3&gt;&lt;p&gt;配置项&lt;code&gt;hbase.hregion.max.filesize&lt;/code&gt;，所属配置文件为hbase-site.xml，默认大小是256m。&lt;/p&gt;
&lt;p&gt;在当前RegionServer上单个Region的最大存储空间，单个Region超过该值时，这个Region会被自动split成更小的Region。小Region对split和compaction友好，因为拆分Region或compact小Region里的StoreFile速度非常快，内存占用低。缺点是split和compaction会很频繁，特别是数量较多的小Region不同的split，compaction，会导致集群响应时间波动很大，Region数量太多不仅给管理上带来麻烦，设置会引起一些HBase个bug。一般 512M 以下的都算小 Region。大 Region 则不太适合经常 split 和 compaction，因为做一次 compact 和 split 会产生较长时间的停顿，对应用的读写性能冲击非常大。&lt;/p&gt;
&lt;p&gt;此外，大 Region 意味着较大的 StoreFile，compaction 时对内存也是一个挑战。如果你的应用场景中，某个时间点的访问量较低，那么在此时做 compact 和 split，既能顺利完成 split 和 compaction，又能保证绝大多数时间平稳的读写性能。compaction 是无法避免的，split 可以从自动调整为手动。只要通过将这个参数值调大到某个很难达到的值，比如 100G，就可以间接禁用自动 split(RegionServer 不会对未到达 100G 的 Region 做 split)。再配合 RegionSplitter 这个工具，在需要 split 时，手动 split。手动 split 在灵活性和稳定性上比起自动 split 要高很多，而且管理成本增加不多，比较推荐 online 实时系统使用。内存方面，小 Region 在设置 memstore 的大小值上比较灵活，大 Region 则过大过小都不行，过大会导致 flush 时 app 的 IO wait 增高，过小则因 StoreFile 过多影响读性能。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;本文主要是从HBase应用程序设计与开发的角度，总结几种常用的性能优化方法。&lt;br&gt;
    
    </summary>
    
    
      <category term="hbase" scheme="http://dxer.github.io/tags/hbase/"/>
    
  </entry>
  
  <entry>
    <title>Redis-消息队列</title>
    <link href="http://dxer.github.io/2016/03/20/redis-%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"/>
    <id>http://dxer.github.io/2016/03/20/redis-消息队列/</id>
    <published>2016-03-20T03:21:38.000Z</published>
    <updated>2016-06-07T00:39:08.402Z</updated>
    
    <content type="html">&lt;p&gt;在网站开发中，当页面需要进行如发送邮件、发送短信、复杂数据运算等耗时较长的操作时会阻塞页面的渲染。为了避免用户等待太久，应该使用独立的线程来完成这类操作。不过一些编程语言或框架不易实现多线程，这时很容易就会想到通过其他进程来实现。设想有一个进程能够完成发邮件的功能，那么在页面中只需要想办法通知这个进程向指定的地址发送邮件就可以了。&lt;/p&gt;
&lt;p&gt;更多的时候，服务器做的额外的事情，并不需要客户端等待，这时候就可以把这些额外的事情异步去做。处理异步任务的工具很多。主要还是处理通知消息，针对通知消息通常采用的是队列结构。这个异步处理的模型可以抽象为生产者和消费者模型。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;redis中提供了两种方式来做消息队列，一个是使用生产者消费者模式，一种是使用发布订阅者模式。生产者消费者模式会让一个或者多个客户端监听消息队列，一旦有队列中有消息，消费者会马上去消费，谁先获得这个消息，谁就去处理。如果队列为空，则消费者继续监听。发布订阅者模式也是使用了一个或者多个客户端订阅消息频道，只要发布者发布了消息，所有的订阅者都能收到消息。&lt;/p&gt;
&lt;p&gt;这里我们先看下生产者和消费者模型的消息队列。&lt;/p&gt;
&lt;h2 id=&quot;队列&quot;&gt;&lt;a href=&quot;#队列&quot; class=&quot;headerlink&quot; title=&quot;队列&quot;&gt;&lt;/a&gt;队列&lt;/h2&gt;&lt;p&gt;与任务队列进行交互的实体有两类：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;生产者（producer）：生产者会将需要处理的任务放入任务队列中&lt;/li&gt;
&lt;li&gt;消费者（consumer）：消费者不断从任务队列中读入任务信息并执行&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;使用任务队列的好处&quot;&gt;&lt;a href=&quot;#使用任务队列的好处&quot; class=&quot;headerlink&quot; title=&quot;使用任务队列的好处&quot;&gt;&lt;/a&gt;使用任务队列的好处&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;松耦合&lt;br&gt;生产者和消费者无需知道彼此的实现细节，只需要约定好任务的描述格式。这使得生产者和消费者可以由不同的团队使用不同的编程语言来进行开发。&lt;/li&gt;
&lt;li&gt;易扩展&lt;br&gt;可以很方便的将消费者阔这到很多个，而且可以分布在不同的服务器中。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&quot;普通队列&quot;&gt;&lt;a href=&quot;#普通队列&quot; class=&quot;headerlink&quot; title=&quot;普通队列&quot;&gt;&lt;/a&gt;普通队列&lt;/h3&gt;&lt;p&gt;在redis中，可以使用列表（list）类型来实现。使用LPUSH和RPOP命令，&lt;br&gt;生产者将任务使用LPUSH命令加入到某个键中，消费者不断的使用RPOP命令从该键中取出任务。&lt;br&gt;代码如下:&lt;/p&gt;
&lt;figure class=&quot;highlight java&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;while&lt;/span&gt; (&lt;span class=&quot;keyword&quot;&gt;true&lt;/span&gt;) &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	String task = jedis.rpop(&lt;span class=&quot;string&quot;&gt;&quot;queue.task&quot;&lt;/span&gt;);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&lt;span class=&quot;keyword&quot;&gt;if&lt;/span&gt;(task!=&lt;span class=&quot;keyword&quot;&gt;null&lt;/span&gt; &amp;amp;&amp;amp; task.length()&amp;gt;&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;)&amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		execute(task);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&amp;#125;&lt;span class=&quot;keyword&quot;&gt;else&lt;/span&gt;&amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		Thread.sleep(&lt;span class=&quot;number&quot;&gt;1000&lt;/span&gt;);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;上面是一个很简单的任务队列的程序，不过上面的代码还是有点不太完美的地方：当任务队列中没有任务的时候，消费者每秒都会调用一次RPOP命令查看是否有新的任务。这里我们可以借助BRPOP命令来实现一旦有新的任务队列就通知消费者，这样消费者每秒都去查看任务队列中是否有任务了。&lt;/p&gt;
&lt;p&gt;上面的程序可以修改为：&lt;br&gt;&lt;figure class=&quot;highlight java&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;while&lt;/span&gt; (&lt;span class=&quot;keyword&quot;&gt;true&lt;/span&gt;) &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	List&amp;lt;String&amp;gt; tasks = jedis.brpop(&lt;span class=&quot;number&quot;&gt;10&lt;/span&gt;, &lt;span class=&quot;string&quot;&gt;&quot;queue.task&quot;&lt;/span&gt;);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&lt;span class=&quot;keyword&quot;&gt;if&lt;/span&gt; (tasks != &lt;span class=&quot;keyword&quot;&gt;null&lt;/span&gt; &amp;amp;&amp;amp; tasks.size() &amp;gt; &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;) &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		execute(tasks.get(&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;)); &lt;span class=&quot;comment&quot;&gt;// 这里要获取index为1的数据，因为index为0的数据是该队列的名字&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;BRPOP&lt;/code&gt;命令和&lt;code&gt;RPOP&lt;/code&gt;命令相似，唯一的区别就是当列表中没有元数据的时候，BRPOP命令会一直阻塞住连接，直到有新元素加入。&lt;/p&gt;
&lt;p&gt;BRPOP命令接收两个参数，第一个是键名，第二个是超时时间（单位：s）。当超过了这个时间，任然没有获得到新的数据的话，就会返回nil。当设置超时时间为0的时候，表示不限制等待时间，也就是说没有新数据加入的时候，就会永远阻塞下去。&lt;/p&gt;
&lt;p&gt;redis还提供了BLPOP命令，和BRPOP的区别在与从队列取数据时，BLPOP会从队列左边开始取数据，而BRPOP是从队列的右边开始取数据。&lt;/p&gt;
&lt;h2 id=&quot;优先级队列&quot;&gt;&lt;a href=&quot;#优先级队列&quot; class=&quot;headerlink&quot; title=&quot;优先级队列&quot;&gt;&lt;/a&gt;优先级队列&lt;/h2&gt;&lt;p&gt;在产品给用户发送短信的时候，有验证短信和营销短信，同样都是将短信添加到任务队列，供消费者进行处理。在没有优先级队列的时候，系统现在正在给用户发送营销短信，这是有一个用户注册了，系统要给用户发送验证短信，但是系统正在处理营销短信，按照普通任务队列，验证短信，要在营销短信发送完成之后，才开始发送，这样多影响用户体验。要是不管在什么时候，只要有发送验证短信的任务，就能立刻去处理掉，这样就好啦。&lt;/p&gt;
&lt;p&gt;这样我们就需要一个具有优先级的任务队列啦，按照我们的业务逻辑，优先处理重要的任务。&lt;/p&gt;
&lt;p&gt;在redis中，&lt;code&gt;BRPOP&lt;/code&gt;命令可以同时接收多个键，完整的命令格式如下&lt;/p&gt;
&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;BRPOP queue.task.1 queue.task.2 0&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;它可以同时检测多个键，如果所有的键都没有数据则阻塞，如果其中有一个键有数据则会返回响应的数据。如果多个键都有数据，则按照命令中从左到右的键的顺序取第一个有数据的键中对应的数据。这样我们就可以实现一个具有优先级的任务队列了。&lt;/p&gt;
&lt;p&gt;代码如下：&lt;br&gt;&lt;figure class=&quot;highlight java&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;while&lt;/span&gt; (&lt;span class=&quot;keyword&quot;&gt;true&lt;/span&gt;) &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	List&amp;lt;String&amp;gt; tasks = jedis.brpop(&lt;span class=&quot;number&quot;&gt;10&lt;/span&gt;, &lt;span class=&quot;string&quot;&gt;&quot;queue.task.1&quot;&lt;/span&gt;, &lt;span class=&quot;string&quot;&gt;&quot;queue.task.2&quot;&lt;/span&gt;);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&lt;span class=&quot;keyword&quot;&gt;if&lt;/span&gt; (tasks != &lt;span class=&quot;keyword&quot;&gt;null&lt;/span&gt; &amp;amp;&amp;amp; tasks.size() &amp;gt; &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;) &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		execute(tasks.get(&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;)); &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;在网站开发中，当页面需要进行如发送邮件、发送短信、复杂数据运算等耗时较长的操作时会阻塞页面的渲染。为了避免用户等待太久，应该使用独立的线程来完成这类操作。不过一些编程语言或框架不易实现多线程，这时很容易就会想到通过其他进程来实现。设想有一个进程能够完成发邮件的功能，那么在页面中只需要想办法通知这个进程向指定的地址发送邮件就可以了。&lt;/p&gt;
&lt;p&gt;更多的时候，服务器做的额外的事情，并不需要客户端等待，这时候就可以把这些额外的事情异步去做。处理异步任务的工具很多。主要还是处理通知消息，针对通知消息通常采用的是队列结构。这个异步处理的模型可以抽象为生产者和消费者模型。&lt;br&gt;
    
    </summary>
    
    
      <category term="redis" scheme="http://dxer.github.io/tags/redis/"/>
    
  </entry>
  
  <entry>
    <title>HBase简介</title>
    <link href="http://dxer.github.io/2016/03/19/hbase%E7%AE%80%E4%BB%8B/"/>
    <id>http://dxer.github.io/2016/03/19/hbase简介/</id>
    <published>2016-03-19T03:21:38.000Z</published>
    <updated>2016-05-12T08:25:38.218Z</updated>
    
    <content type="html">&lt;p&gt;HBase是一个分布式的、面向列的开源数据库。HBase是Apache的Hadoop项目的子项目。HBase不同于一般的关系数据库，它是一个适合于非结构化数据存储的数据库。另一个不同的是HBase基于列的而不是基于行的模式。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;HBase表的特点&quot;&gt;&lt;a href=&quot;#HBase表的特点&quot; class=&quot;headerlink&quot; title=&quot;HBase表的特点&quot;&gt;&lt;/a&gt;HBase表的特点&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;大：一个表可以有有数以十亿行，上百万列&lt;/li&gt;
&lt;li&gt;面向列：面向列（族）的存储和权限访问，列（族）独立索引&lt;/li&gt;
&lt;li&gt;稀疏：对于未空（null）的列，并不占用存储空间，因此表可以设计的非常稀疏&lt;/li&gt;
&lt;li&gt;数据类型单一：HBase中的数据类型都是字符串（string）&lt;/li&gt;
&lt;li&gt;无模式：每行都有一个可排序的主键和任意多的列，列可以根据需要动态增加，同一张表中不同的行可以截然不同的列&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;HBase和关系数据库区别&quot;&gt;&lt;a href=&quot;#HBase和关系数据库区别&quot; class=&quot;headerlink&quot; title=&quot;HBase和关系数据库区别&quot;&gt;&lt;/a&gt;HBase和关系数据库区别&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;数据库类型：HBase中的数据类型都是字符串类型（string）&lt;/li&gt;
&lt;li&gt;数据操作：HBase只有普通的增删改查等操作，没有表之间的关联查询&lt;/li&gt;
&lt;li&gt;存储模式：HBase是基于列式存储模式，而RDBMS是基于行式存储的&lt;/li&gt;
&lt;li&gt;应用场景：HBase适合存储大量数据，查询效率极高&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;基本概念&quot;&gt;&lt;a href=&quot;#基本概念&quot; class=&quot;headerlink&quot; title=&quot;基本概念&quot;&gt;&lt;/a&gt;基本概念&lt;/h2&gt;&lt;p&gt;HBase以表的形式存储数据。表有行和列组成。列划分为若干个列族(column family)&lt;/p&gt;
&lt;h3 id=&quot;RowKey&quot;&gt;&lt;a href=&quot;#RowKey&quot; class=&quot;headerlink&quot; title=&quot;RowKey&quot;&gt;&lt;/a&gt;RowKey&lt;/h3&gt;&lt;p&gt;用来检索记录的主键&lt;br&gt;主键为任意字符串，最大长度为64kb，按字典顺序存储，在HBase内部保存为字节数组&lt;/p&gt;
&lt;p&gt;Rowkey是以字典顺序从大到小排序&lt;br&gt;Rowkey尽量散列设计，保证所有的数据不是在一个Region上，从而避免读写的时候负载会集中在个别Region上。&lt;br&gt;Rowkey的长度尽量短，如果太长存储开销会增加，影响存储效率，Rowkey字段过长，会导致内存的利用率降低，进而降低索引的命中率&lt;/p&gt;
&lt;h6 id=&quot;常见Rowkey设计方法：&quot;&gt;&lt;a href=&quot;#常见Rowkey设计方法：&quot; class=&quot;headerlink&quot; title=&quot;常见Rowkey设计方法：&quot;&gt;&lt;/a&gt;常见Rowkey设计方法：&lt;/h6&gt;&lt;ul&gt;
&lt;li&gt;反转userId，将userId字符串反转后存储&lt;/li&gt;
&lt;li&gt;散列userId，对userId进行散列&lt;/li&gt;
&lt;li&gt;userId取模后进行MD5，区前6位作为前缀加入到userId前面&lt;/li&gt;
&lt;li&gt;时间使用long型来表示&lt;/li&gt;
&lt;li&gt;尽量使用编码压缩&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;访问HBase表中的行，只有三种方式：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;通过rowkey&lt;/li&gt;
&lt;li&gt;通过rowkey的range&lt;/li&gt;
&lt;li&gt;全表扫描&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;列族（Column-Family）&quot;&gt;&lt;a href=&quot;#列族（Column-Family）&quot; class=&quot;headerlink&quot; title=&quot;列族（Column Family）&quot;&gt;&lt;/a&gt;列族（Column Family）&lt;/h3&gt;&lt;p&gt;列族在创建表的时候声明，一个列族可以包含多个列，列中的数据都是以二进制形式存在，没有数据类型&lt;br&gt;列族是一些列的集合&lt;br&gt;一个列族所有成员是有着相同的前缀。用”:”来分割列族和列名&lt;/p&gt;
&lt;h3 id=&quot;列（Column）&quot;&gt;&lt;a href=&quot;#列（Column）&quot; class=&quot;headerlink&quot; title=&quot;列（Column）&quot;&gt;&lt;/a&gt;列（Column）&lt;/h3&gt;&lt;p&gt;属于某一个column family，columnfamily:columnName，每条记录可动态添加&lt;/p&gt;
&lt;h3 id=&quot;时间戳和存储单元（TimeStamp-and-Cell）&quot;&gt;&lt;a href=&quot;#时间戳和存储单元（TimeStamp-and-Cell）&quot; class=&quot;headerlink&quot; title=&quot;时间戳和存储单元（TimeStamp and Cell）&quot;&gt;&lt;/a&gt;时间戳和存储单元（TimeStamp and Cell）&lt;/h3&gt;&lt;p&gt;HBase中通过row和columns确定的唯一个存储单元成为cell，每个cell都保存同一份数据的多个版本&lt;br&gt;在写入数据时，时间戳可以又HBase自动赋值（当前系统时间精确到毫秒），也阔以显示赋值&lt;br&gt;每个cell中，不同版本的数据按照时间的倒叙排序&lt;br&gt;{row，Column，version}元组就是HBase中的一个cell&lt;/p&gt;
&lt;h2 id=&quot;HBase物理模型&quot;&gt;&lt;a href=&quot;#HBase物理模型&quot; class=&quot;headerlink&quot; title=&quot;HBase物理模型&quot;&gt;&lt;/a&gt;HBase物理模型&lt;/h2&gt;&lt;p&gt;HBase存储细节&lt;br&gt;每个列族存储在HDFS上的一个单独文件夹中&lt;br&gt;Key和Version number会在每个列族中存储一份&lt;br&gt;空值不会被保存&lt;br&gt;HBase 为每个值维护了多级索引，即：&lt;key, column=&quot;&quot; family,=&quot;&quot; name,=&quot;&quot; timestamp=&quot;&quot;&gt;&lt;/key,&gt;&lt;/p&gt;
&lt;p&gt;物理存储：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Table中所有行都按照row key的字典序排列；&lt;/li&gt;
&lt;li&gt;Table在行的方向上分割为多个Region；&lt;/li&gt;
&lt;li&gt;Region按大小分割的，每个表开始只有一个region，随着数据增多，region不断增大，当增大到一个阀值的时候，region就会等分会两个新的region，之后会有越来越多的region；&lt;/li&gt;
&lt;li&gt;Region是Hbase中分布式存储和负载均衡的最小单元，不同Region分布到不同RegionServer上。&lt;/li&gt;
&lt;li&gt;Region虽然是分布式存储的最小单元，但并不是存储的最小单元。Region由一个或者多个Store组成，每个store保存一个columns family；每个Strore又由一个memStore和0至多个StoreFile组成，StoreFile包含HFile；memStore存储在内存中，StoreFile存储在HDFS上。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&quot;HBase架构与基本组件&quot;&gt;&lt;a href=&quot;#HBase架构与基本组件&quot; class=&quot;headerlink&quot; title=&quot;HBase架构与基本组件&quot;&gt;&lt;/a&gt;HBase架构与基本组件&lt;/h2&gt;&lt;h3 id=&quot;Client&quot;&gt;&lt;a href=&quot;#Client&quot; class=&quot;headerlink&quot; title=&quot;Client&quot;&gt;&lt;/a&gt;Client&lt;/h3&gt;&lt;p&gt;整个HBase集群的入口&lt;br&gt;使用HBase RPC机制与HMaster和HRegionServer通信&lt;br&gt;与HMaster通信进行管理类的操作&lt;br&gt;与HRegionServer通信进行读写类操作&lt;br&gt;包含访问HBase的接口，并维护cache来加快对HBase的访问，与HRegionServer交互&lt;/p&gt;
&lt;h3 id=&quot;ZooKeeper程序协调服务&quot;&gt;&lt;a href=&quot;#ZooKeeper程序协调服务&quot; class=&quot;headerlink&quot; title=&quot;ZooKeeper程序协调服务&quot;&gt;&lt;/a&gt;ZooKeeper程序协调服务&lt;/h3&gt;&lt;p&gt;保证任何时候，集群中只有一个Master（HA）&lt;br&gt;存储所有Region的寻址入口&lt;br&gt;实时监控Region server的上线和下线信息。并实时通知HMaster&lt;br&gt;存储HBase的schema和table元数据&lt;/p&gt;
&lt;h3 id=&quot;HBase主节点HMaster&quot;&gt;&lt;a href=&quot;#HBase主节点HMaster&quot; class=&quot;headerlink&quot; title=&quot;HBase主节点HMaster&quot;&gt;&lt;/a&gt;HBase主节点HMaster&lt;/h3&gt;&lt;p&gt;管理用户对Table的增删改查操作（表操作）&lt;br&gt;管理HRegionServer的负载均衡，调整Region分布&lt;br&gt;在Region split后，负责新Region的分配&lt;br&gt;在HRegionServer停机后，负责将失效的HRegionServer上的Region迁移&lt;br&gt;HMaster失效仅会导致所有元数据无法被修改，但是表的数据读写还是可以正常进行&lt;/p&gt;
&lt;h3 id=&quot;HRegionServer节点&quot;&gt;&lt;a href=&quot;#HRegionServer节点&quot; class=&quot;headerlink&quot; title=&quot;HRegionServer节点&quot;&gt;&lt;/a&gt;HRegionServer节点&lt;/h3&gt;&lt;p&gt;维护HRegion并往HDFS中写数据&lt;br&gt;当表的大小超过设置值时，split HRegion&lt;br&gt;在HRegionServer停机后，负责失效HRegionServer上的HRegion迁移&lt;/p&gt;
&lt;h2 id=&quot;HBase与Zookeeper&quot;&gt;&lt;a href=&quot;#HBase与Zookeeper&quot; class=&quot;headerlink&quot; title=&quot;HBase与Zookeeper&quot;&gt;&lt;/a&gt;HBase与Zookeeper&lt;/h2&gt;&lt;p&gt;HBase元数据存储在Zookeeper中&lt;br&gt;默认情况下,HBase管理Zookeeper实例，比如，启动或者停止Zookeeper&lt;br&gt;Zookeeper解决HBase单点故障问题&lt;br&gt;HMaster与HRegionServer启动时会向Zookeeper注册&lt;/p&gt;
&lt;h2 id=&quot;WAL&quot;&gt;&lt;a href=&quot;#WAL&quot; class=&quot;headerlink&quot; title=&quot;WAL&quot;&gt;&lt;/a&gt;WAL&lt;/h2&gt;&lt;p&gt;WAL是Regionserver在处理插入和删除的过程中用来记录操作内容的一种日志&lt;/p&gt;
&lt;p&gt;一个表由一个region或者多个region组成，region由regionserver进行管理&lt;br&gt;每个region包含memstore和storeFile，memstore存储在内存中，storeFile存储在磁盘中&lt;/p&gt;
&lt;h2 id=&quot;HBase在HDFS中存储&quot;&gt;&lt;a href=&quot;#HBase在HDFS中存储&quot; class=&quot;headerlink&quot; title=&quot;HBase在HDFS中存储&quot;&gt;&lt;/a&gt;HBase在HDFS中存储&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;code&gt;/hbase/.tmp&lt;/code&gt;：临时目录，当对表做创建和删除的时候，会将表move到该目录，然后进行操作&lt;/li&gt;
&lt;li&gt;&lt;code&gt;/hbase/data&lt;/code&gt;：核心目录，存储HBase表的数据&lt;br&gt;默认情况下，目录下有两个目录&lt;/li&gt;
&lt;li&gt;&lt;code&gt;/hbase/data/default&lt;/code&gt;:&lt;br&gt;在用户创建表的时候，没有指定namespace时，表就创建在此目录下&lt;/li&gt;
&lt;li&gt;&lt;code&gt;/hbase/data/hbase&lt;/code&gt;：系统内部创建的表，.META.表（region的详细信息）和namespace表（namespace信息）&lt;/li&gt;
&lt;li&gt;&lt;code&gt;/hbase/hbase.id&lt;/code&gt;：存储的是集群的唯一cluster id（uuid）&lt;/li&gt;
&lt;li&gt;&lt;code&gt;/hbase/hbase.version&lt;/code&gt;：集群的版本号&lt;/li&gt;
&lt;li&gt;&lt;code&gt;/hbase/oldWALs&lt;/code&gt;: 对应0.94.x版本中.oldlogs目录&lt;br&gt;当/hbase/WALs目录中的logs没有之后，会将这些logs移动到此目录下，HMaster会定期清理&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;HBase使用场景&quot;&gt;&lt;a href=&quot;#HBase使用场景&quot; class=&quot;headerlink&quot; title=&quot;HBase使用场景&quot;&gt;&lt;/a&gt;HBase使用场景&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;大数据量存储，大数据量高并发操作&lt;/li&gt;
&lt;li&gt;需要对数据随机读写操作&lt;/li&gt;
&lt;li&gt;读写访问均是非常简单的操作&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&quot;HBase与HDFS对比&quot;&gt;&lt;a href=&quot;#HBase与HDFS对比&quot; class=&quot;headerlink&quot; title=&quot;HBase与HDFS对比&quot;&gt;&lt;/a&gt;HBase与HDFS对比&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;两者都具有良好的容错性和扩展性，都可以扩展到成百上千个节点；&lt;/li&gt;
&lt;li&gt;HDFS适合批处理场景，不支持数据随机查找，不适合增量数据处理，不支持数据更新&lt;/li&gt;
&lt;/ol&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;HBase是一个分布式的、面向列的开源数据库。HBase是Apache的Hadoop项目的子项目。HBase不同于一般的关系数据库，它是一个适合于非结构化数据存储的数据库。另一个不同的是HBase基于列的而不是基于行的模式。&lt;br&gt;
    
    </summary>
    
    
      <category term="hbase" scheme="http://dxer.github.io/tags/hbase/"/>
    
  </entry>
  
  <entry>
    <title>HBase入门</title>
    <link href="http://dxer.github.io/2016/03/18/hbase/"/>
    <id>http://dxer.github.io/2016/03/18/hbase/</id>
    <published>2016-03-18T11:25:38.000Z</published>
    <updated>2016-05-18T09:51:11.887Z</updated>
    
    <content type="html">&lt;h2 id=&quot;HBase一些基本概念&quot;&gt;&lt;a href=&quot;#HBase一些基本概念&quot; class=&quot;headerlink&quot; title=&quot;HBase一些基本概念&quot;&gt;&lt;/a&gt;HBase一些基本概念&lt;/h2&gt;&lt;p&gt;1、Row key&lt;br&gt;行主键，在对HBase进行查询时候只能依靠Row key，HBase不支持条件查询等类似于一些主流数据库的查询方式，读取记录只能依赖行主键以及进行全局扫面，可以将行主键想象成主流数据库查询过程中用到的主键（例如，id）。&lt;/p&gt;
&lt;p&gt;2、Column Family&lt;br&gt;列族，可以将列族想象成日常主流数据库中的表结构的所有列的一个大管家，列族中存储了所有列的名称，整个表包括多少列，列族就包括多少（除去Row key和Timestamp列）。&lt;/p&gt;
&lt;p&gt;3、Column&lt;br&gt;列，HBase的每个列都隶属于一个列族，以列族名称作为前缀，同一列族中的所有列会聚集在一个存储单元上，同时按照Column key进行排序。&lt;/p&gt;
&lt;p&gt;4、Timestamp&lt;br&gt;在HBase中，通过row key 和 Colum Family确定一份数据，同一个row key和Colum Family可能有多份不同的数据，HBase通过时间戳来区分这些数据，同时按照时间戳对左右的数据进行排序，最新的数据排在最前面，时间戳默认为系统当前时间（精确到毫秒），同时也可以人为设置该值。&lt;/p&gt;
&lt;p&gt;5、Value&lt;br&gt;我们在HBase表中精确查询数据时，通过TableName找到表，接着通过Row key找到对应的行，然后通过ColumnKey找到相应的列，最后根据时间戳找到最新的需要查询的值，这个值就是value。&lt;/p&gt;
&lt;p&gt;6、存储类型&lt;br&gt;在HBase中，表名称是字符串，行键和列名称是二进制值（即就是Java中的Byte[]），时间戳是一个64为的整数（Java中的long类型），最后的查询结果Value是字节数组（Java中的byte[]类型）。&lt;/p&gt;
&lt;p&gt;7、存储结构&lt;/p&gt;
&lt;p&gt;在HBase中，整个数据表是按照行键进行排序，每行包括任意数量的列，列和列之间通过列键进行排序，每列包括若干的数据，整个HBase的存储结构可以理解如下：&lt;/p&gt;
&lt;figure class=&quot;highlight sql&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;Table(&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	Row key，List(&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		SortedMap(&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;			Column，list(&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;			Value，Timestamp&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;			)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;hr&gt;
&lt;h2 id=&quot;HBase数据模型&quot;&gt;&lt;a href=&quot;#HBase数据模型&quot; class=&quot;headerlink&quot; title=&quot;HBase数据模型&quot;&gt;&lt;/a&gt;HBase数据模型&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;表（table）：HBase用表组织数据。表名是字符串（String），由可以在文件系统路径里使用的字符组成。&lt;/li&gt;
&lt;li&gt;行（row）：在表里，数据按行存储。行由行健（rowkey）唯一标识。行健没有数据类型，视为字节数组byte[]。&lt;/li&gt;
&lt;li&gt;列族（column family）：行里的数据按照列族进行分组，列族也影响到HBase数据的物理存放。因此，他们必须事前定义并且不轻易修改。表中每行拥有相同列族，尽管行不需要在每个列族里存储数据，列族名字是字符串（String），由可以在文件系统路径里使用的字符组成。&lt;/li&gt;
&lt;li&gt;列限定符（column qualifier）：列族里的数据通过列限定符或列来定位。列限定符不必事前定义。列限定符不必在不同行之间保持一致。就像行健一样，类限定符没有数据类型，视为字节数据byte[]。&lt;/li&gt;
&lt;li&gt;单元（cell）：行健、列族和列限定符一起确定一个单元。存储在单元里的数据成为单元值（value）。值没有数据类型，视为字节数组byte[]。&lt;/li&gt;
&lt;li&gt;时间版本（version）：单元值有时间版本。时间版本用时间戳标识，是一个long型。没有指定时间版本时，当前时间戳作为操作的基础。HBase保留单元值时间版本的数量基于列族进行配置。默认3个版本。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;数据坐标&lt;/p&gt;
&lt;p&gt;行健、列族、列限定符和时间版本&lt;/p&gt;
&lt;h5 id=&quot;写&quot;&gt;&lt;a href=&quot;#写&quot; class=&quot;headerlink&quot; title=&quot;写&quot;&gt;&lt;/a&gt;写&lt;/h5&gt;&lt;p&gt;执行写入的时候会写到两个文件：预写式日志（write-ahead log，也称HLog）和MemStore。HBase的默认方式是把写入动作记录在这两个地方，以保证数据持久化。只有当这两个地方的变化信息都写入并确认后，才认为写动作完成。&lt;/p&gt;
&lt;p&gt;&lt;em&gt;MemStore&lt;/em&gt;是内存里的写入缓冲区，HBase中数据在永久写入硬盘之前在这里积累。当MemStore填满后，其中的数据会刷写到硬盘，生成一个HFile文件。HFile是HBase使用底层存储格式。HFile对应列族，一个列族可以有多个HFile，但一个HFile不能存储多个列族的数据。在集群的每个节点上，每个列族都有一个MemStore。&lt;/p&gt;
&lt;p&gt;注：不写入WAL会在RegionServer故障时增加丢失数据的风险。关闭WAL，出现故障时HBase可能无法恢复数据，没有刷写到硬盘的所有写入数据都会丢失。&lt;/p&gt;
&lt;h4 id=&quot;读&quot;&gt;&lt;a href=&quot;#读&quot; class=&quot;headerlink&quot; title=&quot;读&quot;&gt;&lt;/a&gt;读&lt;/h4&gt;&lt;p&gt;HBase在读操作上使用了LRU（最近最少使用算法）缓存技术。也叫作BlockCache。BlockCache设计用来保存从HFile里读入内存的频繁访问的数据，避免硬盘读。每个列族都有自己的BlockCache。&lt;/p&gt;
&lt;p&gt;BlockCache中的Block是HBase从硬盘完成一次读取的数据单位。HFile物理存放形式是一个Block的序列外加这些Block的索引。从HBase中读取一个Block需要先将索引上查找一次改Block然后从硬盘读出、Block是建立索引的最小数据单位，也是从硬盘读取的最小数据单位。Block大小按照列族设定，默认是64kb。如果主要用于随机查询，可能需要细粒度的Block索引，小一点儿的Block更好一些。Block变小会导致索引变大，进而消耗更多内存。如果经常执行顺序扫描，一次读取多个Block，大一点的Block更好一些。Block变大意味着索引项变少，索引编写，因此节省内存。&lt;/p&gt;
&lt;p&gt;从HBase总读出一行，首先会检查MemStore等待修改的队列，然后检查BlockCache看包含改行的Blocj是否最近被访问过，最后访问硬盘上对应的HFile。&lt;/p&gt;
&lt;h4 id=&quot;删&quot;&gt;&lt;a href=&quot;#删&quot; class=&quot;headerlink&quot; title=&quot;删&quot;&gt;&lt;/a&gt;删&lt;/h4&gt;&lt;p&gt;执行HBase删除命令的时候，实际上数据并不会立即删除，只是会在该数据上打上删除的记录。被标记的记录不能在Get和Scan命令中返回结果。因为HFile文件是不能改变的，直到执行一次大合并，含有这些标记的数据才会被处理，被删除的数据占用的空间才会释放。&lt;/p&gt;
&lt;p&gt;&lt;em&gt;大合并（major compaction）&lt;/em&gt;：处理给定region的一个列族的所有HFile。大合并完成后，这个列族的所有HFile合并成一个文件，可以从Shell中收工出发整个表（或者特定region）的大合并。大合并是HBase清理被删除记录的唯一机会&lt;/p&gt;
&lt;p&gt;&lt;em&gt;小合并（minor compaction）&lt;/em&gt;：把多个小HFile合并成一个大HFile。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&quot;HBase-Shell命令&quot;&gt;&lt;a href=&quot;#HBase-Shell命令&quot; class=&quot;headerlink&quot; title=&quot;HBase Shell命令&quot;&gt;&lt;/a&gt;HBase Shell命令&lt;/h2&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Command&lt;/th&gt;
&lt;th&gt;描述&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;alter&lt;/td&gt;
&lt;td&gt;修改列族模式&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;count&lt;/td&gt;
&lt;td&gt;统计表中行的数量&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;create&lt;/td&gt;
&lt;td&gt;创建表&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;describe&lt;/td&gt;
&lt;td&gt;显示表相关的详细信息&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;delete&lt;/td&gt;
&lt;td&gt;删除指定对象的值（可以为表，行，列对应的值，另外也可以指定时间戳的值）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;deleteall&lt;/td&gt;
&lt;td&gt;删除指定行的所有元素值&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;disable&lt;/td&gt;
&lt;td&gt;使表无效&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;enable&lt;/td&gt;
&lt;td&gt;使表有效&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;drop&lt;/td&gt;
&lt;td&gt;删除表&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;exists&lt;/td&gt;
&lt;td&gt;测试表是否存在&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;exit&lt;/td&gt;
&lt;td&gt;退出HBase Shell的值&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;get&lt;/td&gt;
&lt;td&gt;获取行或单元的值&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;incr&lt;/td&gt;
&lt;td&gt;增加指定表、行或列的值&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;list&lt;/td&gt;
&lt;td&gt;列出HBase中存在的所有表&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;put&lt;/td&gt;
&lt;td&gt;向指定的表单元添加值&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;tools&lt;/td&gt;
&lt;td&gt;列出HBase所支持的工具&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;scan&lt;/td&gt;
&lt;td&gt;通过对表的扫描来获取对应的值&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;status&lt;/td&gt;
&lt;td&gt;返回HBase集群的状态信息&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;shutdown&lt;/td&gt;
&lt;td&gt;关闭HBase集群（与exit不同）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;truncate&lt;/td&gt;
&lt;td&gt;重新创建指定表&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;version&lt;/td&gt;
&lt;td&gt;返回HBase版本信息&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h4 id=&quot;create&quot;&gt;&lt;a href=&quot;#create&quot; class=&quot;headerlink&quot; title=&quot;create&quot;&gt;&lt;/a&gt;create&lt;/h4&gt;&lt;p&gt;创建表&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;create &amp;apos;t1&amp;apos;, &amp;#123;NAME =&amp;gt; &amp;apos;f1&amp;apos;, VERSIONS =&amp;gt; 5&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;create &amp;apos;t1&amp;apos;, &amp;#123;Name =&amp;gt; &amp;apos;f1&amp;apos;&amp;#125;, &amp;#123;NAME =&amp;gt; &amp;apos;f2&amp;apos;&amp;#125;, &amp;#123;NAME =&amp;gt; &amp;apos;f3&amp;apos;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;#等价于：&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;create &amp;apos;t1&amp;apos;, &amp;apos;cf&amp;apos;, &amp;apos;cf2&amp;apos;, &amp;apos;cf3&amp;apos;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h4 id=&quot;list&quot;&gt;&lt;a href=&quot;#list&quot; class=&quot;headerlink&quot; title=&quot;list&quot;&gt;&lt;/a&gt;list&lt;/h4&gt;&lt;p&gt;列出HBase中包含的表名称&lt;/p&gt;
&lt;h4 id=&quot;put&quot;&gt;&lt;a href=&quot;#put&quot; class=&quot;headerlink&quot; title=&quot;put&quot;&gt;&lt;/a&gt;put&lt;/h4&gt;&lt;p&gt;向指定表中添加值&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;put &amp;apos;t1&amp;apos;, &amp;apos;rowkey&amp;apos;, &amp;apos;cf:name&amp;apos;, &amp;apos;test&amp;apos;, ts&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;#向t1表的rowkey，列cf:name添加值name，并指定时间戳为ts&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h4 id=&quot;scan&quot;&gt;&lt;a href=&quot;#scan&quot; class=&quot;headerlink&quot; title=&quot;scan&quot;&gt;&lt;/a&gt;scan&lt;/h4&gt;&lt;p&gt;对表的扫描来获取对应的值&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;scan &amp;apos;t1&amp;apos;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;scan &amp;apos;t1&amp;apos;, &amp;#123;COLUMNS =&amp;gt; &amp;apos;cf&amp;apos;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;scan &amp;apos;t1&amp;apos;, &amp;#123;COLUMNS =&amp;gt; &amp;apos;cf&amp;apos;,  LIMIT =&amp;gt; 10&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h4 id=&quot;get&quot;&gt;&lt;a href=&quot;#get&quot; class=&quot;headerlink&quot; title=&quot;get&quot;&gt;&lt;/a&gt;get&lt;/h4&gt;&lt;p&gt;获取行或者单元的值。&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;get &amp;apos;t1&amp;apos;, &amp;apos;rowkey&amp;apos;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;get &amp;apos;t1&amp;apos;, &amp;apos;rowkey&amp;apos;, &amp;#123;COLUMN =&amp;gt; &amp;apos;cf:name&amp;apos;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;&lt;em&gt;注：COLUMN和COLUMNS是不同的，scan操作中的COLUMNS指定的是表的列族，get操作中的COLUMN指定的是特定的列，COLUMN的值是指上是“列族+列修饰符”&lt;/em&gt;&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;HBase一些基本概念&quot;&gt;&lt;a href=&quot;#HBase一些基本概念&quot; class=&quot;headerlink&quot; title=&quot;HBase一些基本概念&quot;&gt;&lt;/a&gt;HBase一些基本概念&lt;/h2&gt;&lt;p&gt;1、Row key&lt;br&gt;行主键，在对HBase进行查询时候只能依靠
    
    </summary>
    
    
      <category term="hbase" scheme="http://dxer.github.io/tags/hbase/"/>
    
  </entry>
  
  <entry>
    <title>Hive入门</title>
    <link href="http://dxer.github.io/2016/03/11/hive02/"/>
    <id>http://dxer.github.io/2016/03/11/hive02/</id>
    <published>2016-03-11T02:14:20.000Z</published>
    <updated>2016-04-28T10:43:14.167Z</updated>
    
    <content type="html">&lt;p&gt;Hive是建立在 Hadoop 上的数据仓库基础构架。它提供了一系列的工具，可以用来进行数据提取转化加载（ETL），这是一种可以存储、查询和分析存储在 Hadoop 中的大规模数据的机制。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;那什么是数据仓库呢&quot;&gt;&lt;a href=&quot;#那什么是数据仓库呢&quot; class=&quot;headerlink&quot; title=&quot;那什么是数据仓库呢?&quot;&gt;&lt;/a&gt;那什么是数据仓库呢?&lt;/h2&gt;&lt;p&gt;数据仓库是一个面向主题的，集成的，不可更新的，随时间不变化的数据集合，它用于支持企业或组织的决策分析处理(主要是查询操作),数据仓库实际上就是一个数据库，可以利用数据仓库来保存数据，但是数据仓库有别于我们一般的数据库&lt;/p&gt;
&lt;h2 id=&quot;数据仓库的结构和建立过程&quot;&gt;&lt;a href=&quot;#数据仓库的结构和建立过程&quot; class=&quot;headerlink&quot; title=&quot;数据仓库的结构和建立过程&quot;&gt;&lt;/a&gt;数据仓库的结构和建立过程&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;数据源（业务数据系统，文档资料，其他数据）&lt;br&gt;数据存储和管理（ETL，抽取Extract，转换Transform，装载Load）&lt;br&gt;数据仓库引擎&lt;br&gt;前端展示（数据查询，数据报表，数据分析，各类应用）&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;什么是Hive？&quot;&gt;&lt;a href=&quot;#什么是Hive？&quot; class=&quot;headerlink&quot; title=&quot;什么是Hive？&quot;&gt;&lt;/a&gt;什么是Hive？&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;hive是建立在hadoop hdfs上的数据仓库基础架构,hive中的表和文件其实就是hdfs中的目录和文件&lt;/li&gt;
&lt;li&gt;hive可以用来进行数据提取转化加载（ETL）&lt;/li&gt;
&lt;li&gt;hive定义了简单的类似SQL查询语言（HQL），它允许熟悉SQL的用户查询数据&lt;/li&gt;
&lt;li&gt;hive允许熟悉MapReduce开发者开发自定义的mapper和reducer来处理內建的mapper和reducer无法完成的复杂的分析工作&lt;/li&gt;
&lt;li&gt;hive是SQL解析引擎，它将SQL语句转义成MapReduce Job然后在hadoop上执行&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;hive的元数据&quot;&gt;&lt;a href=&quot;#hive的元数据&quot; class=&quot;headerlink&quot; title=&quot;hive的元数据&quot;&gt;&lt;/a&gt;hive的元数据&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;hive将元数据存储在数据库中（metastore），支持mysql和derby（默认）等数据库&lt;br&gt;hive中的元数据包括表的名字，表的列和分区及其属性，表的属性（是否为外部表等），表的数据所在目录等&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;HQL的执行过程&quot;&gt;&lt;a href=&quot;#HQL的执行过程&quot; class=&quot;headerlink&quot; title=&quot;HQL的执行过程&quot;&gt;&lt;/a&gt;HQL的执行过程&lt;/h2&gt;&lt;p&gt;解释器，编译器，优化器完成HQL查询语句从此法分析，语法分析，编译，优化以及查询计划（plan）的生成。生成的查询计划存储在HDFS中，并在随后又MapReduce调用执行&lt;/p&gt;
&lt;p&gt;HQL执行过程如下：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;HQL select语句&lt;/li&gt;
&lt;li&gt;解释器进行此法分析&lt;/li&gt;
&lt;li&gt;编译器生成HQL的执行计划（类似javac命令，将java文件编译成class文件）&lt;/li&gt;
&lt;li&gt;优化器生成最佳的执行计划&lt;/li&gt;
&lt;li&gt;执行&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&quot;hive的三种安装模式&quot;&gt;&lt;a href=&quot;#hive的三种安装模式&quot; class=&quot;headerlink&quot; title=&quot;hive的三种安装模式&quot;&gt;&lt;/a&gt;hive的三种安装模式&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;&lt;p&gt;嵌入模式&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;元数据信息保存在hive自带的derby数据库中&lt;/li&gt;
&lt;li&gt;只允许创建一个连接&lt;/li&gt;
&lt;li&gt;多用于Demo&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;本地模式&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;元数据信息被存储在MySQL数据库中&lt;/li&gt;
&lt;li&gt;MySQL数据库与Hive运行在同一台物理机器上&lt;/li&gt;
&lt;li&gt;多用于开发和测试&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;远程模式&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;元数据信息被保存在远程的MySQL数据库中&lt;/li&gt;
&lt;li&gt;多用于实际的生产运行环境&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&quot;常用的CLI命令&quot;&gt;&lt;a href=&quot;#常用的CLI命令&quot; class=&quot;headerlink&quot; title=&quot;常用的CLI命令&quot;&gt;&lt;/a&gt;常用的CLI命令&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;进入CLI&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;交互模式&lt;br&gt;hive  # 进入命令行交互模式，非静默&lt;br&gt;hive -S # 静默模式，不显示调试信息&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;直接执行一条语句&lt;br&gt;hive -e ‘show tables’;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;执行一个文件的文件&lt;br&gt;hive -f ~/test.hql&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;清屏&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Ctrl + L或者 !clear;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;查看数据仓库中的表&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;show tables;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;查看数据仓库中内置的函数&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;show functions;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;查看表的结构&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;desc 表名&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;查看HDFS上的文件&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;dfs -ls 目录&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;执行操作系统的命令&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;!命令&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;执行HQL语句&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;select &lt;strong&gt;&lt;em&gt; from &lt;/em&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;执行SQL的脚本&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;source SQL文件&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;hive的数据类型&quot;&gt;&lt;a href=&quot;#hive的数据类型&quot; class=&quot;headerlink&quot; title=&quot;hive的数据类型&quot;&gt;&lt;/a&gt;hive的数据类型&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;基本数据类型&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;tinyint/smallint/int/bigint：整数类型&lt;/li&gt;
&lt;li&gt;float/double：浮点数类型&lt;/li&gt;
&lt;li&gt;boolean：布尔类型&lt;/li&gt;
&lt;li&gt;string：字符串类型&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;复杂数据类型&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Array：数组类型，由一系列相同数据类型的元素组成&lt;/li&gt;
&lt;li&gt;Map：集合类型，包含key-&amp;gt;value，可以通过key来访问元素&lt;/li&gt;
&lt;li&gt;Struct：结构类型，可以包含不同数据类型的元素，这些元素可以通过“点语法”的方式来得到所需要的元素&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;时间类型&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Date：从Hive0.12.0开始支持&lt;/li&gt;
&lt;li&gt;Timestamp：从Hive0.8.0开始支持&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;figure class=&quot;highlight sql&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;TABLE&lt;/span&gt; employees(&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;name&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;STRING&lt;/span&gt;,&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;salary &lt;span class=&quot;built_in&quot;&gt;FLOAT&lt;/span&gt;,&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;subordintes &lt;span class=&quot;built_in&quot;&gt;ARRAY&lt;/span&gt;&amp;lt;&lt;span class=&quot;keyword&quot;&gt;STRING&lt;/span&gt;&amp;gt;,&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;deucations &lt;span class=&quot;keyword&quot;&gt;MAP&lt;/span&gt;&amp;lt;&lt;span class=&quot;keyword&quot;&gt;STRING&lt;/span&gt;, &lt;span class=&quot;built_in&quot;&gt;FLOAT&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;address &lt;span class=&quot;keyword&quot;&gt;STRUCT&lt;/span&gt;&amp;lt;street:&lt;span class=&quot;keyword&quot;&gt;STRING&lt;/span&gt;, city:&lt;span class=&quot;keyword&quot;&gt;STRING&lt;/span&gt;, state:&lt;span class=&quot;keyword&quot;&gt;STRING&lt;/span&gt;, zip:&lt;span class=&quot;built_in&quot;&gt;INT&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;Hive中的数据都是保存在HDFS中&lt;br&gt;没有专门的数据存储格式&lt;br&gt;存储结构主要包括：数据库，文件，表，视图&lt;br&gt;Hive可以直接加载文本文件&lt;br&gt;创建表的时候，指定Hive数据的列分隔符与行分隔符&lt;/p&gt;
&lt;h6 id=&quot;数据库database&quot;&gt;&lt;a href=&quot;#数据库database&quot; class=&quot;headerlink&quot; title=&quot;数据库database&quot;&gt;&lt;/a&gt;数据库database&lt;/h6&gt;&lt;ul&gt;
&lt;li&gt;相当于关系数据库中的命名空间（namespace），它的作用是将用户和数据库的应用隔离到不同的数据库或模式中&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;表&quot;&gt;&lt;a href=&quot;#表&quot; class=&quot;headerlink&quot; title=&quot;表&quot;&gt;&lt;/a&gt;表&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Table内部表&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;与数据库中的Table在概念上是类似的&lt;/li&gt;
&lt;li&gt;每一个Table在Hive中都有一个相应的目录存储数据&lt;/li&gt;
&lt;li&gt;所有的Table数据（不包括External Table）都保存在这个目录中&lt;/li&gt;
&lt;li&gt;删除表的时候，元数据与数据都会被删除&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Partition分区表&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Partition对应于数据库的Partition列的密集索引&lt;/li&gt;
&lt;li&gt;在Hive中，表中的一个Partition对应于表下的一个目录，多有的Partition的数据都存储在对应的目录中&lt;/li&gt;
&lt;li&gt;在数据量特别大的时候，需要将数据按照一定的条件进行分区，这样在进行查询操作的时候能够降低扫描的数据，从而提高查询的效率（通过执行计划知道）&lt;/li&gt;
&lt;li&gt;Hive把表组织成”分区“，这是一种根据“分区列”（如日期）的值对表的数据进行粗略划分的机制。使用分区可以加快数据分片（slice）的查询速度&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;External Table 外部表&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;指向已经存在于HDFS中的数据，也可以创建Patition&lt;/li&gt;
&lt;li&gt;它和内部表在元数据的组织上是相同的，而实际数据的存储则有较大的差异&lt;/li&gt;
&lt;li&gt;外部表只有一个过程，加载数据和创建表同时完成，并不会移动到数据仓库目录中，只是与外部数据建立一个链接。当删除一个外部表是，仅删除该链接&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Bucket Table 桶表&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;桶表是对数据进行哈希取值，然后放到不同文件中存储&lt;/li&gt;
&lt;li&gt;降低系统的热块，从而提高查询的速度&lt;/li&gt;
&lt;li&gt;表和分区可以进一步分为“桶”，它会为数据提供额外的结构以获得更高效的查询处理。例如，可以根据用户ID来划分桶，这则是对数据源数据文件本身来拆分数据。使用桶的表会将源数据文件按一定规律拆分成多个文件，要使用bucket&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;视图&quot;&gt;&lt;a href=&quot;#视图&quot; class=&quot;headerlink&quot; title=&quot;视图&quot;&gt;&lt;/a&gt;视图&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;视图是一种虚表，是一个逻辑概念，不存数据；可以跨越多张表&lt;/li&gt;
&lt;li&gt;视图建立在已有表的基础上，视图赖以建立的这些表成为基表&lt;/li&gt;
&lt;li&gt;视图可以简化复杂的查询&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;内部表和外部表的区别？&quot;&gt;&lt;a href=&quot;#内部表和外部表的区别？&quot; class=&quot;headerlink&quot; title=&quot;内部表和外部表的区别？&quot;&gt;&lt;/a&gt;内部表和外部表的区别？&lt;/h2&gt;&lt;p&gt;内部表也叫做管理表，Hive会控制着数据的生命周期，默认情况下会将这些表的数据存储在由配置项&lt;code&gt;hive.metastore.warehourse.dir&lt;/code&gt;所定义的目录的子目录下&lt;br&gt;当删除一个内部表的时候，Hive也会删除这个表中的数据&lt;/p&gt;
&lt;p&gt;外部表&lt;br&gt;先看一个例子：&lt;/p&gt;
&lt;figure class=&quot;highlight sql&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;18&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;create&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;external&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;table&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;exists&lt;/span&gt; pimaccess(&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    accesstime &lt;span class=&quot;built_in&quot;&gt;BIGINT&lt;/span&gt;,&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;keyword&quot;&gt;account&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;STRING&lt;/span&gt;,&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    ip &lt;span class=&quot;keyword&quot;&gt;STRING&lt;/span&gt;,&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    appkey &lt;span class=&quot;keyword&quot;&gt;STRING&lt;/span&gt;,&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    prelinkmannum &lt;span class=&quot;built_in&quot;&gt;INT&lt;/span&gt;,&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    aftlinkmannum &lt;span class=&quot;built_in&quot;&gt;INT&lt;/span&gt;,&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    pregroupnum &lt;span class=&quot;built_in&quot;&gt;INT&lt;/span&gt;,&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    aftgroupnum &lt;span class=&quot;built_in&quot;&gt;INT&lt;/span&gt;,&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    resultcode &lt;span class=&quot;built_in&quot;&gt;INT&lt;/span&gt;,&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    costtime &lt;span class=&quot;built_in&quot;&gt;INT&lt;/span&gt;,&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    requesttype &lt;span class=&quot;built_in&quot;&gt;INT&lt;/span&gt;,&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    responsetype &lt;span class=&quot;built_in&quot;&gt;INT&lt;/span&gt;,&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    apiname &lt;span class=&quot;keyword&quot;&gt;STRING&lt;/span&gt;,&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    requestdata &lt;span class=&quot;keyword&quot;&gt;STRING&lt;/span&gt;,&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    responsedata &lt;span class=&quot;keyword&quot;&gt;STRING&lt;/span&gt;,&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    rtime &lt;span class=&quot;keyword&quot;&gt;STRING&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;)&lt;span class=&quot;keyword&quot;&gt;ROW&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;FORMAT&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;DELIMITED&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;FIELDS&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;TERMINATED&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;&#39;\t&#39;&lt;/span&gt; LOCATION &lt;span class=&quot;string&quot;&gt;&#39;/pimaccess&#39;&lt;/span&gt;;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;在创建表的时候使用&lt;code&gt;EXTENAL&lt;/code&gt;关键字，用来告诉Hive这个表是外部表，&lt;code&gt;LOCATION&lt;/code&gt;子句则用于告诉Hive数据位于哪个路径下。&lt;br&gt;对于外部表，Hive认为没有完全拥有这份数据，因此在删除该表的时候不会删除掉这份数据，不过描述表的元数据信息会被删除。&lt;/p&gt;
&lt;h2 id=&quot;Hive常见的数据导入方式&quot;&gt;&lt;a href=&quot;#Hive常见的数据导入方式&quot; class=&quot;headerlink&quot; title=&quot;Hive常见的数据导入方式&quot;&gt;&lt;/a&gt;Hive常见的数据导入方式&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;从本地文件系统中导入&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;load data local inpath ‘test.txt’ into table test;&lt;/li&gt;
&lt;li&gt;load data local inpath ‘test.txt’ overwrite into table test;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;从HDFS上导入&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;load data inpath ‘/test.txt’ into table test;&lt;/li&gt;
&lt;li&gt;load data inpath ‘/test.txt’ overwrite into table test;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;从别的表中查询出相应数据并导入 &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;insert into table test partition(age=’25’) select id, name, tel from test;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;在创建表的时候通过从别的表中查询出相应的记录并插入到所创建的表中&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;create table test2 as select id, name, tel from test;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;Hive是建立在 Hadoop 上的数据仓库基础构架。它提供了一系列的工具，可以用来进行数据提取转化加载（ETL），这是一种可以存储、查询和分析存储在 Hadoop 中的大规模数据的机制。&lt;br&gt;
    
    </summary>
    
    
      <category term="bigdata" scheme="http://dxer.github.io/tags/bigdata/"/>
    
      <category term="hive" scheme="http://dxer.github.io/tags/hive/"/>
    
  </entry>
  
  <entry>
    <title>zookeeper伪集群模式安装和配置</title>
    <link href="http://dxer.github.io/2016/03/07/zookeeper01/"/>
    <id>http://dxer.github.io/2016/03/07/zookeeper01/</id>
    <published>2016-03-07T02:25:38.000Z</published>
    <updated>2016-04-28T10:39:34.349Z</updated>
    
    <content type="html">&lt;p&gt;伪分布式集群：在一台Server中，启动多个ZooKeeper的实例。&lt;br&gt;下面来看看zookeeper怎么进行安装的吧。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;下载&quot;&gt;&lt;a href=&quot;#下载&quot; class=&quot;headerlink&quot; title=&quot;下载&quot;&gt;&lt;/a&gt;下载&lt;/h2&gt;&lt;p&gt;选择一个稳定版本进行下载，我这里下载的是zookeeper-3.4.6版本。&lt;/p&gt;
&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;wget http://mirror.bit.edu.cn/apache/zookeeper/zookeeper-3.4.6/zookeeper-3.4.6.tar.gz&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h2 id=&quot;解压&quot;&gt;&lt;a href=&quot;#解压&quot; class=&quot;headerlink&quot; title=&quot;解压&quot;&gt;&lt;/a&gt;解压&lt;/h2&gt;&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;tar -zxvf  zookeeper-3.4.6.tar.gz&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# 3个实例，复制三份 zk1，zk2，zk3&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;cp -r zookeeper-3.4.6 zk1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;cp -r zookeeper-3.4.6 zk2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;cp -r zookeeper-3.4.6 zk3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h2 id=&quot;创建实例配置文件&quot;&gt;&lt;a href=&quot;#创建实例配置文件&quot; class=&quot;headerlink&quot; title=&quot;创建实例配置文件&quot;&gt;&lt;/a&gt;创建实例配置文件&lt;/h2&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;cd zookeeper-3.4.6/conf&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;cp zoo_sample.cfg zoo1.cfg&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;cp zoo_sample.cfg zoo2.cfg&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;cp zoo_sample.cfg zoo3.cfg&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h2 id=&quot;修改配置&quot;&gt;&lt;a href=&quot;#修改配置&quot; class=&quot;headerlink&quot; title=&quot;修改配置&quot;&gt;&lt;/a&gt;修改配置&lt;/h2&gt;&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;tickTime=2000  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;dataDir=/opt/zk1/data  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;clientPort=2181  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;initLimit=10  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;syncLimit=5  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;server.1=127.0.0.1:2881:3881  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;server.2=127.0.0.1:2882:3882  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;server.3=127.0.0.1:2883:3883&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;ol&gt;
&lt;li&gt;分别配置三个实例的clientPort端口为2181, 2182, 2183&lt;/li&gt;
&lt;li&gt;分别配置是哪个实例的dataDir目录为&lt;code&gt;/opt/zk1/data&lt;/code&gt;，&lt;code&gt;/opt/zk2/data&lt;/code&gt;，&lt;code&gt;/opt/zk3/data&lt;/code&gt;，并创建这三个目录,没有创建该目录会启动出错&lt;/li&gt;
&lt;li&gt;定义zookeeper集群的各个实例的ip和端口，server.1=127.0.0.1:2881:3881 ,server.2=127.0.0.1:2882:3882,server.3=127.0.0.1:2883:3883 &lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;解释：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;dataDir&lt;br&gt;定义zookeeper实例存储持久出具的本地文件系统位置&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;clientPort&lt;br&gt;定义zookeeper客户端连接zookeeper服务端时使用的端口&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;server&lt;br&gt;定义zookeeper集群的各个实例的ip和端口&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;tickTime&lt;br&gt;指定了zookeeper中的基本时间单元（以毫秒为单位）&lt;br&gt;zookeeper集群中，每个服务器都有一个id（数字），服务器id在集群中是唯一的，并且取值范围是1~255，通过一个名为myid的纯文本设置，这个文件保存在dataDir中&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;server.n=hostname:port:port&lt;br&gt;n是服务器id，第一个port是follower用来连接leader的端口，第二个port是用于leader选举&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;clientPort&lt;br&gt;监听client连接的端口号&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;initLimit&lt;br&gt;设定了所有follower与leader进行连接并同步的时间范围。如果在设定的时间段内，半数以上的follower跟随者未能完成同步，leader会宣布放弃领导地位，然后进行另外一次leader选举，如果这种情况经常发生，则表明设定的值太小&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;syncLimit&lt;br&gt;设定了允许一个follower与leader这进行同步的时间。如果在设定的时间段内，一个follower未能完成同步，会自己重启，所有关联到follower的客户端将连接到另一个follower&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;h6 id=&quot;创建dataDir和实例id文件&quot;&gt;&lt;a href=&quot;#创建dataDir和实例id文件&quot; class=&quot;headerlink&quot; title=&quot;创建dataDir和实例id文件&quot;&gt;&lt;/a&gt;创建dataDir和实例id文件&lt;/h6&gt;&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;mkdir -p /opt/zk1/data  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;mkdir -p /opt/zk2/data  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;mkdir -p /opt/zk3/data  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;built_in&quot;&gt;echo&lt;/span&gt; 1 &amp;gt; /opt/zk1/data/myid  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;built_in&quot;&gt;echo&lt;/span&gt; 2 &amp;gt; /opt/zk2/data/myid  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;built_in&quot;&gt;echo&lt;/span&gt; 3 &amp;gt; /opt/zk3/data/myid&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h2 id=&quot;启动zookeeper服务&quot;&gt;&lt;a href=&quot;#启动zookeeper服务&quot; class=&quot;headerlink&quot; title=&quot;启动zookeeper服务&quot;&gt;&lt;/a&gt;启动zookeeper服务&lt;/h2&gt;&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;bin/zkServer.sh start zoo1.cfg&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;bin/zkServer.sh start zoo2.cfg&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;bin/zkServer.sh start zoo3.cfg&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h2 id=&quot;查看是否启动成功&quot;&gt;&lt;a href=&quot;#查看是否启动成功&quot; class=&quot;headerlink&quot; title=&quot;查看是否启动成功&quot;&gt;&lt;/a&gt;查看是否启动成功&lt;/h2&gt;&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;jps&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;blockquote&gt;
&lt;p&gt;看到类似下面的进程就表示3个实例均启动成功&lt;br&gt;13419 QuorumPeerMain&lt;br&gt;13460 QuorumPeerMain&lt;br&gt;13561 Jps&lt;br&gt;13392 QuorumPeerMain&lt;br&gt;如果未成功启动，可以到zookeeper.out文件中查看启动失败的日志信息。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;客户端连接&quot;&gt;&lt;a href=&quot;#客户端连接&quot; class=&quot;headerlink&quot; title=&quot;客户端连接&quot;&gt;&lt;/a&gt;客户端连接&lt;/h2&gt;&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;./zkCli.sh -server 127.0.0.1:2181&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h2 id=&quot;关闭zookeeper&quot;&gt;&lt;a href=&quot;#关闭zookeeper&quot; class=&quot;headerlink&quot; title=&quot;关闭zookeeper&quot;&gt;&lt;/a&gt;关闭zookeeper&lt;/h2&gt;&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;bin/zkServer.sh stop&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h2 id=&quot;重启zookeeper&quot;&gt;&lt;a href=&quot;#重启zookeeper&quot; class=&quot;headerlink&quot; title=&quot;重启zookeeper&quot;&gt;&lt;/a&gt;重启zookeeper&lt;/h2&gt;&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;bin/zkServer.sh restart&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;伪分布式集群：在一台Server中，启动多个ZooKeeper的实例。&lt;br&gt;下面来看看zookeeper怎么进行安装的吧。&lt;br&gt;
    
    </summary>
    
    
      <category term="zookeeper" scheme="http://dxer.github.io/tags/zookeeper/"/>
    
  </entry>
  
  <entry>
    <title>Neo4j - Cypher</title>
    <link href="http://dxer.github.io/2015/12/02/neo4j-cypher/"/>
    <id>http://dxer.github.io/2015/12/02/neo4j-cypher/</id>
    <published>2015-12-02T04:17:19.000Z</published>
    <updated>2016-05-13T01:13:39.707Z</updated>
    
    <content type="html">&lt;p&gt;Neo4j是一种图数据库。它将结构化数据存储在图上而不是传统的数据库表中。 相对于关系数据库来说，图数据库善于处理大量复杂、互连接、低结构化的数据，这些数据变化迅速，需要频繁的查询。在关系数据库中， 这些查询会导致大量的表连接，因此会产生性能上的问题,但是使用Neo4j就可以解决查询时出现的性能衰退问题。 同时Neo4j还提供了非常快的图算法、推荐系统和OLAP风格的分析。下面主要简单记录一下Cypher查询语言的使用方法。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;这个查询语言包含以下几个明显的部分：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;START：在图中的开始点，通过元素的ID或所以查找获得。&lt;/li&gt;
&lt;li&gt;MATCH：图形的匹配模式，束缚于开始点。&lt;/li&gt;
&lt;li&gt;WHERE：过滤条件。&lt;/li&gt;
&lt;li&gt;RETURN：返回所需要的。&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Operators&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Mathematical&lt;/td&gt;
&lt;td&gt;+, -, *, /, %, ^&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Comparison&lt;/td&gt;
&lt;td&gt;=, &amp;lt;&amp;gt;, &amp;lt;, &amp;gt;, &amp;lt;=, &amp;gt;=&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Boolean&lt;/td&gt;
&lt;td&gt;AND, OR, XOR, NOT&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;String&lt;/td&gt;
&lt;td&gt;+&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Collection&lt;/td&gt;
&lt;td&gt;+, IN, [x], [x .. y]&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Regular Expression&lt;/td&gt;
&lt;td&gt;=~&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;String matching&lt;/td&gt;
&lt;td&gt;STARTS WITH, ENDS WITH, CONTAINS&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h4 id=&quot;Create&quot;&gt;&lt;a href=&quot;#Create&quot; class=&quot;headerlink&quot; title=&quot;Create&quot;&gt;&lt;/a&gt;Create&lt;/h4&gt;&lt;ol&gt;
&lt;li&gt;&lt;p&gt;创建节点&lt;/p&gt;
&lt;figure class=&quot;highlight sql&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;17&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;-- 创建单节点&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;CREATE&lt;/span&gt; (n)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;-- 创建多节点&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;CREATE&lt;/span&gt; (n),(m)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt; &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;-- 创建一个节点并含有一个label&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;CREATE&lt;/span&gt; (n:Person) &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;-- 创建一个节点并含有多个label&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;CREATE&lt;/span&gt; (n:Person:Swedish) &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;-- 创建一个节点并含有label和properties&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;CREATE&lt;/span&gt; (n:Person &amp;#123; &lt;span class=&quot;keyword&quot;&gt;name&lt;/span&gt; : &lt;span class=&quot;string&quot;&gt;&#39;Andres&#39;&lt;/span&gt;, title : &lt;span class=&quot;string&quot;&gt;&#39;Developer&#39;&lt;/span&gt; &amp;#125;) &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;-- 创建一个节点并返回该节点&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;CREATE&lt;/span&gt; (a &amp;#123; &lt;span class=&quot;keyword&quot;&gt;name&lt;/span&gt; : &lt;span class=&quot;string&quot;&gt;&#39;Andres&#39;&lt;/span&gt; &amp;#125;) &lt;span class=&quot;keyword&quot;&gt;RETURN&lt;/span&gt; a&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;创建关系&lt;/p&gt;
&lt;figure class=&quot;highlight sql&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;MATCH (a:Person),(b:Person)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;WHERE a.name = &#39;Node A&#39; AND b.name = &#39;Node B&#39;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;CREATE&lt;/span&gt; (a)-[r:RELTYPE]-&amp;gt;(b)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;RETURN&lt;/span&gt; r&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;创建关系并设置属性&lt;/p&gt;
&lt;figure class=&quot;highlight sql&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;MATCH (a:Person),(b:Person)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;WHERE a.name = &#39;Node A&#39; AND b.name = &#39;Node B&#39;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;CREATE&lt;/span&gt; (a)-[r:RELTYPE &amp;#123; &lt;span class=&quot;keyword&quot;&gt;name&lt;/span&gt; : a.name + &lt;span class=&quot;string&quot;&gt;&#39;&amp;lt;-&amp;gt;&#39;&lt;/span&gt; + b.name &amp;#125;]-&amp;gt;(b)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;RETURN&lt;/span&gt; r&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&quot;Merge&quot;&gt;&lt;a href=&quot;#Merge&quot; class=&quot;headerlink&quot; title=&quot;Merge&quot;&gt;&lt;/a&gt;Merge&lt;/h4&gt;&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Use ON CREATE and ON MATCH&lt;/p&gt;
&lt;figure class=&quot;highlight sql&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;MERGE&lt;/span&gt; (keanu:Person &amp;#123; &lt;span class=&quot;keyword&quot;&gt;name&lt;/span&gt;:&lt;span class=&quot;string&quot;&gt;&#39;Keanu Reeves&#39;&lt;/span&gt; &amp;#125;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;ON&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;SET&lt;/span&gt; keanu.created = &lt;span class=&quot;keyword&quot;&gt;timestamp&lt;/span&gt;()&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;RETURN&lt;/span&gt; keanu.name, keanu.created&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Merge with ON CREATE and ON MATCH&lt;/p&gt;
&lt;figure class=&quot;highlight sql&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;MERGE&lt;/span&gt; (keanu:Person &amp;#123; &lt;span class=&quot;keyword&quot;&gt;name&lt;/span&gt;:&lt;span class=&quot;string&quot;&gt;&#39;Keanu Reeves&#39;&lt;/span&gt; &amp;#125;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;ON&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;SET&lt;/span&gt; keanu.created = &lt;span class=&quot;keyword&quot;&gt;timestamp&lt;/span&gt;()&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;ON&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;MATCH&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;SET&lt;/span&gt; keanu.lastSeen = &lt;span class=&quot;keyword&quot;&gt;timestamp&lt;/span&gt;()&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;RETURN&lt;/span&gt; keanu.name, keanu.created, keanu.lastSeen&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Merge relationships&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;MATCH (charlie:Person &amp;#123; name:&#39;Charlie Sheen&#39; &amp;#125;),(wallStreet:Movie &amp;#123; title:&#39;Wall Street&#39; &amp;#125;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;MERGE (charlie)-[r:ACTED_IN]-&amp;gt;(wallStreet)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;RETURN charlie.name, type(r), wallStreet.title&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;MATCH (oliver:Person &amp;#123; name:&#39;Oliver Stone&#39; &amp;#125;),(reiner:Person &amp;#123; name:&#39;Rob Reiner&#39; &amp;#125;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;MERGE (oliver)-[:DIRECTED]-&amp;gt;(movie:Movie)&amp;lt;-[:ACTED_IN]-(reiner)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;RETURN movie&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h3 id=&quot;查询&quot;&gt;&lt;a href=&quot;#查询&quot; class=&quot;headerlink&quot; title=&quot;查询&quot;&gt;&lt;/a&gt;查询&lt;/h3&gt;&lt;p&gt;语法&lt;br&gt;&lt;figure class=&quot;highlight sql&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;[MATCH WHERE] &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;[OPTIONAL MATCH WHERE] &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;[WITH [ORDER BY] [SKIP] [LIMIT]] &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;RETURN [ORDER BY] [SKIP] [LIMIT]&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;示例&lt;br&gt;&lt;figure class=&quot;highlight&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;MATCH (n:Person)-[:KNOWS]-&amp;gt;(m:Person)WHERE n.name=&quot;Alice&quot;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Node patterns can contain labels and properties.&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;MATCH (n)--&amp;gt;(m)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Any pattern can be used in MATCH.&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;MATCH (n &amp;#123;name:&#39;Alice&#39;&amp;#125;)--&amp;gt;(m)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Patterns with node properties.&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;MATCH p = (n)--&amp;gt;(m)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Assign a path to p.&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;OPTIONAL MATCH (n)-[r]-&amp;gt;(m)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Optional pattern, NULLs will be used for missing parts&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h3 id=&quot;唯一约束&quot;&gt;&lt;a href=&quot;#唯一约束&quot; class=&quot;headerlink&quot; title=&quot;唯一约束&quot;&gt;&lt;/a&gt;唯一约束&lt;/h3&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;CREATE CONSTRAINT ON (p:Person) ASSERT p.name IS UNIQUE&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;DROP CONSTRAINT ON (p:Person) ASSERT p.name IS UNIQUE&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h3 id=&quot;索引&quot;&gt;&lt;a href=&quot;#索引&quot; class=&quot;headerlink&quot; title=&quot;索引&quot;&gt;&lt;/a&gt;索引&lt;/h3&gt;&lt;figure class=&quot;highlight sql&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1. 创建索引&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;INDEX&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;ON&lt;/span&gt; :Person(&lt;span class=&quot;keyword&quot;&gt;name&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;number&quot;&gt;2.&lt;/span&gt; 删除索引&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;DROP&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;INDEX&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;ON&lt;/span&gt; :Person(&lt;span class=&quot;keyword&quot;&gt;name&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h2 id=&quot;参考&quot;&gt;&lt;a href=&quot;#参考&quot; class=&quot;headerlink&quot; title=&quot;参考:&quot;&gt;&lt;/a&gt;参考:&lt;/h2&gt;&lt;p&gt;&lt;a href=&quot;http://neo4j.com/docs/stable/cypher-query-lang.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;neo4j官网Cypher文档&lt;/a&gt;&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;Neo4j是一种图数据库。它将结构化数据存储在图上而不是传统的数据库表中。 相对于关系数据库来说，图数据库善于处理大量复杂、互连接、低结构化的数据，这些数据变化迅速，需要频繁的查询。在关系数据库中， 这些查询会导致大量的表连接，因此会产生性能上的问题,但是使用Neo4j就可以解决查询时出现的性能衰退问题。 同时Neo4j还提供了非常快的图算法、推荐系统和OLAP风格的分析。下面主要简单记录一下Cypher查询语言的使用方法。&lt;br&gt;
    
    </summary>
    
    
      <category term="Neo4j" scheme="http://dxer.github.io/tags/Neo4j/"/>
    
      <category term="Cypher" scheme="http://dxer.github.io/tags/Cypher/"/>
    
  </entry>
  
  <entry>
    <title>Neo4j</title>
    <link href="http://dxer.github.io/2015/12/02/neo4j-01/"/>
    <id>http://dxer.github.io/2015/12/02/neo4j-01/</id>
    <published>2015-12-02T01:13:19.000Z</published>
    <updated>2016-04-29T07:35:08.003Z</updated>
    
    <content type="html">&lt;p&gt;最近在用图形数据库来完成对项目的支持。在使用过程中觉得这种图形数据库实际上挺有意思的。因此在这里给大家做一个简单的介绍。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;图数据库&quot;&gt;&lt;a href=&quot;#图数据库&quot; class=&quot;headerlink&quot; title=&quot;图数据库&quot;&gt;&lt;/a&gt;图数据库&lt;/h2&gt;&lt;p&gt;图形数据库是一种非关系型数据库，它应用图形理论存储实体之间的关系信息。最常见的一个例子，就是社会网络中人与人之间的关系。关系型数据库用于存储“关系型”数据的效果并不好，其查询复杂、缓慢、超出预期，而图形数据库的独特设计恰恰弥补了这个缺陷。&lt;/p&gt;
&lt;h2 id=&quot;Neo4j&quot;&gt;&lt;a href=&quot;#Neo4j&quot; class=&quot;headerlink&quot; title=&quot;Neo4j&quot;&gt;&lt;/a&gt;Neo4j&lt;/h2&gt;&lt;p&gt;Neo4j是一个流行的图形数据库，它是开源的。Neo4j基于Java实现，兼容ACID特性，也支持其他编程语言，如Ruby和Python。&lt;/p&gt;
&lt;p&gt;Neo4j是一个高性能的,NOSQL图形数据库，它将结构化数据存储在网络上而不是表中。Neo4j 使用图（graph）相关的概念来描述数据模型，把数据保存为图中的节点以及节点之间的关系。很多应用中数据之间的关系，可以很直接地使用图中节点和关系的概念来建模。对于这样的应用，使用 Neo4j 来存储数据会非常的自然，要优于使用关系数据库。&lt;/p&gt;
&lt;p&gt;Neo4j 使用数据结构中图（graph）的概念来进行建模。Neo4j 中两个最基本的概念是节点和边。节点表示实体，边则表示实体之间的关系。节点和边都可以有自己的属性。不同实体通过各种不同的关系关联起来，形成复杂的对象图。Neo4j 同时提供了在对象图上进行查找和遍历的功能。&lt;/p&gt;
&lt;h3 id=&quot;Neo4j特点&quot;&gt;&lt;a href=&quot;#Neo4j特点&quot; class=&quot;headerlink&quot; title=&quot;Neo4j特点&quot;&gt;&lt;/a&gt;Neo4j特点&lt;/h3&gt;&lt;p&gt;作为一款强健的，可伸缩的高性能数据库，Neo4j最适合完整的企业部署或者用于一个轻量级项目中完整服务器的一个子集存在。&lt;/p&gt;
&lt;p&gt;它包括如下几个显著特点:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;完整的ACID支持&lt;/li&gt;
&lt;li&gt;高可用性&lt;/li&gt;
&lt;li&gt;轻易扩展到上亿级别的节点和关系&lt;/li&gt;
&lt;li&gt;通过遍历工具高速检索数据&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;适当的ACID操作是保证数据一致性的基础。Neo4j确保了在一个事务里面的多个操作同时发生，保证数据一致性。不管是采用嵌入模式还是多服务器集群部署，都支持这一特性。&lt;/p&gt;
&lt;p&gt;可靠的图型存储可以非常轻松的集成到任何一个应用中。随着我们开发的应用在运营中不断发展，性能问题肯定会逐步凸显出来，而Neo4j不管应用如何变化，他只会受到计算机硬件性能的影响，不受业务本身的约束。&lt;/p&gt;
&lt;p&gt;部署一个neo4j服务器便可以承载上亿级的节点和关系。当然，当单节点无法承载我们的数据需求时，我们可以进行分布式集群部署（含有集群方案的版本是商业版）。&lt;/p&gt;
&lt;p&gt;将图数据库用于存储关系复杂的数据是他最大的优势。通过Neo4j提供的遍历工具，可以非常高效的进行数据检索，每秒可以达到上亿级的检索量。一个检索操作类似于RDBMS里面的连接（&lt;em&gt;join&lt;/em&gt;）操作。&lt;/p&gt;
&lt;h3 id=&quot;Cypher查询语言&quot;&gt;&lt;a href=&quot;#Cypher查询语言&quot; class=&quot;headerlink&quot; title=&quot;Cypher查询语言&quot;&gt;&lt;/a&gt;Cypher查询语言&lt;/h3&gt;&lt;p&gt;&lt;em&gt;Cypher&lt;/em&gt;查询语言，是一种不需要手动遍历图结构数据，就可高效完成查询功能的陈述性查询语言。Cypher用于在图数据库中存储和检索数据，可以实现对Neo4j数据库的添加、删除及更新操作。Cypher受启于陈述性查询语言，很多关键字如WHERE、ORDER BY等来源于SQL；模式匹配方法来源于SPARQL。Cypher语言更专注于检索内容的图结构形式化描述，而不是实现。&lt;/p&gt;
&lt;p&gt;在查询语言中包含以下几个明显的部分：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;START：在图中的开始点，通过元素的ID或所以查找获得。&lt;/li&gt;
&lt;li&gt;MATCH：图形的匹配模式，束缚于开始点。&lt;/li&gt;
&lt;li&gt;WHERE：过滤条件。&lt;/li&gt;
&lt;li&gt;RETURN：返回所需要的。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;使用Neo4j图数据库的优势&quot;&gt;&lt;a href=&quot;#使用Neo4j图数据库的优势&quot; class=&quot;headerlink&quot; title=&quot;使用Neo4j图数据库的优势&quot;&gt;&lt;/a&gt;使用Neo4j图数据库的优势&lt;/h3&gt;&lt;p&gt;使用Neo4j图数据库的优势如下：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;自带一套易于学习的Cypher查询语言，减少在开发过程中的学习成本；&lt;/li&gt;
&lt;li&gt;与关系型数据库相比，对于高度关联的数据（图形数据）的查询快速要快上许多；&lt;/li&gt;
&lt;li&gt;它的实体与关系结构非常自然地切合人类的直观感受；&lt;/li&gt;
&lt;li&gt;支持兼容ACID的事务操作；&lt;/li&gt;
&lt;li&gt;提供了一个高可用性模型，以支持大规模数据量的查询，支持备份、数据局部性以及冗余；&lt;/li&gt;
&lt;li&gt;提供了一个可视化的查询控制台，方便在控制台进行查询操作。&lt;/li&gt;
&lt;/ol&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;最近在用图形数据库来完成对项目的支持。在使用过程中觉得这种图形数据库实际上挺有意思的。因此在这里给大家做一个简单的介绍。&lt;br&gt;
    
    </summary>
    
    
      <category term="Neo4j" scheme="http://dxer.github.io/tags/Neo4j/"/>
    
      <category term="NoSQL" scheme="http://dxer.github.io/tags/NoSQL/"/>
    
  </entry>
  
  <entry>
    <title>【Hadoop学习】Hadoop配额实战</title>
    <link href="http://dxer.github.io/2015/11/23/hadoop_quota/"/>
    <id>http://dxer.github.io/2015/11/23/hadoop_quota/</id>
    <published>2015-11-23T06:46:19.000Z</published>
    <updated>2016-06-12T09:24:01.634Z</updated>
    
    <content type="html">&lt;p&gt;在HDFS中，管理员可以为每一个目录设置基于名称或者空间上的配额。可以设置名称配额和空间配额，名称配额和空间配额可以单独设置。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&quot;名称配额（Name-Quota）&quot;&gt;&lt;a href=&quot;#名称配额（Name-Quota）&quot; class=&quot;headerlink&quot; title=&quot;名称配额（Name Quota）&quot;&gt;&lt;/a&gt;名称配额（Name Quota）&lt;/h3&gt;&lt;p&gt;名称配额是在对应的目录下所有文件和目录名称的数量上的限制。当超过这个配额的时候，文件或目录就会创建失败，重命名后名称配额仍然有效。如果重命名操作违反配额的限制，那么重命名会失败，新建的目录不会有任何配额设置，名字配额的上限是Long.Max_Value，如果配额为1，那么这个目录会强制为空，因为目录自身也会占用1个配额。配额的设置是持久化在fsimage中，如果fsimage发现违反了配额限制，会输出警告。&lt;/p&gt;
&lt;p&gt;只有管理员可以设置名称配额和空间配额。下面的命令设置/清理名称配额：&lt;/p&gt;
&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# 设置目录的名称配额&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;hdfs dfsadmin -setQuota N &amp;lt;DirName&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# 清除目录的名称配额&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;hdfs dfsadmin -clrQuota &amp;lt;DirName&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# 查询目录的配额和当前可用余额&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;hdfs dfs -count -q &amp;lt;DirName&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h3 id=&quot;空间配额（Space-Quota）&quot;&gt;&lt;a href=&quot;#空间配额（Space-Quota）&quot; class=&quot;headerlink&quot; title=&quot;空间配额（Space Quota）&quot;&gt;&lt;/a&gt;空间配额（Space Quota）&lt;/h3&gt;&lt;p&gt;空间配额是目录的空间大小限制。如果超过这个配额，块写入操作会失败。副本也算配额中的一部分。空间配额为0的时候，可以创建文件，但是不能向文件中写入内容。创建空间配额的命令如下:&lt;/p&gt;
&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# 设置目录的空间配额&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;hdfs dfsadmin -setSpaceQuota &amp;lt;quota&amp;gt; &amp;lt;dirname&amp;gt;...&amp;lt;dirname&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# 清除目录的空间配额&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;hdfs dfsadmin -clrSpaceQuota &amp;lt;dirname&amp;gt;...&amp;lt;dirname&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# 查询目录的配额和当前可用余额&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;hdfs dfs -count -q &amp;lt;DirName&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;其中可以通过&lt;br&gt;&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;fs -count -q directory ... directory&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;使用-q选项，可以显示目录的名称配额，剩余名称配额，空间配额，可用空间配额。如果目录没有设置配额，会显示为none和inf。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;在HDFS中，管理员可以为每一个目录设置基于名称或者空间上的配额。可以设置名称配额和空间配额，名称配额和空间配额可以单独设置。&lt;br&gt;
    
    </summary>
    
    
      <category term="hadoop" scheme="http://dxer.github.io/tags/hadoop/"/>
    
  </entry>
  
  <entry>
    <title>【Hadoop学习】YARN学习</title>
    <link href="http://dxer.github.io/2015/11/03/yarn/"/>
    <id>http://dxer.github.io/2015/11/03/yarn/</id>
    <published>2015-11-03T06:46:19.000Z</published>
    <updated>2016-05-25T03:40:23.138Z</updated>
    
    <content type="html">&lt;p&gt;YARN采用Master/Slave架构，ResourceManager为Master，NodeManager为Slave。ResourceManager负责对各个NodeManager上的资源进行统一管理和调度，当用户提交一个应用程序时，需要提供一个用来跟踪和管理这个程序的ApplicationMaster，它负责向ResourceManager申请资源，并要求NodeManager启动可以占用一定资源的任务。由于不同的ApplicationMaster被分布到不同的节点上，因此它们之间不会相互影响。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;ResourceManager&quot;&gt;&lt;a href=&quot;#ResourceManager&quot; class=&quot;headerlink&quot; title=&quot;ResourceManager&quot;&gt;&lt;/a&gt;ResourceManager&lt;/h2&gt;&lt;p&gt;ResourceManager简称RM，是一个全局的资源管理器，负责整个系统的资源管理和分配工作。主要由调度器（Scheduler）和应用程序管理器（Applications Master，ASM）两部分组成。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;调度器（Scheduler）&lt;br&gt;调度器根据容量，队列等限制条件将系统中的资源分配给各个正在运行的应用程序。&lt;/li&gt;
&lt;li&gt;应用程序管理器（Applications Master）&lt;br&gt;ApplicationMaster负责管理整个系统中所有应用程序，包括应用程序提交、与调度器协商资源以启动ApplicationMaster，监控ApplicationMaster运行状态并在失败时重新启动它等。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&quot;ApplicationMaster&quot;&gt;&lt;a href=&quot;#ApplicationMaster&quot; class=&quot;headerlink&quot; title=&quot;ApplicationMaster&quot;&gt;&lt;/a&gt;ApplicationMaster&lt;/h2&gt;&lt;p&gt;ApplicationMaster简称AM。YARN中每个应用都会启动一个AM。&lt;br&gt;主要功能包括：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;与RM调度器协商以获取资源&lt;/li&gt;
&lt;li&gt;将得到的任务进一步分配给内部的任务&lt;/li&gt;
&lt;li&gt;与NM通信以启动/停止任务&lt;/li&gt;
&lt;li&gt;监控所有任务运行状态，并在任务失败时重新为任务申请资源以重新运行任务&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&quot;NodeManager&quot;&gt;&lt;a href=&quot;#NodeManager&quot; class=&quot;headerlink&quot; title=&quot;NodeManager&quot;&gt;&lt;/a&gt;NodeManager&lt;/h2&gt;&lt;p&gt;NodeManager简称NM，NM是每个节点上的资源和任务管理器&lt;br&gt;主要功能包括：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;定时向RM汇报本节点上的资源使用情况和各个Continer的运行状态&lt;/li&gt;
&lt;li&gt;接收并处理来自AM的Container启动/停止等各种请求&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&quot;Container&quot;&gt;&lt;a href=&quot;#Container&quot; class=&quot;headerlink&quot; title=&quot;Container&quot;&gt;&lt;/a&gt;Container&lt;/h2&gt;&lt;p&gt;Container是YARN中资源容器。它封装了某个节点上的多维度资源，如内存、cpu、磁盘、网络等。YARN中所有的应用都是在container上运行的。AM也是在container上运行的，不过AM的container是向RM申请的。YARN会为每一个任务分配一个Container，并且该任务只能使用该Container中描述的资源。&lt;/p&gt;
&lt;h2 id=&quot;YARN工作流程&quot;&gt;&lt;a href=&quot;#YARN工作流程&quot; class=&quot;headerlink&quot; title=&quot;YARN工作流程&quot;&gt;&lt;/a&gt;YARN工作流程&lt;/h2&gt;&lt;p&gt;YARN上运行的应用程序主要分为两类：短应用程序和长应用程序。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;短应用程序是指一定时间内（可能是秒级、分钟级或小时级，尽管天级别或者更长时间的也存在，但是非常少）可运行完成并征程退出的应用程序&lt;/li&gt;
&lt;li&gt;长应用程序是指不出意外，永不终止运行的应用程序，通常是一些服务，如Storm，HBase等&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;YARN的工作流程包括：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;向YARN中提交一个应用程序，其中包括ApplicationMaster程序，启动ApplicationMaster的命令，用户程序等&lt;/li&gt;
&lt;li&gt;ResourceManager为该应用程序分配一个Container，并与对应的NodeManager通信，要求它在这个Container中启动应用程序的ApplicationMaster&lt;/li&gt;
&lt;li&gt;ApplicationMaster首先向ResourceManager注册（注册之后可以直接通过ResourceManager查看应用程序的运行状态），然后它将为各个任务申请资源，并监控它的运行状态，直到运行结束&lt;/li&gt;
&lt;li&gt;ApplicationMaster采用轮询的方式通过RPC协议向ResourceManager申请和领取资源&lt;/li&gt;
&lt;li&gt;一旦ApplicationMaster申请到资源后，便与对应的NodeManager通信，要求它启动任务&lt;/li&gt;
&lt;li&gt;NodeManager为任务设置好运行环境（包括环境变量，jar包，二进制程序等）后，将任务启动命令写到一个脚本中，并通过运行该脚本启动任务&lt;/li&gt;
&lt;li&gt;各个任务通过RPC协议向ApplicationMaster汇报自己的状态和进度，使得ApplicationMaster随时掌握各个任务的运行状态，从而可以在任务失败时重新启动任务&lt;/li&gt;
&lt;/ol&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;YARN采用Master/Slave架构，ResourceManager为Master，NodeManager为Slave。ResourceManager负责对各个NodeManager上的资源进行统一管理和调度，当用户提交一个应用程序时，需要提供一个用来跟踪和管理这个程序的ApplicationMaster，它负责向ResourceManager申请资源，并要求NodeManager启动可以占用一定资源的任务。由于不同的ApplicationMaster被分布到不同的节点上，因此它们之间不会相互影响。&lt;br&gt;
    
    </summary>
    
    
      <category term="hadoop" scheme="http://dxer.github.io/tags/hadoop/"/>
    
      <category term="bigdata" scheme="http://dxer.github.io/tags/bigdata/"/>
    
      <category term="YAR" scheme="http://dxer.github.io/tags/YAR/"/>
    
  </entry>
  
  <entry>
    <title>【Hadoop学习】Hadoop2.0高可用性</title>
    <link href="http://dxer.github.io/2015/11/03/hadoop_ha/"/>
    <id>http://dxer.github.io/2015/11/03/hadoop_ha/</id>
    <published>2015-11-03T06:38:19.000Z</published>
    <updated>2016-05-25T06:53:29.068Z</updated>
    
    <content type="html">&lt;p&gt;在Hadoop2.0之前，只有一个NameNode，虽然有SecondaryNameNode（不能迅速切换，需要花费一定时间恢复），还是存在单点问题。NameNode在Hadoop中就好比是人的心脏，不能停止工作。如果NameNode数据丢失或者不能工作，那整个集群就不能恢复了。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;在Hadoop2.0中解决了这个问题，在Hadoop2.0中NameNode不再只是一个，可以有多个。每一个都具有相同的职能，一个NameNode是active状态，一个是standby状态。当集群在运行的时候，只有active状态的NameNode是正常工作的，standBy状态的NameNode是处于待命状态，时刻同步active状态NameNode的数据。一旦active状态的NameNode不能工作了，通过手工或者自动切换，standby状态的NameNode就可以转变为active状态了，这样集群还是正常工作了，这样集群就具有高可用性了。&lt;/p&gt;
&lt;p&gt;Hadoop2.0的HA机制官方介绍了2中方式：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;NFS（Network File System）&lt;/li&gt;
&lt;li&gt;QJM（Quorum Journal Manager）&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&quot;基本原理&quot;&gt;&lt;a href=&quot;#基本原理&quot; class=&quot;headerlink&quot; title=&quot;基本原理&quot;&gt;&lt;/a&gt;基本原理&lt;/h3&gt;&lt;p&gt;&lt;img src=&quot;/pic/20151103/HDFS_HA_arch.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;Hadoop2.0中有两个NameNode，一个是active状态NameNode，一个是standby状态NameNode。两者的状态是可以切换的，但是不能同时都是active状态，最多只有一个active状态。只有active状态的NameNode对外提供服务，standby状态的NameNode不对外服务。active状态的NameNode和standby状态的NameNode之间通过NFS或者JN（journalnode，QJM方式）来同步数据。&lt;/p&gt;
&lt;p&gt;active状态的NameNode会把最近的操作记录写到本地的edits文件中（edits file），并传输到NFS或者JN中。standby状态的NameNode定期检查，从NFS或者JN中把最近的edit文件读过来，然后把edits文件和fsimage文件合并成一个新的fsimage，合并完成之后会通知active状态NameNode来获取新的fsiamge，active状态NameNode获得到这个新的fsimage文件后，替换掉原来旧的fsimage文件。&lt;/p&gt;
&lt;h3 id=&quot;NFS方式&quot;&gt;&lt;a href=&quot;#NFS方式&quot; class=&quot;headerlink&quot; title=&quot;NFS方式&quot;&gt;&lt;/a&gt;NFS方式&lt;/h3&gt;&lt;p&gt;&lt;img src=&quot;/pic/20151103/ha_nfs.jpg&quot; alt=&quot;&quot;&gt;&lt;br&gt;NFS作为active NameNode和standby NameNode之间数据共享的存储，active状态的 NameNode会把最近的edits文件写到NFS，而standby状态的NameNode从NFS中读取edits文件。这个方式的缺点就是，如果active状态的NameNode或standby状态的NameNode有一个和NFS之间网络有问题是，就会造成它们之间数据的同步出现问题。&lt;/p&gt;
&lt;h3 id=&quot;QJM方式&quot;&gt;&lt;a href=&quot;#QJM方式&quot; class=&quot;headerlink&quot; title=&quot;QJM方式&quot;&gt;&lt;/a&gt;QJM方式&lt;/h3&gt;&lt;p&gt;&lt;img src=&quot;/pic/20151103/ha_qjm.jpg&quot; alt=&quot;&quot;&gt;&lt;br&gt;QJM方式可以解决NFS容错机制不足的问题，active状态NameNode和standby状态NameNode之间通过一组journalnode（奇数个，2n+1）来共享数据，active状态NameNode把最近的edits文件写到这组journalnode上，只要有n+1个写入成功就认为这次写入操作是成功的，然后standby状态NameNode就可以从journalnode上读取数据了。QJM方式有容错机制，可以容忍n个journalnode的失败&lt;/p&gt;
&lt;h3 id=&quot;NameNode故障切换&quot;&gt;&lt;a href=&quot;#NameNode故障切换&quot; class=&quot;headerlink&quot; title=&quot;NameNode故障切换&quot;&gt;&lt;/a&gt;NameNode故障切换&lt;/h3&gt;&lt;p&gt;active和standby状态NameNode可以随时切换，当active挂掉后，可以把standby切换成active状态。&lt;br&gt;故障切换可以通过人工切换和自动切换方式完成。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;人工切换是通过HA管理的命令来改变NameNode的状态&lt;/li&gt;
&lt;li&gt;自动切换是在active状态NameNode挂掉的时候，standby状态NameNode自动切换成active状态，取代原来的active状态NameNode成为新的active状态NameNode，确保HDFS继续正常工作&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&quot;/pic/20151103/ha.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;自动切换需要配置zookeeper。集群中两个NameNode都在zookeeper中注册，当active状态的NameNode出现故障时，zookeeper能检查到这种情况，它就会自动把standby状态的NameNode切换为active状态。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;在Hadoop2.0之前，只有一个NameNode，虽然有SecondaryNameNode（不能迅速切换，需要花费一定时间恢复），还是存在单点问题。NameNode在Hadoop中就好比是人的心脏，不能停止工作。如果NameNode数据丢失或者不能工作，那整个集群就不能恢复了。&lt;br&gt;
    
    </summary>
    
    
      <category term="hadoop" scheme="http://dxer.github.io/tags/hadoop/"/>
    
      <category term="ha" scheme="http://dxer.github.io/tags/ha/"/>
    
      <category term="bigdata" scheme="http://dxer.github.io/tags/bigdata/"/>
    
  </entry>
  
  <entry>
    <title>【Hadoop学习】Hadoop 1.0 &amp; Hadoop 2.0</title>
    <link href="http://dxer.github.io/2015/11/03/hadoop%20v1.0%20and%20hadoopv2.0/"/>
    <id>http://dxer.github.io/2015/11/03/hadoop v1.0 and hadoopv2.0/</id>
    <published>2015-11-03T01:29:19.000Z</published>
    <updated>2016-05-25T03:40:47.130Z</updated>
    
    <content type="html">&lt;h2 id=&quot;Hadoop-1-0&quot;&gt;&lt;a href=&quot;#Hadoop-1-0&quot; class=&quot;headerlink&quot; title=&quot;Hadoop 1.0&quot;&gt;&lt;/a&gt;Hadoop 1.0&lt;/h2&gt;&lt;p&gt;Hadoop 1.0即第一代Hadoop，由分布式存储系统HDFS和分布式和分布式计算框架MapReduce组成。其中HDFS由一个NameNode和多个DataNode组成MapReduce由一个JobTracker和多个TaskTracker组成，对应的Hadoop版本为Apache Hadoop 0.20.x、1.x、0.21.x、0.22.x和CDH3。&lt;/p&gt;
&lt;h2 id=&quot;Hadoop-2-0&quot;&gt;&lt;a href=&quot;#Hadoop-2-0&quot; class=&quot;headerlink&quot; title=&quot;Hadoop 2.0&quot;&gt;&lt;/a&gt;Hadoop 2.0&lt;/h2&gt;&lt;p&gt;Hadoop 2.0即第二代Hadoop，为了克服Hadooop 1.0中HDFS和MapReduce存在的各种问题而提出的。针对Hadoop 1.0中的单NameNode制约HDFS的扩展性问题，提出了HDFS Federation，它让多个NameNode分管不同的目录进而实现访问隔离和横向扩展，同时解决了NameNode的单点故障问题。针对Hadoop 1.0中的MapReduce在扩展性和多框架支持等方面的不足，它将JobTracker中的资源管理和作业控制功能分开，分别由组件ResourceManager和ApplicationMaster实现，其中，ResourceManager负责所有应用程序的资源分配，ApplicationMaster仅负责管理一个应用程序，着便是全新的通用的资源管理框架YARN。Hadoop 2.0对应的Hadoop的版本为Apache Hadoop 0.23.x、2.x和CDH4。&lt;/p&gt;
&lt;h2 id=&quot;MRv1&quot;&gt;&lt;a href=&quot;#MRv1&quot; class=&quot;headerlink&quot; title=&quot;MRv1&quot;&gt;&lt;/a&gt;MRv1&lt;/h2&gt;&lt;p&gt;MapReduce 1.0计算框架主要由三部分组成，分别是编程模型，数据处理引擎和运行时环境。它的编程模型是将问题抽象成Map和Reduce两个阶段，其中Map阶段将输入数据解析成key/value，迭代调用map()函数处理后，再以key/value的形式输出到本地目录，而Reduce阶段则是将Map阶段输出的数据按照key相同的value进行归约处理，并将最终结果写到HDFS上。它的数据处理引擎由MapTask和ReduceTask组成，分别负责Map阶段逻辑和Reduce阶段逻辑的处理。运行时的环境由一个JobTracker和若干个TaskTracker组成，JobTracker负责资源管理和所有作业的控制，TaskTracker负责接收来自JobTracker的命令并执行它。&lt;/p&gt;
&lt;h2 id=&quot;MRv2&quot;&gt;&lt;a href=&quot;#MRv2&quot; class=&quot;headerlink&quot; title=&quot;MRv2&quot;&gt;&lt;/a&gt;MRv2&lt;/h2&gt;&lt;p&gt;MRv2具有与MRv1相同的编程模型和数据处理引擎，唯一不同的是运行时环境。MRv2是在MRv1基础上经加工之后，运行于资源管理框架YARN之上的计算框架。它由资源管理系统YARN和作业控制进程ApplicationMaster组成，其中YARN负责资源管理和调度，而ApplicationMaster仅负责一个作业的管理。MRv1仅是一个独立的离线计算框架，而MRv2则是运行于YARN之上的MapReduce。&lt;/p&gt;
&lt;h2 id=&quot;YARN&quot;&gt;&lt;a href=&quot;#YARN&quot; class=&quot;headerlink&quot; title=&quot;YARN&quot;&gt;&lt;/a&gt;YARN&lt;/h2&gt;&lt;p&gt;YARN是Hadoop 2.0中的资源管理系统，它是一个通用的资源管理模块，可以为各类应用横须进行资源管理和调度。YARN不仅限于MapReduce一种框架使用，也可以供其他框架使用，比如Spark,Storm等。&lt;/p&gt;
&lt;h2 id=&quot;HDFS-Federation&quot;&gt;&lt;a href=&quot;#HDFS-Federation&quot; class=&quot;headerlink&quot; title=&quot;HDFS Federation&quot;&gt;&lt;/a&gt;HDFS Federation&lt;/h2&gt;&lt;p&gt;在Hadoop 2.0中，对HDFS进行改进，是的NameNode可以横向扩展成多个，每个NameNode分管一部分目录，进而产生了HDFS Federation，该机制的引入不仅增强了HDFS的扩展性，也使HDFS具备了隔离性。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;Hadoop-1-0&quot;&gt;&lt;a href=&quot;#Hadoop-1-0&quot; class=&quot;headerlink&quot; title=&quot;Hadoop 1.0&quot;&gt;&lt;/a&gt;Hadoop 1.0&lt;/h2&gt;&lt;p&gt;Hadoop 1.0即第一代Hadoop，由分布式存储系统HDFS和分布式和
    
    </summary>
    
    
      <category term="hadoop" scheme="http://dxer.github.io/tags/hadoop/"/>
    
      <category term="bigdata" scheme="http://dxer.github.io/tags/bigdata/"/>
    
      <category term="mapreduce" scheme="http://dxer.github.io/tags/mapreduce/"/>
    
  </entry>
  
  <entry>
    <title>【Hadoop学习】Secondary NameNode解读</title>
    <link href="http://dxer.github.io/2015/10/26/secondarynamenode/"/>
    <id>http://dxer.github.io/2015/10/26/secondarynamenode/</id>
    <published>2015-10-26T12:18:19.000Z</published>
    <updated>2016-05-25T08:17:31.947Z</updated>
    
    <content type="html">&lt;p&gt;Secondary NameNode从它的名字上来看，给人的感觉是NameNode的备份。但实际上不是这样。那到底Secondary NameNode在HDFS中扮演的是什么角色呢？&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;从名字上来看Secondary NameNode与NameNode，都包含着NameNode，这两者是不是存在某种关系呢，先来看下NameNode是干什么的。&lt;/p&gt;
&lt;h3 id=&quot;NameNode&quot;&gt;&lt;a href=&quot;#NameNode&quot; class=&quot;headerlink&quot; title=&quot;NameNode&quot;&gt;&lt;/a&gt;NameNode&lt;/h3&gt;&lt;p&gt;NameNode主要是用来保存HDFS的元数据信息，比如命名空间信息，快信息等。当它运行的时候，这些信息会保存在内存中。同时这部分信息也会持久化到磁盘上。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/pic/20151026/nn.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;fsimage:是在NameNode启动时对整个文件系统的快照&lt;/li&gt;
&lt;li&gt;edits:在NameNode启动后，对文件系统改动序列&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;只有在NameNode重启时，edits才会合并到fsimage文件中，从而得到一个文件系统的最新快照。但是在产品集群中NameNode是很少重启的，这也意味着当NameNode运行了很长时间后，edits文件会变得很大。就会面临如下问题：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;edits文件会变的很大，怎么去管理这个文件是一个挑战&lt;/li&gt;
&lt;li&gt;NameNode的重启会花费很长时间，因为有很多edits中改动要合并到fsimage文件上。&lt;/li&gt;
&lt;li&gt;如果NameNode挂掉了，就会丢失了很多改动，因为此时的fsimage文件非常旧。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;这个时候Secondary NameNode就出场了，Secondary NameNode可以来帮助解决上面问题，它的职责就是用来合并NameNode的edits到fsimage中。&lt;/p&gt;
&lt;h3 id=&quot;Secondary-NameNode&quot;&gt;&lt;a href=&quot;#Secondary-NameNode&quot; class=&quot;headerlink&quot; title=&quot;Secondary NameNode&quot;&gt;&lt;/a&gt;Secondary NameNode&lt;/h3&gt;&lt;p&gt;HDFS文件系统的写操作不是直接被修改到fsimage中，而是edits中，Secondary NameNode节点负责将两者进行整合。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/pic/20151026/checkpoint.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;checkpoint过程如下：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Secondary Namenode请求Namenode停止使用edits文件，暂时将新的写操作记录到一个新文件中，如edits.new。&lt;/li&gt;
&lt;li&gt;Secondary Namenode节点从Namenode节点获取fsimage和edits文件（采用HTTP GET）&lt;/li&gt;
&lt;li&gt;Secondary Namenode将fsimage文件载入到内存，逐一执行edits文件中的操作，创建新的fsimage文件&lt;/li&gt;
&lt;li&gt;Secondary Namenode将新的fsimage文件发送回Namenode（使用HTTP POST）&lt;/li&gt;
&lt;li&gt;Namenode节点将从Secondary Namenode节点接收的fsimage文件替换旧的fsimage文件，用步骤1产生的edits.new文件替换旧的edits文件（即改名）。同时更新fstime文件来记录检查点执行的时间&lt;br&gt;注：从Hadoop0.21.0开始，辅助Namenode已经放弃不用，由checkpoint节点取而代之，功能不变。新版本同时引入一种新的Namenode，名为BackupNode。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Secondary NameNode的整个目的在HDFS中提供一个Checkpoint Node，它只是NameNode的一个助手节点&lt;/p&gt;
&lt;p&gt;现在，我们明白Secondary NameNode所做的是在文件系统这设置一个Checkpoint来帮助NameNode更好的工作；它不是取代NameNode，也不是NameNode的备份。&lt;/p&gt;
&lt;p&gt;Secondary NameNode的检查点进程启动，是由两个配置参数控制的：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;fs.checkpoint.period，指定连续两次检查点的最大时间间隔， 默认值是1小时。&lt;/li&gt;
&lt;li&gt;fs.checkpoint.size定义了edits日志文件的最大值，一旦超过这个值会导致强制执行检查点（即使没到检查点的最大时间间隔）。默认值是64MB。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;关于NameNode是什么时候将改动写到edit logs中的？&lt;br&gt;这个操作实际上是由DataNode的写操作触发的，当我们往DataNode写文件时，DataNode会跟NameNode通信，告诉NameNode什么文件的第几个block放在它那里，NameNode这个时候会将这些元数据信息写到edit logs文件中。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;Secondary NameNode从它的名字上来看，给人的感觉是NameNode的备份。但实际上不是这样。那到底Secondary NameNode在HDFS中扮演的是什么角色呢？&lt;br&gt;
    
    </summary>
    
    
      <category term="hadoop" scheme="http://dxer.github.io/tags/hadoop/"/>
    
      <category term="hdfs" scheme="http://dxer.github.io/tags/hdfs/"/>
    
  </entry>
  
  <entry>
    <title>【Hadoop学习】Hadoop的序列化</title>
    <link href="http://dxer.github.io/2015/10/25/hadoop_serializable/"/>
    <id>http://dxer.github.io/2015/10/25/hadoop_serializable/</id>
    <published>2015-10-25T06:46:19.000Z</published>
    <updated>2016-05-25T03:41:02.709Z</updated>
    
    <content type="html">&lt;p&gt;对象的序列化用于将对象编码成一个字节流，以及从字节流中重新构建对象。&lt;br&gt;将一个对象编码成一个字节流叫做序列化改对象(Serializing)&lt;br&gt;相反的处理过程称为反序列化（Deserializing）&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;序列化的主要用途：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;作为一种持久化格式&lt;br&gt;一个对象被序列化之后，它的编码可以被存储到磁盘上，供反序列化使用&lt;/li&gt;
&lt;li&gt;作为一种通信数据格式&lt;br&gt;序列化的结果可以从一个正在运行的虚拟机，通过网络传输到一个虚拟机上&lt;/li&gt;
&lt;li&gt;作为一种拷贝，克隆机制&lt;br&gt;将对象序列化到内存，然后通过反序列化，可以得到一个对已经存在的对象的深拷贝的新对象&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;在hadoop中，序列化是要使用的是数据持久化和通信数据格式两种功能。&lt;/p&gt;
&lt;h2 id=&quot;JDK中自带序列化&quot;&gt;&lt;a href=&quot;#JDK中自带序列化&quot; class=&quot;headerlink&quot; title=&quot;JDK中自带序列化&quot;&gt;&lt;/a&gt;JDK中自带序列化&lt;/h2&gt;&lt;p&gt;JDK的序列化只有实现了serializable接口就能实现序列化与反序列化，但是记得一定要加上序列化版本ID serialVersionUID，这个是用来识别序列化的之前那个类的到底是哪一个。&lt;br&gt;我们显式设置这个序列化版本ID的目的就是为了：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;在某些场合，希望类的不同版本对序列化兼容，因此需要确保类的不同版本具有相同的serialVersionUID；&lt;/li&gt;
&lt;li&gt;在某些场合，不希望类的不同版本对序列化兼容，因此需要确保类的不同版本具有不同的serialVersionUID。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;java序列化算法要点：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;将对象实例相关的元数据输出&lt;/li&gt;
&lt;li&gt;递归的输出类的超类描述直到不再有超类&lt;/li&gt;
&lt;li&gt;类元数据完了之后，开始从最顶层的超类开始输出对象的实例的实际数据值&lt;/li&gt;
&lt;li&gt;从上到下递归输出实例的数据&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;java序列化与反序列化实现方法&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;创建一个对象，并实现Serializbale接口&lt;/li&gt;
&lt;li&gt;序列化&lt;code&gt;ObjectOutputStream.writeObject(obj);&lt;/code&gt;&lt;br&gt;反序列化&lt;code&gt;ObjectOutputStream.readObject();&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;java序列化不足之处：&lt;br&gt;java序列化将每个对象的类名写入到输出流中，这就导致了java序列化对象需要占用比原对象更多的存储空间。&lt;br&gt;java的反序列化会不断的创建对象，这会给系统带来一定的开销。&lt;/p&gt;
&lt;p&gt;正是由于java序列化的不足，所以hadoop没有直接使用java序列化，而是实现了自己的序列化机制，在hadoop序列化中，用户可以复用对象，这样就减少了java对象的分配和回收，提高了应用的效率。&lt;/p&gt;
&lt;p&gt;Hadoop序列化特点：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;紧凑&lt;br&gt;由于带宽是hadoop集群中稀缺的资源，一个紧凑的序列化机制可以充分利用数据中心的带宽&lt;/li&gt;
&lt;li&gt;快速&lt;br&gt;在进程间通信时会大量使用序列化机制，因此必须尽量减少序列化和反序列化的开销&lt;/li&gt;
&lt;li&gt;可扩展&lt;br&gt;随着系统的发展，系统间通信的协议升级，类的定义会发生变化，序列化机制需要支持这些升级和变化&lt;/li&gt;
&lt;li&gt;互操作&lt;br&gt;可以支持不同开发语言间的通信，如c++和java之间的通信。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;Hadoop序列化&quot;&gt;&lt;a href=&quot;#Hadoop序列化&quot; class=&quot;headerlink&quot; title=&quot;Hadoop序列化&quot;&gt;&lt;/a&gt;Hadoop序列化&lt;/h2&gt;&lt;p&gt;hadoop中通过实现Writable接口来实现序列化，它比较紧凑、快速。&lt;/p&gt;
&lt;figure class=&quot;highlight java&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;class&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;interface&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;Writable&lt;/span&gt; &lt;/span&gt;&amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  &lt;span class=&quot;comment&quot;&gt;/**&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;   * 输出（序列化）对象到流中&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;   * &lt;span class=&quot;doctag&quot;&gt;@param&lt;/span&gt; out&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;   * &lt;span class=&quot;doctag&quot;&gt;@throws&lt;/span&gt; IOException&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;   */&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  &lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;write&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;(DataOutput out)&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;throws&lt;/span&gt; IOException&lt;/span&gt;;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt; &lt;span class=&quot;comment&quot;&gt;/**&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  * 从流中读取（反序列化对象）&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  * &lt;span class=&quot;doctag&quot;&gt;@param&lt;/span&gt; in&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  * &lt;span class=&quot;doctag&quot;&gt;@throws&lt;/span&gt; IOException&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  */&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  &lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;readFields&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;(DataInput in)&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;throws&lt;/span&gt; IOException&lt;/span&gt;;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;write方法用于将对象写入二进制的DataOutput中，完成序列化&lt;br&gt;readFields从DataInput流中读取数据，完成反序列化&lt;/p&gt;
&lt;p&gt;下面是一个demo：&lt;/p&gt;
&lt;figure class=&quot;highlight java&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;22&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;class&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;MyWritable&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;implements&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;Writable&lt;/span&gt; &lt;/span&gt;&amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;comment&quot;&gt;// Some data&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;keyword&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;int&lt;/span&gt; counter;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;keyword&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;long&lt;/span&gt; timestamp;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;write&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;(DataOutput out)&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;throws&lt;/span&gt; IOException &lt;/span&gt;&amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        out.writeInt(counter);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        out.writeLong(timestamp);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;readFields&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;(DataInput in)&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;throws&lt;/span&gt; IOException &lt;/span&gt;&amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        counter = in.readInt();&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        timestamp = in.readLong();&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;static&lt;/span&gt; MyWritable &lt;span class=&quot;title&quot;&gt;read&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;(DataInput in)&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;throws&lt;/span&gt; IOException &lt;/span&gt;&amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        MyWritable w = &lt;span class=&quot;keyword&quot;&gt;new&lt;/span&gt; MyWritable();&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        w.readFields(in);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &lt;span class=&quot;keyword&quot;&gt;return&lt;/span&gt; w;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;hadoop中常用的序列化文件如下图所示&lt;br&gt;&lt;img src=&quot;/pic/20160520/hadoop_Serializable.jpg&quot; alt=&quot;hadoop序列化&quot;&gt;&lt;/p&gt;
&lt;h3 id=&quot;BytesWritable&quot;&gt;&lt;a href=&quot;#BytesWritable&quot; class=&quot;headerlink&quot; title=&quot;BytesWritable&quot;&gt;&lt;/a&gt;BytesWritable&lt;/h3&gt;&lt;p&gt;BytesWritable类型是一个二进制数组的封装类型，序列化格式是以一个4字节的整数。&lt;/p&gt;
&lt;h3 id=&quot;NullWritable&quot;&gt;&lt;a href=&quot;#NullWritable&quot; class=&quot;headerlink&quot; title=&quot;NullWritable&quot;&gt;&lt;/a&gt;NullWritable&lt;/h3&gt;&lt;p&gt;NullWritable是一个非常特殊的Writable类型，序列化不包含任何字符，仅仅相当于个占位符。在MapReduce编程中，key或者value在不需要使用时，可以定义为NullWritable。&lt;/p&gt;
&lt;h3 id=&quot;ObjectWritable&quot;&gt;&lt;a href=&quot;#ObjectWritable&quot; class=&quot;headerlink&quot; title=&quot;ObjectWritable&quot;&gt;&lt;/a&gt;ObjectWritable&lt;/h3&gt;&lt;p&gt;ObjectWritable是其他类型的封装类，包括java原生类型，String，enum，null等，或者这些类型的数组。当一个field有多种类型时，就可以使用ObjectWritable，不过有个不好的地方就是占用的空间太大，即使你存一个字母，因为它需要保存封装前的类型。&lt;/p&gt;
&lt;h3 id=&quot;GenericWritable&quot;&gt;&lt;a href=&quot;#GenericWritable&quot; class=&quot;headerlink&quot; title=&quot;GenericWritable&quot;&gt;&lt;/a&gt;GenericWritable&lt;/h3&gt;&lt;p&gt;使用GenericWritable时，只需继承他，并通过getTypes方法指定哪些类型需要支持即可。&lt;br&gt;GenericWritable的序列化只是把类型在type数组里的索引放在了前面，这样就比ObjectWritable节省了很多空间，所以推荐大家使用GenericWritable&lt;/p&gt;
&lt;h2 id=&quot;集合类型的Writable&quot;&gt;&lt;a href=&quot;#集合类型的Writable&quot; class=&quot;headerlink&quot; title=&quot;集合类型的Writable&quot;&gt;&lt;/a&gt;集合类型的Writable&lt;/h2&gt;&lt;h3 id=&quot;ArrayWritable和TwoDArrayWritable&quot;&gt;&lt;a href=&quot;#ArrayWritable和TwoDArrayWritable&quot; class=&quot;headerlink&quot; title=&quot;ArrayWritable和TwoDArrayWritable&quot;&gt;&lt;/a&gt;ArrayWritable和TwoDArrayWritable&lt;/h3&gt;&lt;p&gt;ArrayWritable和TwoDArrayWritable分别表示数组和二维数组的Writable类型，指定数组的类型有两种方法,构造方法里设置，或者继承于ArrayWritable,TwoDArrayWritable也是一样。&lt;/p&gt;
&lt;h3 id=&quot;MapWritable和SortedMapWritable&quot;&gt;&lt;a href=&quot;#MapWritable和SortedMapWritable&quot; class=&quot;headerlink&quot; title=&quot;MapWritable和SortedMapWritable&quot;&gt;&lt;/a&gt;MapWritable和SortedMapWritable&lt;/h3&gt;&lt;p&gt;MapWritable对应Map,SortedMapWritable对应SortedMap,以4个字节开头，存储集合大小，然后每个元素以一个字节开头存储类型的索引（类似GenericWritable,所以总共的类型总数只能倒127），接着是元素本身，先key后value，这样一对对排开。&lt;br&gt;这两个Writable以后会用很多，贯穿整个hadoop，这里就不写示例了。&lt;/p&gt;
&lt;p&gt;hadoop序列化中没有set集合和list集合，但是可以代替实现。用MapWritable代替set，SortedMapWritable代替sortedmap，只需将他们的values设置成NullWritable即可，NullWritable不占空间。可以用ArrayWritable代替list集合，不同类型的list可以用GenericWritable实现类型，然后再使用ArrayWritable封装。当然MapWritable一样可以实现list，把key设置为索引，values做list里的元素。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;对象的序列化用于将对象编码成一个字节流，以及从字节流中重新构建对象。&lt;br&gt;将一个对象编码成一个字节流叫做序列化改对象(Serializing)&lt;br&gt;相反的处理过程称为反序列化（Deserializing）&lt;br&gt;
    
    </summary>
    
    
      <category term="hadoop" scheme="http://dxer.github.io/tags/hadoop/"/>
    
      <category term="bigdata" scheme="http://dxer.github.io/tags/bigdata/"/>
    
      <category term="serializable" scheme="http://dxer.github.io/tags/serializable/"/>
    
  </entry>
  
  <entry>
    <title>JVM垃圾回收</title>
    <link href="http://dxer.github.io/2015/08/17/jvm/"/>
    <id>http://dxer.github.io/2015/08/17/jvm/</id>
    <published>2015-08-17T13:21:38.000Z</published>
    <updated>2016-05-18T09:44:25.574Z</updated>
    
    <content type="html">&lt;p&gt;JVM堆内存被分为两部分&lt;em&gt;年轻代(Young Generation)&lt;/em&gt;和&lt;em&gt;老年代(Old Generation)&lt;/em&gt;。&lt;/p&gt;
&lt;h5 id=&quot;新生代-Young-Generation&quot;&gt;&lt;a href=&quot;#新生代-Young-Generation&quot; class=&quot;headerlink&quot; title=&quot;新生代(Young Generation)&quot;&gt;&lt;/a&gt;新生代(Young Generation)&lt;/h5&gt;&lt;p&gt;新生代是所有新对象产生的地方。当年轻代的内存空间被用完时，就会触发垃圾回收。这个垃圾回收叫做&lt;em&gt;Minor GC&lt;/em&gt;。新生代分为3个部分&lt;em&gt;Eden区&lt;/em&gt;和&lt;em&gt;Survivor区(FromSpace和ToSpace,两个区域大小相同)&lt;/em&gt;，新生代的大小可以通过&lt;code&gt;-Xmn&lt;/code&gt;来控制，也可以用&lt;code&gt;-XX：SurvivorRatio&lt;/code&gt;来控制Eden和Survivor的比例。&lt;/p&gt;
&lt;p&gt;新生代的特点&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;大多数新建的对象都在Eden区&lt;/li&gt;
&lt;li&gt;当Eden区域被填满时，就会执行Minor GC。并把所有存活下来的对象转移到其中一个survivor区&lt;/li&gt;
&lt;li&gt;Minor GC同样会检查存活下来的对象，并把他们转移到另一个survivor区。这样在一段时间内，总会有一个空的survivor区&lt;/li&gt;
&lt;li&gt;经过多次GC周期后，仍然存活下来的对象会被转移到老年代内存空间。通常这是在新生代有资格提升到老年代前通过设定年龄阈值来完成的。&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id=&quot;老年代-Old-Generation&quot;&gt;&lt;a href=&quot;#老年代-Old-Generation&quot; class=&quot;headerlink&quot; title=&quot;老年代(Old Generation)&quot;&gt;&lt;/a&gt;老年代(Old Generation)&lt;/h5&gt;&lt;p&gt;老年代内存里包含了长期存活的对象和经过多次Minor GC后依然存活下来的对象。通常会在老年代内存被占满时进行垃圾回收。老年代的垃圾收集叫做Major GC。Major GC会花费更多的时间。旧生带占用大小为&lt;code&gt;-Xmx&lt;/code&gt;值减去&lt;code&gt;-Xmn&lt;/code&gt;对应的值&lt;/p&gt;
&lt;h5 id=&quot;永久代-Permanent-Generation&quot;&gt;&lt;a href=&quot;#永久代-Permanent-Generation&quot; class=&quot;headerlink&quot; title=&quot;永久代(Permanent Generation)&quot;&gt;&lt;/a&gt;永久代(Permanent Generation)&lt;/h5&gt;&lt;p&gt;永久代包含了JVM需要的应用元数据，这些元数据描述了在应用里使用的类和方法。注意，永久代不是Java堆内存的一部分，有一些JVM没有这一代，主要存放敞亮及类的一些信息，默认最小值为16MB，最大值为64MB，可以通过&lt;code&gt;-XX:PermSize&lt;/code&gt;及&lt;code&gt;-XX:MaxPermSize&lt;/code&gt;来设置最小值和最大值。&lt;/p&gt;
&lt;p&gt;永久代存放JVM运行时使用的类。永久代同样包含了Java SE库的类和方法。永久代的对象在full GC时进行垃圾收集。&lt;/p&gt;
&lt;h5 id=&quot;方法区&quot;&gt;&lt;a href=&quot;#方法区&quot; class=&quot;headerlink&quot; title=&quot;方法区&quot;&gt;&lt;/a&gt;方法区&lt;/h5&gt;&lt;p&gt;方法区是永久代空间的一部分，并用来存储类型信息（运行时常量和静态变量）和方法代码和构造函数代码。&lt;/p&gt;
&lt;h5 id=&quot;内存池&quot;&gt;&lt;a href=&quot;#内存池&quot; class=&quot;headerlink&quot; title=&quot;内存池&quot;&gt;&lt;/a&gt;内存池&lt;/h5&gt;&lt;p&gt;如果JVM实现支持，JVM内存管理会为创建内存池，用来为不变对象创建对象池。字符串池就是内存池类型的一个很好的例子。内存池可以属于堆或者永久代，这取决于JVM内存管理的实现。&lt;/p&gt;
&lt;h5 id=&quot;运行时常量池&quot;&gt;&lt;a href=&quot;#运行时常量池&quot; class=&quot;headerlink&quot; title=&quot;运行时常量池&quot;&gt;&lt;/a&gt;运行时常量池&lt;/h5&gt;&lt;p&gt;运行时常量池是每个类常量池的运行时代表。它包含了类的运行时常量和静态方法。运行时常量池是方法区的一部分。&lt;/p&gt;
&lt;h5 id=&quot;Java栈内存&quot;&gt;&lt;a href=&quot;#Java栈内存&quot; class=&quot;headerlink&quot; title=&quot;Java栈内存&quot;&gt;&lt;/a&gt;Java栈内存&lt;/h5&gt;&lt;p&gt;Java栈内存用于运行线程。它们包含了方法里的临时数据、堆里其它对象引用的特定数据。你可以阅读栈内存和堆内存的区别。&lt;/p&gt;
&lt;h5 id=&quot;Java-堆内存开关&quot;&gt;&lt;a href=&quot;#Java-堆内存开关&quot; class=&quot;headerlink&quot; title=&quot;Java 堆内存开关&quot;&gt;&lt;/a&gt;Java 堆内存开关&lt;/h5&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;VM设置&lt;/th&gt;
&lt;th&gt;描述&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;-Xms&lt;/td&gt;
&lt;td&gt;设置JVM启动时堆的初始化大小。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;-Xmx&lt;/td&gt;
&lt;td&gt;设置堆最大值。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;-Xmn&lt;/td&gt;
&lt;td&gt;设置年轻代的空间大小，剩下的为老年代的空间大小。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;-XX:PermGen&lt;/td&gt;
&lt;td&gt;设置永久代内存的初始化大小。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;-XX:MaxPermGen&lt;/td&gt;
&lt;td&gt;设置永久代的最大值。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;-XX:SurvivorRatio&lt;/td&gt;
&lt;td&gt;提供Eden区和survivor区的空间比例。比如，如果年轻代的大小为10m并且VM开关是-XX:SurvivorRatio=2，那么将会保留5m内存给Eden区和每个Survivor区分配2.5m内存。默认比例是8。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;-XX:NewRatio&lt;/td&gt;
&lt;td&gt;提供年老代和年轻代的比例大小。默认值是2。&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;大多数时候，上面的选项已经足够使用了。但是如果你还想了解其他的选项，那么请查看JVM选项官方网页。&lt;/p&gt;
&lt;h5 id=&quot;Java垃圾回收&quot;&gt;&lt;a href=&quot;#Java垃圾回收&quot; class=&quot;headerlink&quot; title=&quot;Java垃圾回收&quot;&gt;&lt;/a&gt;Java垃圾回收&lt;/h5&gt;&lt;p&gt;JVM堆内存主要被分为三块，新生代、老年代、持久代。三代的特点不同，造就了他们所用的GC算法不同，新生代适合那些生命周期较短，频繁创建及销毁的对象，老年代适合生命周期相对较长的对象，持久代在Sun HotSpot中就是指方法区（有些JVM中根本就没有持久代这中说法）。&lt;/p&gt;
&lt;p&gt;Java垃圾回收会找出没用的对象，把它从内存中移除并释放出内存给以后创建的对象使用。Java程序语言中的一个最大优点是自动垃圾回收，不像其他的程序语言那样需要手动分配和释放内存，比如C语言。&lt;/p&gt;
&lt;p&gt;垃圾收集器是一个后台运行程序。它管理着内存中的所有对象并找出没被引用的对象。所有的这些未引用的对象都会被删除，回收它们的空间并分配给其他对象。&lt;/p&gt;
&lt;p&gt;一个基本的垃圾回收过程涉及三个步骤：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;标记：这是第一步。在这一步，垃圾收集器会找出哪些对象正在使用和哪些对象不在使用。&lt;/li&gt;
&lt;li&gt;正常清除：垃圾收集器清会除不在使用的对象，回收它们的空间分配给其他对象。&lt;/li&gt;
&lt;li&gt;压缩清除：为了提升性能，压缩清除会在删除没用的对象后，把所有存活的对象移到一起。这样可以提高分配新对象的效率。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;简单标记和清除方法存在两个问题：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;效率很低。因为大多数新建对象都会成为“没用对象”。&lt;/li&gt;
&lt;li&gt;经过多次垃圾回收周期的对象很有可能在以后的周期也会存活下来。&lt;br&gt;上面简单清除方法的问题在于Java垃圾收集的分代回收的，而且在堆内存里有年轻代和年老代两个区域。我已经在上面解释了Minor GC和Major GC是怎样扫描对象，以及如何把对象从一个分代空间移到另外一个分代空间。&lt;/li&gt;
&lt;/ol&gt;
&lt;h5 id=&quot;Java垃圾回收类型&quot;&gt;&lt;a href=&quot;#Java垃圾回收类型&quot; class=&quot;headerlink&quot; title=&quot;Java垃圾回收类型&quot;&gt;&lt;/a&gt;Java垃圾回收类型&lt;/h5&gt;&lt;p&gt;这里有五种可以在应用里使用的垃圾回收类型。仅需要使用JVM开关就可以在我们的应用里启用垃圾回收策略。让我们一起来逐一了解：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Serial GC（-XX:+UseSerialGC）：Serial GC使用简单的标记、清除、压缩方法对年轻代和年老代进行垃圾回收，即Minor GC和Major GC。Serial GC在client模式（客户端模式）很有用，比如在简单的独立应用和CPU配置较低的机器。这个模式对占有内存较少的应用很管用。&lt;/li&gt;
&lt;li&gt;Parallel GC（-XX:+UseParallelGC）：除了会产生N个线程来进行年轻代的垃圾收集外，Parallel GC和Serial GC几乎一样。这里的N是系统CPU的核数。我们可以使用 -XX:ParallelGCThreads=n 这个JVM选项来控制线程数量。并行垃圾收集器也叫throughput收集器。因为它使用了多CPU加快垃圾回收性能。Parallel GC在进行年老代垃圾收集时使用单线程。&lt;/li&gt;
&lt;li&gt;Parallel Old GC（-XX:+UseParallelOldGC）：和Parallel GC一样。不同之处，Parallel Old GC在年轻代垃圾收集和年老代垃圾回收时都使用多线程收集。&lt;/li&gt;
&lt;li&gt;并发标记清除（CMS）收集器（-XX:+UseConcMarkSweepGC)：CMS收集器也被称为短暂停顿并发收集器。它是对年老代进行垃圾收集的。CMS收集器通过多线程并发进行垃圾回收，尽量减少垃圾收集造成的停顿。CMS收集器对年轻代进行垃圾回收使用的算法和Parallel收集器一样。这个垃圾收集器适用于不能忍受长时间停顿要求快速响应的应用。可使用 -XX:ParallelCMSThreads=n JVM选项来限制CMS收集器的线程数量。&lt;/li&gt;
&lt;li&gt;G1垃圾收集器（-XX:+UseG1GC) G1（Garbage First）：垃圾收集器是在Java 7后才可以使用的特性，它的长远目标时代替CMS收集器。G1收集器是一个并行的、并发的和增量式压缩短暂停顿的垃圾收集器。G1收集器和其他的收集器运行方式不一样，不区分年轻代和年老代空间。它把堆空间划分为多个大小相等的区域。当进行垃圾收集时，它会优先收集存活对象较少的区域，因此叫“Garbage First”。你可以在Oracle Garbage-FIrst收集器文档找到更多详细信息。&lt;/li&gt;
&lt;/ol&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;JVM堆内存被分为两部分&lt;em&gt;年轻代(Young Generation)&lt;/em&gt;和&lt;em&gt;老年代(Old Generation)&lt;/em&gt;。&lt;/p&gt;
&lt;h5 id=&quot;新生代-Young-Generation&quot;&gt;&lt;a href=&quot;#新生代-Young-Generation
    
    </summary>
    
    
      <category term="java" scheme="http://dxer.github.io/tags/java/"/>
    
      <category term="jvm" scheme="http://dxer.github.io/tags/jvm/"/>
    
  </entry>
  
  <entry>
    <title>redis学习 - 数据持久化</title>
    <link href="http://dxer.github.io/2015/05/07/redis-persistence/"/>
    <id>http://dxer.github.io/2015/05/07/redis-persistence/</id>
    <published>2015-05-07T06:55:38.000Z</published>
    <updated>2016-04-28T10:33:59.527Z</updated>
    
    <content type="html">&lt;p&gt;Redis提供了多种不同级别的持久化方式:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;RDB 持久化可以在指定的时间间隔内产生数据集的时间点快照（point-in-time snapshot）&lt;/li&gt;
&lt;li&gt;AOF持久化记录服务器执行的所有写操作命令，并在服务器启动时，通过重新执行这些命令来还原数据集。AOF文件中的命令全部以Redis协议的格式来保存，新命令会被追加到文件的末尾.Redis还可以在后台对AOF文件进行重写(rewrite)，使得AOF文件的体积不会超过保存数据集状态所需的实际大小。&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Redis还可以同时使用AOF和RDB持久化。在这种情况下，当Redis重启时，它会优先使用AOF文件来还原数据集，因为AOF文件保存的数据集通常比RDB文件所保存的数据集更完整。&lt;/li&gt;
&lt;li&gt;可以关闭持久化功能，让数据只在服务器运行时存在。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;RDB的优点&quot;&gt;&lt;a href=&quot;#RDB的优点&quot; class=&quot;headerlink&quot; title=&quot;RDB的优点&quot;&gt;&lt;/a&gt;RDB的优点&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;RDB是一个很紧凑的文件，它保存了redis在某个时间点上的数据集。&lt;/li&gt;
&lt;li&gt;RDB非常适用于灾难恢复，它只有一个文件，并且内容紧凑，可以将它传送到别的数据中心&lt;/li&gt;
&lt;li&gt;可以最大化redis的性能；父进程在保存RDB文件时，唯一要做的就是fork一个子进程，然后这个子进程就会处理接下来的所有保存工作，父进程无需执行任何磁盘I/O操作&lt;/li&gt;
&lt;li&gt;RDB在恢复大数据集的时候比AOF的速度要快&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&quot;RDB的缺点&quot;&gt;&lt;a href=&quot;#RDB的缺点&quot; class=&quot;headerlink&quot; title=&quot;RDB的缺点&quot;&gt;&lt;/a&gt;RDB的缺点&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;因为RDB是保存在某个时间点上的数据集，这样的话，服务器故障可能会丢失数据。&lt;/li&gt;
&lt;li&gt;每次保存RDB的时候，redis要fork一个子进程，并由子进程来进行实际的持久化工作，在数据集比较大的时候，fork可能会非常耗时，可能会造成服务器停止处理客户端请求；如果数据集非常巨大，并且cpu比较紧张的话，那么 这种停止时间设置可能会长达整整1秒。虽然AOF重写也需要进行fork，但无论AOF重写的执行间隔有多长，数据的耐久性都不会有任何损失&lt;/li&gt;
&lt;/ol&gt;
&lt;h5 id=&quot;AOF优点&quot;&gt;&lt;a href=&quot;#AOF优点&quot; class=&quot;headerlink&quot; title=&quot;AOF优点&quot;&gt;&lt;/a&gt;AOF优点&lt;/h5&gt;&lt;ol&gt;
&lt;li&gt;使用AOF持久化会让redis变得非常耐久，你可以设置不同的fsync策略，比如无fsync，每秒钟一次fsync，或者每次写入命令是fsync。AOF的默认策略为每秒钟fsync一次，在这种配置下，redis仍然可以保持良好的性能，并且就算发生故障停机，也最多只会丢失一秒钟的数据&lt;/li&gt;
&lt;li&gt;AOF文件只是一个日志文件追加操作（append only log），因此对AOF文件的写入不需要进行seek，即使日志因为某些原因而包含了未写入完整命令（比如写入时， 磁盘满了，写入时中途停机等），redis-check-aof工具可以轻易的修复这种问题&lt;/li&gt;
&lt;li&gt;redis可以在AOF文件体积过大时，自动在后台对AOF进行重写，重写后的AOF文件包含了恢复当前数据集所需的最小命令集合。这个重写操作是绝对安全的，因为redis在创建新的AOF过程中，会继续讲命令追加到现有的AOF文件里面，即使重写过程中发生停机，现有的AOF文件也不会丢失，而一旦新AOF文件创建完毕，redis就会从旧文件切换到新AOF文件，并开始对新AOF文件进行追加操作&lt;/li&gt;
&lt;li&gt;AOF文件有序地保存了对数据库执行的所有写入操作，这些写入操作以redis协议的格式保存，因此AOF文件的内容非常容易被人读懂，对文件进行分析也很容易。到处AOF文件也非常简单。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&quot;AOF缺点&quot;&gt;&lt;a href=&quot;#AOF缺点&quot; class=&quot;headerlink&quot; title=&quot;AOF缺点&quot;&gt;&lt;/a&gt;AOF缺点&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;对于相同的数据来说，AOF文件的体积通常要大于RDB文件的体积&lt;/li&gt;
&lt;li&gt;根据所使用的fsync策略。AOF的速度可能会慢于RDB。&lt;/li&gt;
&lt;li&gt;AOF的bug，曾经因为个别命令的原因，导致AOF文件在重新载入是，无法将数据集恢复成保存时的样子。&lt;/li&gt;
&lt;/ol&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;Redis提供了多种不同级别的持久化方式:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;RDB 持久化可以在指定的时间间隔内产生数据集的时间点快照（point-in-time snapshot）&lt;/li&gt;
&lt;li&gt;AOF持久化记录服务器执行的所有写操作命令，并在服务器启动时，通过重新执行这些命令来还原数据集。AOF文件中的命令全部以Redis协议的格式来保存，新命令会被追加到文件的末尾.Redis还可以在后台对AOF文件进行重写(rewrite)，使得AOF文件的体积不会超过保存数据集状态所需的实际大小。
    
    </summary>
    
    
      <category term="redis" scheme="http://dxer.github.io/tags/redis/"/>
    
  </entry>
  
  <entry>
    <title>redis学习 - 主从拷贝</title>
    <link href="http://dxer.github.io/2015/05/07/redis_master_slave_copy/"/>
    <id>http://dxer.github.io/2015/05/07/redis_master_slave_copy/</id>
    <published>2015-05-07T06:29:19.000Z</published>
    <updated>2016-04-28T10:34:17.814Z</updated>
    
    <content type="html">&lt;h2 id=&quot;Redis主从拷贝的特点&quot;&gt;&lt;a href=&quot;#Redis主从拷贝的特点&quot; class=&quot;headerlink&quot; title=&quot;Redis主从拷贝的特点&quot;&gt;&lt;/a&gt;Redis主从拷贝的特点&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;同一个Master可以拥有多个Slaves。&lt;/li&gt;
&lt;li&gt;Master下的Slave还可以接受同一架构中其它slave的链接与同步请求，实现数据的级联复制，即Master-&amp;gt;Slave-&amp;gt;Slave模式；&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Master以非阻塞的方式同步数据至slave，这将意味着Master会继续处理一个或多个slave的读写请求；&lt;br&gt;4.Slave端同步数据也可以修改为非阻塞是的方式，当slave在执行新的同步时，它仍可以用旧的数据信息来提供查询；否则，当slave与master失去联系时，slave会返回一个错误给客户端；&lt;/li&gt;
&lt;li&gt;主从复制具有可扩展性，即多个slave专门提供只读查询与数据的冗余，Master端专门提供写操作；&lt;/li&gt;
&lt;li&gt;通过配置禁用Master数据持久化机制，将其数据持久化操作交给Slaves完成，避免在Master中要有独立的进程来完成此操作。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&quot;Redis主从拷贝的过程&quot;&gt;&lt;a href=&quot;#Redis主从拷贝的过程&quot; class=&quot;headerlink&quot; title=&quot;Redis主从拷贝的过程&quot;&gt;&lt;/a&gt;Redis主从拷贝的过程&lt;/h2&gt;&lt;p&gt;slave连接上master之后，slave发送一个SYNC命令到master，master接收到命令之后，无论是第一次同步建立的连接，还是连接断开后的重新连接，master会开启BGSAVE操作，启动一个后台进程，保存一份当前master内存快照，并且开始保存从调用BGSAVE之后的所有写命令，master生成完快照之后，发送内存快照rdb文件给slave。slave接收到master发送过来的rdb文件之后，将清空所有旧数据，加载接收到的rdb文件到内存中，发送完rdb文件给slave之后，开始发送刚刚保存的写操作日志给slave，slave执行这些写操作，至此，主从数据保存一致。发送完写日志之后，master会增量发送之后的写操作给slave，使主从一致。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;ps: 当master和slave的连接断开时，slave可以自动重新建立连接。如果master同时收到多个slave发来的同步连接命令，只会使用启动一个进程来写内存快照，然后发送给所有的slave&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h6 id=&quot;Master-write-Slave-read机制&quot;&gt;&lt;a href=&quot;#Master-write-Slave-read机制&quot; class=&quot;headerlink&quot; title=&quot;Master write, Slave read机制&quot;&gt;&lt;/a&gt;Master write, Slave read机制&lt;/h6&gt;&lt;p&gt;redis的主从复制，通过程序实现数据的读写分离，让master负责处理些请求，slave负责处理读请求，通过扩展slave处理更多的并发请求，减轻master端的负载。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;ps:在程序中判断用户的读写请求，将write请求发送给master，read请求发送给slave处理&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;redis主从拷贝配置&quot;&gt;&lt;a href=&quot;#redis主从拷贝配置&quot; class=&quot;headerlink&quot; title=&quot;redis主从拷贝配置&quot;&gt;&lt;/a&gt;redis主从拷贝配置&lt;/h2&gt;&lt;p&gt;开启主从复制，最简单的方式，连接上从机redis，执行slaveof &amp;lt;主机host&amp;gt; &amp;lt;主机端口&amp;gt;，另外也可以在从机的配置文件中加入slaveof &amp;lt;主机host&amp;gt; &amp;lt;主机端口&amp;gt;，这样从机启动的时候，就会自动连接主机，并且同步数据。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;slaveof 192.168.100.126 6379 # 配置主机信息&lt;br&gt;masterauth &lt;master-password&gt; # 如果主机设置了密码，配置密码&lt;br&gt;slave-serve-stale-data yes # 配置当从机正在和主机进行同步的时候是否响应，如果配置是，有可能客户端会读到旧数据，如果配置否，当请求读数据的时候，将会报错SYNC with master in progress&lt;br&gt;slave-read-only yes # 从机是否只读。这边设置可写，不会同步到主机，&lt;br&gt;repl-ping-slave-period 10 # 从机发送ping命令到主机的间隔时间。&lt;br&gt;repl-timeout 60 # 主机响应超时时间，这个包括传输超时，IO超时，ping超时，注意这边时间必须大于上面的间隔时间，要不然会一直报超时错误。&lt;br&gt;repl-disable-tcp-nodelay no # 是否禁用TCP NODELAY。官方对这个配置用法的建议是：&lt;br&gt;# By default we optimize for low latency, but in very high traffic conditions&lt;br&gt;# or when the master and slaves are many hops away, turning this to “yes” may&lt;br&gt;# be a good idea.&lt;br&gt;# 默认情况下，我们优化目的是为了低延迟，但是在高传输条件或者主从机分布在路由很多跳之外的，建议禁用掉tcp-nodelay。&lt;br&gt;slave-priority 100 # 如果master不能再正常工作，那么会在多个slave中，选择优先值最小的一个slave提升为master，优先值为0表示不能提升为master&lt;/master-password&gt;&lt;/p&gt;
&lt;/blockquote&gt;
</content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;Redis主从拷贝的特点&quot;&gt;&lt;a href=&quot;#Redis主从拷贝的特点&quot; class=&quot;headerlink&quot; title=&quot;Redis主从拷贝的特点&quot;&gt;&lt;/a&gt;Redis主从拷贝的特点&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;同一个Master可以拥有多个Slaves。&lt;/li&gt;
&lt;li&gt;Master下的Slave还可以接受同一架构中其它slave的链接与同步请求，实现数据的级联复制，即Master-&amp;gt;Slave-&amp;gt;Slave模式；
    
    </summary>
    
    
      <category term="redis" scheme="http://dxer.github.io/tags/redis/"/>
    
  </entry>
  
  <entry>
    <title>cookie与session</title>
    <link href="http://dxer.github.io/2015/04/17/cookie_and_session/"/>
    <id>http://dxer.github.io/2015/04/17/cookie_and_session/</id>
    <published>2015-04-17T02:43:19.000Z</published>
    <updated>2016-05-16T07:57:36.106Z</updated>
    
    <content type="html">&lt;p&gt;会话（session）跟踪式web程序中常用的技术，用来跟踪用户的整个会话。常用的会话跟踪技术是cookie与session。coolie是通过在客户端记录信息确定用户身份，session是通过在服务端记录信息确定用户身份。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;cookie&quot;&gt;&lt;a href=&quot;#cookie&quot; class=&quot;headerlink&quot; title=&quot;cookie&quot;&gt;&lt;/a&gt;cookie&lt;/h2&gt;&lt;p&gt;cookie技术是客户端解决方案。cookie是由服务器发给客户端的特殊信息，这些信息以文本的方式存放在客户端，客户端每次向服务器发送请求的时候都会带上这些特殊的信息。&lt;/p&gt;
&lt;p&gt;例如：在用户访问一个网站的时候，先登录，用户将用户名和密码发送给服务器；服务器对用户名和密码进行验证，验证成功后，会向客户端回传相应的超文本信息的同时也是返回这些个人信息，这些个人信息存放在HTTP的头部；当客户端接收到服务端的响应之后，浏览器会将这些个人信息存放在一个统一的位置；后面如果客户端再向服务端请求的时候，都会把cookie信息发回到服务器。服务器在接收到来自客户端的请求之后，分析存放于请求头的cookie信息，得到用户相关信息，从而生成与该客户端请求的内容。&lt;/p&gt;
&lt;p&gt;cookie是弥补HTTP协议的无状态的不足。&lt;/p&gt;
&lt;p&gt;cookies是HTTP的一个扩展，有两个专门负责设置以及发送cookie的http头部，Set-Cookie和Cookie。当服务器返回给客户端一个http响应时，如果包含Set-Cookie这个头部时，指示客户端建立一个新的cookie，并且在后续的http请求中自动发送这个cookie到服务端，直到这个cookie过期。如果cookie的生存时间是整个会话期间，浏览器会将cookie保存在内存中个，在浏览器关闭的时候会自动清除这个cookie。cookie也可以保存在客户端的磁盘上，这种情况，在浏览器关闭之后，该cookie也不会清除，下次打开浏览器访问对应网站的时候，这个cookie就会自动再次发送到服务器端。&lt;/p&gt;
&lt;p&gt;客户端发送一个http请求到服务器端，服务器端发送一个http响应到客户端，其中包含Set-Cookie头部&lt;/p&gt;
&lt;p&gt;客户端发送一个http请求到服务器端，其中包含Cookie头部&lt;/p&gt;
&lt;h3 id=&quot;cookie的不可跨域性&quot;&gt;&lt;a href=&quot;#cookie的不可跨域性&quot; class=&quot;headerlink&quot; title=&quot;cookie的不可跨域性&quot;&gt;&lt;/a&gt;cookie的不可跨域性&lt;/h3&gt;&lt;p&gt;很多网站都会使用cookie，但是不同网站的只能使用本网站生成的cookie，不能进行跨域访问。&lt;/p&gt;
&lt;p&gt;cookie中使用Unicode字符时，需要对Unicode字符进行编码，否则会乱码&lt;/p&gt;
&lt;p&gt;cookie不仅可以使用ASCII字符与Unicode字符，还可以使用二进制数据，&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&quot;session&quot;&gt;&lt;a href=&quot;#session&quot; class=&quot;headerlink&quot; title=&quot;session&quot;&gt;&lt;/a&gt;session&lt;/h2&gt;&lt;p&gt;web应用中还经常使用session来记录客户端的状态，session是服务器端使用的一种记录客户端状态的机制，比cookie简单，但是会增加服务器的存储压力&lt;/p&gt;
&lt;p&gt;session技术是服务器端的解决方案，它是通过服务器来保持状态的，客户端浏览器访问服务器的时候，服务器把客户端信息以某种形式记录在服务器上，这个就是session。客户端浏览器再次访问时只需要从该session中查找客户的章台就可以了。&lt;/p&gt;
&lt;p&gt;session类似在服务器上建立了一个客户档案，客户来访的时候只需要查询客户档案就可以了。&lt;/p&gt;
&lt;h3 id=&quot;session的生命周期&quot;&gt;&lt;a href=&quot;#session的生命周期&quot; class=&quot;headerlink&quot; title=&quot;session的生命周期&quot;&gt;&lt;/a&gt;session的生命周期&lt;/h3&gt;&lt;p&gt;session是保存在服务端的，为了获得更高的存取速度，服务器一般把session放在内存中，每个用户都会拥有一个独立的session。如果session的内容太复杂，当亮亮客户访问的时候，会导致服务器内存溢出。所以session里的信息应当尽量精简。&lt;/p&gt;
&lt;p&gt;session在用户第一次访问服务器的时候自动创建，访问服务器端的静态资源是不会产生session的&lt;/p&gt;
&lt;p&gt;session生成后，用户只要继续访问，服务器就会更新session的最后访问时间，并维护该sessin，用户没访问服务器一次，无论是否读写session，服务器都认为该用户的session“活跃”了一次&lt;/p&gt;
&lt;h3 id=&quot;session的有效期&quot;&gt;&lt;a href=&quot;#session的有效期&quot; class=&quot;headerlink&quot; title=&quot;session的有效期&quot;&gt;&lt;/a&gt;session的有效期&lt;/h3&gt;&lt;p&gt;由于访问服务端的用户会越来越多，因此session也会越来越多，为了防止内存溢出，如果超过了超时时间也没有访问服务器端，该session就会自动失效了。&lt;/p&gt;
&lt;p&gt;session对浏览器的要求&lt;/p&gt;
&lt;p&gt;虽然session保存在服务器端，对客户端是透明的，它的正常运行任然需要客户端浏览器的支持，因为session需要使用cookie作为识别标志。HTTP协议是无状态的，session不能通过HTTP链接来判断是否是同一个用户，因此服务器向客户端浏览器发送一个名为JSESSIONID的cookie，它的值为该Session的id。&lt;/p&gt;
&lt;p&gt;该cookie是服务器端自动生成的，它的maxAge属性为-1，表示仅当前浏览器内有效，并且个浏览器窗口见不共享，关闭浏览器就会消失。&lt;/p&gt;
&lt;p&gt;同一台机器的两个浏览器窗口访问服务器时，会生成两个不同的session，但是有浏览器窗口内的链接，脚本等打开的新窗口除外。这类子窗口会共享父窗口的cookie，因此会共享一个session。&lt;/p&gt;
&lt;p&gt;新打开的浏览器窗口会生成新的session，但子窗口除外，子窗口会共享父窗口的session。&lt;/p&gt;
&lt;p&gt;如果客户端浏览器将cookie禁用，或者不支持cookie怎么办（绝大数手机浏览器不支持cookie）？&lt;/p&gt;
&lt;p&gt;URL地址重写&lt;/p&gt;
&lt;h2 id=&quot;URL重写&quot;&gt;&lt;a href=&quot;#URL重写&quot; class=&quot;headerlink&quot; title=&quot;URL重写&quot;&gt;&lt;/a&gt;URL重写&lt;/h2&gt;&lt;p&gt;URL地址重写是对客户端不支持cookie的解决方案&lt;/p&gt;
&lt;p&gt;URL地址重写的原理就是将用户的session的id信息重写到URL地址中，服务器能够够解析重写后的URL，从而获取session的id。这样即使客户端不支持cookie，也可以使用session来记录用户的状态了。&lt;/p&gt;
&lt;h2 id=&quot;cookie与session的区别&quot;&gt;&lt;a href=&quot;#cookie与session的区别&quot; class=&quot;headerlink&quot; title=&quot;cookie与session的区别&quot;&gt;&lt;/a&gt;cookie与session的区别&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;&lt;p&gt;cookie数据存在客户端的浏览器上，session数据存放在服务器上&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;cookie不是很安全，别人可以分析存放在本地的cookie并进行cookie欺骗，考虑到安全应当那个使用session&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;session会在一定时间内保存在服务器上，当访问量增多，会占用比较多的服务器资源，考虑到减轻服务器性能方面，应当使用cookie&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;的那个cookie在客户端的限制是3k，就是说一个站点在客户端存放的cookie不能超过3k&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;会话（session）跟踪式web程序中常用的技术，用来跟踪用户的整个会话。常用的会话跟踪技术是cookie与session。coolie是通过在客户端记录信息确定用户身份，session是通过在服务端记录信息确定用户身份。&lt;br&gt;
    
    </summary>
    
    
      <category term="session" scheme="http://dxer.github.io/tags/session/"/>
    
      <category term="cookie" scheme="http://dxer.github.io/tags/cookie/"/>
    
  </entry>
  
</feed>
